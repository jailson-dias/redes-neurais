{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF702 Redes Neurais\n",
    "Projeto de redes neurais utilizando Base de Dados do Tipo 2, Detecção de Células de Câncer em Mamografias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a leitura da base de dados foi feita utilizando a biblioteca pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('mammography.csv')\n",
    "\n",
    "data_set.columns = ['X1','X2','X3','X4','X5','X6','CLASS'] # renomeando as colunas para ficar CLASS em vez de class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo exemplos repetidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7845\n"
     ]
    }
   ],
   "source": [
    "columns = data_set.columns.tolist()[:-1] # remove a coluna da classe da lista de colunas\n",
    "# print (columns)\n",
    "data_set.drop_duplicates(subset=columns, # seleciona apenas as 6 primeiras colunas para verificar duplicatas\n",
    "                         keep=False, # remove todos os exemplos repetidos\n",
    "                         inplace=True)  # Remove exemplos repetidos\n",
    "print (len(data_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renomeando a classe -1 para 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['CLASS'] = data_set['CLASS'].map(lambda x : 0 if (x == -1) else 1)\n",
    "# print (data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estatisticas da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.333764</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>0.251736</td>\n",
       "      <td>0.365734</td>\n",
       "      <td>0.160780</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.032250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.025813</td>\n",
       "      <td>1.136427</td>\n",
       "      <td>1.101461</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>1.157123</td>\n",
       "      <td>0.939678</td>\n",
       "      <td>0.176674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.784415</td>\n",
       "      <td>-0.452501</td>\n",
       "      <td>-0.591631</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.145333</td>\n",
       "      <td>-0.408265</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.111790</td>\n",
       "      <td>-0.271133</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>0.550163</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>0.845975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.508993</td>\n",
       "      <td>0.219887</td>\n",
       "      <td>0.400163</td>\n",
       "      <td>1.027382</td>\n",
       "      <td>0.387549</td>\n",
       "      <td>1.132403</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.508443</td>\n",
       "      <td>5.085849</td>\n",
       "      <td>29.477769</td>\n",
       "      <td>9.591164</td>\n",
       "      <td>23.617122</td>\n",
       "      <td>1.949027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  7845.000000  7845.000000  7845.000000  7845.000000  7845.000000   \n",
       "mean      0.333764     0.200042     0.251736     0.365734     0.160780   \n",
       "std       1.025813     1.136427     1.101461     0.988616     1.157123   \n",
       "min      -0.784415    -0.452501    -0.591631    -0.859553    -0.377866   \n",
       "25%      -0.145333    -0.408265    -0.276061    -0.859553    -0.377866   \n",
       "50%       0.111790    -0.271133    -0.005571     0.550163    -0.377866   \n",
       "75%       0.508993     0.219887     0.400163     1.027382     0.387549   \n",
       "max      31.508443     5.085849    29.477769     9.591164    23.617122   \n",
       "\n",
       "                X6        CLASS  \n",
       "count  7845.000000  7845.000000  \n",
       "mean      0.402400     0.032250  \n",
       "std       0.939678     0.176674  \n",
       "min      -0.945723     0.000000  \n",
       "25%      -0.945723     0.000000  \n",
       "50%       0.845975     0.000000  \n",
       "75%       1.132403     0.000000  \n",
       "max       1.949027     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estatísticas sobre as variáveis\n",
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando as classes da base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando função para separando a base de dados pelas classes, para assim poder garantir que vai ter exemplos de cada classe em todos os conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_classes(data):\n",
    "    zero = data[data.CLASS == 0]\n",
    "    um = data[data.CLASS == 1]\n",
    "    \n",
    "    return [zero, um]\n",
    "\n",
    "# print (len(separar_grupos(data_set)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos Dados em Treino, Validação, e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_grupos_tvt(data): \n",
    "    \"\"\"\n",
    "    Divisão da base de dados\n",
    "    Treinamento = 50%\n",
    "    Validação = 25%\n",
    "    Teste = 25%\n",
    "    \"\"\"\n",
    "    \n",
    "    # classe zero\n",
    "    zero_train, zero_validation = train_test_split(data[0], # base de dados que vai ser dividida\n",
    "                                                   test_size=1/2, # proporção da divisão dos dados\n",
    "                                                   random_state=42)\n",
    "    zero_validation, zero_teste = train_test_split(zero_validation, # base de dados que vai ser dividida\n",
    "                                                   test_size=1/2, # proporção da divisão dos dados\n",
    "                                                   random_state=42)\n",
    "    \n",
    "    #classe um\n",
    "    um_train, um_validation = train_test_split(data[1], # base de dados que vai ser dividida\n",
    "                                                   test_size=1/2, # proporção da divisão dos dados\n",
    "                                                   random_state=42)\n",
    "    um_validation, um_teste = train_test_split(um_validation, # base de dados que vai ser dividida\n",
    "                                                   test_size=1/2, # proporção da divisão dos dados\n",
    "                                                   random_state=42)\n",
    "    \n",
    "    return [(zero_train, zero_validation, zero_teste),(um_train, um_validation, um_teste)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicando os dados da classe minoritaria para ter a mesma quantidade de exemplos das duas classes na MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling_replacement(data):\n",
    "    um_train = data[1][0]\n",
    "    um_validation = data[1][1]\n",
    "    um_train = np.resize(um_train, data[0][0].shape)\n",
    "    um_validation = np.resize(um_validation, data[0][1].shape)\n",
    "    \n",
    "    return [data[0],(um_train, um_validation, data[1][2])]\n",
    "\n",
    "def oversampling_SMOTE(data):\n",
    "    '''Faz o oversampling usando o algoritmo SMOTE\n",
    "    \n",
    "    Parametros:\n",
    "        data (array-like): Array das amostras, com as amostras de treinamento no 1o indice, de validacao no 2o e teste no 3o\n",
    "    \n",
    "    Returns:\n",
    "        array-like: Array das amostras, apos o oversampling\n",
    "    '''\n",
    "    sm = SMOTE(random_state=42)\n",
    "    \n",
    "    train_features = data[0][:, :-1]\n",
    "    train_labels = data[0][:, -1]\n",
    "    features, labels = sm.fit_sample(train_features, train_labels)\n",
    "    train = np.zeros((len(labels), 7))\n",
    "    for i in range(len(train)):\n",
    "        train[i] = np.concatenate((features[i], np.array([labels[i]])), axis=0)\n",
    "    # Sem isso, os 0s tenderiam a ficar acima dos 1s\n",
    "    np.random.shuffle(train)\n",
    "    \n",
    "    validation_features = data[1][:, :-1]\n",
    "    validation_labels = data[1][:, -1]\n",
    "    features, labels = sm.fit_sample(validation_features, validation_labels)\n",
    "    validation = np.zeros((len(labels), 7))\n",
    "    for i in range(len(validation)):\n",
    "        validation[i] = np.concatenate((features[i], np.array([labels[i]])), axis=0)\n",
    "    np.random.shuffle(validation)\n",
    "    \n",
    "    return [train, validation, data[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando as classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando as classes zero e um dos conjuntos de treinamento, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_class(data):\n",
    "    train = np.concatenate((data[0][0], data[1][0]), axis=0)\n",
    "    validation = np.concatenate((data[0][1], data[1][1]), axis=0)\n",
    "    test = np.concatenate((data[0][2], data[1][2]), axis=0)\n",
    "\n",
    "    np.random.shuffle(train)\n",
    "    np.random.shuffle(validation)\n",
    "    np.random.shuffle(test)\n",
    "    \n",
    "    return [train, validation, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592 253\n",
      "3796 1898 1898 126 63 64\n",
      "7592 3796 1962\n"
     ]
    }
   ],
   "source": [
    "sep = separar_classes(data_set)\n",
    "print (len(sep[0]), len(sep[1]))\n",
    "grupos = separar_grupos_tvt(sep)\n",
    "print (len(grupos[0][0]), len(grupos[0][1]), len(grupos[0][2]), \n",
    "       len(grupos[1][0]), len(grupos[1][1]), len(grupos[1][2]))\n",
    "join_c = join_class(grupos)\n",
    "over = oversampling_SMOTE(join_c)\n",
    "print (len(over[0]), len(over[1]), len(over[2])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando entrada de saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 3796, 0.0: 3796})\n",
      "Counter({0.0: 1898, 1.0: 1898})\n",
      "Counter({0.0: 1898, 1.0: 64})\n"
     ]
    }
   ],
   "source": [
    "X_train = over[0][:,:-1]\n",
    "y_train = over[0][:,-1]\n",
    "\n",
    "X_validation = over[1][:,:-1]\n",
    "y_validation = over[1][:,-1]\n",
    "\n",
    "X_test = over[2][:,:-1]\n",
    "y_test = over[2][:,-1]\n",
    "\n",
    "# utilizado para verificar a quantidade de exemplos de cada classe que tem nos conjuntos de validação, teste e treinamento\n",
    "import collections\n",
    "print (collections.Counter(y_train))\n",
    "print (collections.Counter(y_validation))\n",
    "print (collections.Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição e Treino da Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "[[1804   94]\n",
      " [   7   57]]\n",
      "\n",
      "Accuracy:         0.9485\n",
      "MSE:              0.0515\n",
      "AUROC:            0.9205\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(np.concatenate((X_train, X_validation), axis=0), np.concatenate((y_train, y_validation), axis=0))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "## Matriz de confusão\n",
    "print('Matriz de confusão')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy_score(y_test, y_pred)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"MSE:\", value=mean_squared_error(y_test, y_pred)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=roc_auc_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
