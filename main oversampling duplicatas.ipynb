{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF702 Redes Neurais\n",
    "Projeto de redes neurais utilizando Base de Dados do Tipo 2, Detecção de Células de Câncer em Mamografias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a leitura da base de dados foi feita utilizando a biblioteca pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('mammography.csv')\n",
    "\n",
    "data_set.columns = ['X1','X2','X3','X4','X5','X6','CLASS'] # renomeando as colunas para ficar CLASS em vez de class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo exemplos repetidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7845\n"
     ]
    }
   ],
   "source": [
    "columns = data_set.columns.tolist()[:-1] # remove a coluna da classe da lista de colunas\n",
    "# print (columns)\n",
    "data_set.drop_duplicates(subset=columns, # seleciona apenas as 6 primeiras colunas para verificar duplicatas\n",
    "                         keep=False, # remove todos os exemplos repetidos\n",
    "                         inplace=True)  # Remove exemplos repetidos\n",
    "print (len(data_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renomeando a classe -1 para 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['CLASS'] = data_set['CLASS'].map(lambda x : 0 if (x == -1) else 1)\n",
    "# print (data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estatisticas da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "      <td>7845.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.333764</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>0.251736</td>\n",
       "      <td>0.365734</td>\n",
       "      <td>0.160780</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.032250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.025813</td>\n",
       "      <td>1.136427</td>\n",
       "      <td>1.101461</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>1.157123</td>\n",
       "      <td>0.939678</td>\n",
       "      <td>0.176674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.784415</td>\n",
       "      <td>-0.452501</td>\n",
       "      <td>-0.591631</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.145333</td>\n",
       "      <td>-0.408265</td>\n",
       "      <td>-0.276061</td>\n",
       "      <td>-0.859553</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>-0.945723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.111790</td>\n",
       "      <td>-0.271133</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>0.550163</td>\n",
       "      <td>-0.377866</td>\n",
       "      <td>0.845975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.508993</td>\n",
       "      <td>0.219887</td>\n",
       "      <td>0.400163</td>\n",
       "      <td>1.027382</td>\n",
       "      <td>0.387549</td>\n",
       "      <td>1.132403</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.508443</td>\n",
       "      <td>5.085849</td>\n",
       "      <td>29.477769</td>\n",
       "      <td>9.591164</td>\n",
       "      <td>23.617122</td>\n",
       "      <td>1.949027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  7845.000000  7845.000000  7845.000000  7845.000000  7845.000000   \n",
       "mean      0.333764     0.200042     0.251736     0.365734     0.160780   \n",
       "std       1.025813     1.136427     1.101461     0.988616     1.157123   \n",
       "min      -0.784415    -0.452501    -0.591631    -0.859553    -0.377866   \n",
       "25%      -0.145333    -0.408265    -0.276061    -0.859553    -0.377866   \n",
       "50%       0.111790    -0.271133    -0.005571     0.550163    -0.377866   \n",
       "75%       0.508993     0.219887     0.400163     1.027382     0.387549   \n",
       "max      31.508443     5.085849    29.477769     9.591164    23.617122   \n",
       "\n",
       "                X6        CLASS  \n",
       "count  7845.000000  7845.000000  \n",
       "mean      0.402400     0.032250  \n",
       "std       0.939678     0.176674  \n",
       "min      -0.945723     0.000000  \n",
       "25%      -0.945723     0.000000  \n",
       "50%       0.845975     0.000000  \n",
       "75%       1.132403     0.000000  \n",
       "max       1.949027     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estatísticas sobre as variáveis\n",
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando as classes da base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando função para separando a base de dados pelas classes, para assim poder garantir que vai ter exemplos de cada classe em todos os conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_classes(data):\n",
    "    zero = data[data.CLASS == 0]\n",
    "    um = data[data.CLASS == 1]\n",
    "    \n",
    "    return [zero, um]\n",
    "\n",
    "# print (len(separar_grupos(data_set)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos Dados em Treino, Validação, e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_grupos_tvt(data): \n",
    "    \"\"\"\n",
    "    Divisão da base de dados\n",
    "    Treinamento = 50%\n",
    "    Validação = 25%\n",
    "    Teste = 25%\n",
    "    \"\"\"\n",
    "    \n",
    "    # classe zero\n",
    "    zero_train, zero_validation = train_test_split(data[0], # base de dados que vai ser dividida\n",
    "                                                   test_size=1/2, # proporção da divisão dos dados\n",
    "                                                   random_state=42)\n",
    "    zero_validation, zero_teste = train_test_split(zero_validation, # base de dados que vai ser dividida\n",
    "                                                   test_size=1/2, # proporção da divisão dos dados\n",
    "                                                   random_state=42)\n",
    "    \n",
    "    #classe um\n",
    "    um_train, um_validation = train_test_split(data[1], # base de dados que vai ser dividida\n",
    "                                                   test_size=1/2, # proporção da divisão dos dados\n",
    "                                                   random_state=42)\n",
    "    um_validation, um_teste = train_test_split(um_validation, # base de dados que vai ser dividida\n",
    "                                                   test_size=1/2, # proporção da divisão dos dados\n",
    "                                                   random_state=42)\n",
    "    \n",
    "    return [(zero_train, zero_validation, zero_teste),(um_train, um_validation, um_teste)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicando os dados da classe minoritaria para ter a mesma quantidade de exemplos das duas classes na MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling_replacement(data):\n",
    "    um_train = data[1][0]\n",
    "    um_validation = data[1][1]\n",
    "    um_train = np.resize(um_train, data[0][0].shape)\n",
    "    um_validation = np.resize(um_validation, data[0][1].shape)\n",
    "    \n",
    "    return [data[0],(um_train, um_validation, data[1][2])]\n",
    "\n",
    "def oversampling_SMOTE(data):\n",
    "    '''Faz o oversampling usando o algoritmo SMOTE\n",
    "    \n",
    "    Parametros:\n",
    "        data (array-like): Array das amostras, com as amostras de treinamento no 1o indice, de validacao no 2o e teste no 3o\n",
    "    \n",
    "    Returns:\n",
    "        array-like: Array das amostras, apos o oversampling\n",
    "    '''\n",
    "    sm = SMOTE(random_state=42)\n",
    "    \n",
    "    train_features = data[0][:, :-1]\n",
    "    train_labels = data[0][:, -1]\n",
    "    features, labels = sm.fit_sample(train_features, train_labels)\n",
    "    train = np.zeros((len(labels), 7))\n",
    "    for i in range(len(train)):\n",
    "        train[i] = np.concatenate((features[i], np.array([labels[i]])), axis=0)\n",
    "    # Sem isso, os 0s tenderiam a ficar acima dos 1s\n",
    "    np.random.shuffle(train)\n",
    "    \n",
    "    validation_features = data[1][:, :-1]\n",
    "    validation_labels = data[1][:, -1]\n",
    "    features, labels = sm.fit_sample(validation_features, validation_labels)\n",
    "    validation = np.zeros((len(labels), 7))\n",
    "    for i in range(len(validation)):\n",
    "        validation[i] = np.concatenate((features[i], np.array([labels[i]])), axis=0)\n",
    "    np.random.shuffle(validation)\n",
    "    \n",
    "    return [train, validation, data[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando as classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando as classes zero e um dos conjuntos de treinamento, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_class(data):\n",
    "    train = np.concatenate((data[0][0], data[1][0]), axis=0)\n",
    "    validation = np.concatenate((data[0][1], data[1][1]), axis=0)\n",
    "    test = np.concatenate((data[0][2], data[1][2]), axis=0)\n",
    "\n",
    "    np.random.shuffle(train)\n",
    "    np.random.shuffle(validation)\n",
    "    np.random.shuffle(test)\n",
    "    \n",
    "    return [train, validation, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592 253\n",
      "3796 1898 1898 126 63 64\n",
      "3796 1898 1898 3796 1898 64\n",
      "7592 3796 1962\n"
     ]
    }
   ],
   "source": [
    "# data_set_oversampling = oversampling(separar_grupos_tvt(separar_classes(data_set)))\n",
    "# print (data_set_oversampling)\n",
    "sep = separar_classes(data_set)\n",
    "print (len(sep[0]), len(sep[1]))\n",
    "grupos = separar_grupos_tvt(sep)\n",
    "print (len(grupos[0][0]), len(grupos[0][1]), len(grupos[0][2]), \n",
    "       len(grupos[1][0]), len(grupos[1][1]), len(grupos[1][2]))\n",
    "over = oversampling_replacement(grupos)\n",
    "print (len(over[0][0]), len(over[0][1]), len(over[0][2]), \n",
    "       len(over[1][0]), len(over[1][1]), len(over[1][2]))\n",
    "\n",
    "join_c = join_class(over)\n",
    "print (len(join_c[0]), len(join_c[1]), len(join_c[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando entrada de saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 3796, 0.0: 3796})\n",
      "Counter({0.0: 1898, 1.0: 1898})\n",
      "Counter({0.0: 1898, 1.0: 64})\n"
     ]
    }
   ],
   "source": [
    "# columns = data_set.columns.tolist()\n",
    "# shape_view = data_set.reindex(columns=columns[1:10] + [columns[0]]) # columns[0] é a coluna que fica qual é a classe que o exemplo pertence\n",
    "# rgb_view = data_set.reindex(columns=columns[10:] + [columns[0]]) # columns[0] é a coluna que fica qual é a classe que o exemplo pertence\n",
    "X_train = join_c[0][:,:-1]\n",
    "y_train = join_c[0][:,-1]\n",
    "\n",
    "X_validation = join_c[1][:,:-1]\n",
    "y_validation = join_c[1][:,-1]\n",
    "\n",
    "X_test = join_c[2][:,:-1]\n",
    "y_test = join_c[2][:,-1]\n",
    "# print (y_validation)\n",
    "\n",
    "\n",
    "# utilizado para verificar a quantidade de exemplos de cada classe que tem nos conjuntos de validação, teste e treinamento\n",
    "import collections\n",
    "print (collections.Counter(y_train))\n",
    "print (collections.Counter(y_validation))\n",
    "print (collections.Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição e Treino da Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas funções auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_losses(history):\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    idx_min_val_loss = np.argmin(val_loss)\n",
    "    \n",
    "    return {'train_loss': train_loss[idx_min_val_loss], 'val_loss': val_loss[idx_min_val_loss]}\n",
    "\n",
    "def plot_training_error_curves(history):\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_loss, label='Train')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.set(title='Training and Validation Error Curves', xlabel='Epochs', ylabel='Loss (MSE)')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_training_acc_curves(history):\n",
    "    train_loss = history.history['acc']\n",
    "    val_loss = history.history['val_acc']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_loss, label='Train')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.set(title='Training and Validation Accuracy Curves', xlabel='Epochs', ylabel='Accuracy')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA 1 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7592 samples, validate on 3796 samples\n",
      "Epoch 1/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.3759 - acc: 0.6470 - val_loss: 0.4021 - val_acc: 0.6502\n",
      "Epoch 2/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.2109 - acc: 0.7337 - val_loss: 0.1824 - val_acc: 0.8156\n",
      "Epoch 3/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.1378 - acc: 0.8315 - val_loss: 0.1511 - val_acc: 0.8498\n",
      "Epoch 4/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.1076 - acc: 0.8722 - val_loss: 0.1308 - val_acc: 0.8483\n",
      "Epoch 5/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0982 - acc: 0.8790 - val_loss: 0.1184 - val_acc: 0.8519\n",
      "Epoch 6/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0934 - acc: 0.8857 - val_loss: 0.1158 - val_acc: 0.8525\n",
      "Epoch 7/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0908 - acc: 0.8950 - val_loss: 0.1154 - val_acc: 0.8462\n",
      "Epoch 8/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0888 - acc: 0.9033 - val_loss: 0.1166 - val_acc: 0.8475\n",
      "Epoch 9/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0878 - acc: 0.9035 - val_loss: 0.1133 - val_acc: 0.8409\n",
      "Epoch 10/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0871 - acc: 0.9033 - val_loss: 0.1108 - val_acc: 0.8464\n",
      "Epoch 11/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0862 - acc: 0.9038 - val_loss: 0.1095 - val_acc: 0.8467\n",
      "Epoch 12/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0849 - acc: 0.9015 - val_loss: 0.1150 - val_acc: 0.8440\n",
      "Epoch 13/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0832 - acc: 0.9065 - val_loss: 0.1104 - val_acc: 0.8509\n",
      "Epoch 14/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0815 - acc: 0.9053 - val_loss: 0.1075 - val_acc: 0.8525\n",
      "Epoch 15/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0802 - acc: 0.9036 - val_loss: 0.1033 - val_acc: 0.8533\n",
      "Epoch 16/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0793 - acc: 0.9054 - val_loss: 0.1035 - val_acc: 0.8680\n",
      "Epoch 17/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0784 - acc: 0.9048 - val_loss: 0.1002 - val_acc: 0.8675\n",
      "Epoch 18/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0780 - acc: 0.9049 - val_loss: 0.1001 - val_acc: 0.8633\n",
      "Epoch 19/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0777 - acc: 0.9044 - val_loss: 0.0967 - val_acc: 0.8693\n",
      "Epoch 20/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0770 - acc: 0.9033 - val_loss: 0.0968 - val_acc: 0.8651\n",
      "Epoch 21/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0768 - acc: 0.9057 - val_loss: 0.0972 - val_acc: 0.8707\n",
      "Epoch 22/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0767 - acc: 0.9052 - val_loss: 0.0951 - val_acc: 0.8678\n",
      "Epoch 23/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0762 - acc: 0.9050 - val_loss: 0.0941 - val_acc: 0.8770\n",
      "Epoch 24/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0761 - acc: 0.9054 - val_loss: 0.0939 - val_acc: 0.8759\n",
      "Epoch 25/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0759 - acc: 0.9036 - val_loss: 0.0949 - val_acc: 0.8672\n",
      "Epoch 26/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0757 - acc: 0.9042 - val_loss: 0.0941 - val_acc: 0.8678\n",
      "Epoch 27/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0757 - acc: 0.9045 - val_loss: 0.0937 - val_acc: 0.8791\n",
      "Epoch 28/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0755 - acc: 0.9050 - val_loss: 0.0957 - val_acc: 0.8720\n",
      "Epoch 29/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0755 - acc: 0.9049 - val_loss: 0.0937 - val_acc: 0.8696\n",
      "Epoch 30/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0755 - acc: 0.9045 - val_loss: 0.0928 - val_acc: 0.8770\n",
      "Epoch 31/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0754 - acc: 0.9035 - val_loss: 0.0933 - val_acc: 0.8701\n",
      "Epoch 32/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0753 - acc: 0.9045 - val_loss: 0.0940 - val_acc: 0.8691\n",
      "Epoch 33/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0753 - acc: 0.9041 - val_loss: 0.0949 - val_acc: 0.8704\n",
      "Epoch 34/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0753 - acc: 0.9056 - val_loss: 0.0925 - val_acc: 0.8772\n",
      "Epoch 35/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0752 - acc: 0.9053 - val_loss: 0.0942 - val_acc: 0.8696\n",
      "Epoch 36/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0752 - acc: 0.9046 - val_loss: 0.0924 - val_acc: 0.8778\n",
      "Epoch 37/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0751 - acc: 0.9037 - val_loss: 0.0940 - val_acc: 0.8701\n",
      "Epoch 38/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0751 - acc: 0.9050 - val_loss: 0.0928 - val_acc: 0.8778\n",
      "Epoch 39/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0752 - acc: 0.9053 - val_loss: 0.0966 - val_acc: 0.8696\n",
      "Epoch 40/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0750 - acc: 0.9049 - val_loss: 0.0933 - val_acc: 0.8672\n",
      "Epoch 41/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0750 - acc: 0.9045 - val_loss: 0.0956 - val_acc: 0.8704\n",
      "Epoch 42/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0750 - acc: 0.9042 - val_loss: 0.0937 - val_acc: 0.8704\n",
      "Epoch 43/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0749 - acc: 0.9042 - val_loss: 0.0932 - val_acc: 0.8691\n",
      "Epoch 44/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0750 - acc: 0.9046 - val_loss: 0.0937 - val_acc: 0.8699\n",
      "Epoch 45/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0749 - acc: 0.9049 - val_loss: 0.0921 - val_acc: 0.8778\n",
      "Epoch 46/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0748 - acc: 0.9042 - val_loss: 0.0944 - val_acc: 0.8699\n",
      "Epoch 47/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0749 - acc: 0.9046 - val_loss: 0.0926 - val_acc: 0.8772\n",
      "Epoch 48/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0749 - acc: 0.9057 - val_loss: 0.0933 - val_acc: 0.8680\n",
      "Epoch 49/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9045 - val_loss: 0.0931 - val_acc: 0.8699\n",
      "Epoch 50/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0749 - acc: 0.9045 - val_loss: 0.0922 - val_acc: 0.8770\n",
      "Epoch 51/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0748 - acc: 0.9041 - val_loss: 0.0934 - val_acc: 0.8701\n",
      "Epoch 52/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0748 - acc: 0.9049 - val_loss: 0.0930 - val_acc: 0.8780\n",
      "Epoch 53/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0748 - acc: 0.9046 - val_loss: 0.0929 - val_acc: 0.8683\n",
      "Epoch 54/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9049 - val_loss: 0.0923 - val_acc: 0.8767\n",
      "Epoch 55/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0748 - acc: 0.9050 - val_loss: 0.0961 - val_acc: 0.8675\n",
      "Epoch 56/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9044 - val_loss: 0.0937 - val_acc: 0.8701\n",
      "Epoch 57/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9046 - val_loss: 0.0933 - val_acc: 0.8701\n",
      "Epoch 58/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0748 - acc: 0.9049 - val_loss: 0.0923 - val_acc: 0.8764\n",
      "Epoch 59/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9045 - val_loss: 0.0928 - val_acc: 0.8772\n",
      "Epoch 60/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0746 - acc: 0.9045 - val_loss: 0.0932 - val_acc: 0.8701\n",
      "Epoch 61/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9042 - val_loss: 0.0931 - val_acc: 0.8696\n",
      "Epoch 62/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9044 - val_loss: 0.0920 - val_acc: 0.8767\n",
      "Epoch 63/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0746 - acc: 0.9046 - val_loss: 0.0951 - val_acc: 0.8699\n",
      "Epoch 64/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9041 - val_loss: 0.0933 - val_acc: 0.8701\n",
      "Epoch 65/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9046 - val_loss: 0.0938 - val_acc: 0.8701\n",
      "Epoch 66/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0748 - acc: 0.9046 - val_loss: 0.0941 - val_acc: 0.8693\n",
      "Epoch 67/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9045 - val_loss: 0.0944 - val_acc: 0.8685\n",
      "Epoch 68/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0746 - acc: 0.9042 - val_loss: 0.0947 - val_acc: 0.86910\n",
      "Epoch 69/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9041 - val_loss: 0.0933 - val_acc: 0.8683\n",
      "Epoch 70/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0746 - acc: 0.9041 - val_loss: 0.0931 - val_acc: 0.8696\n",
      "Epoch 71/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0746 - acc: 0.9045 - val_loss: 0.0933 - val_acc: 0.8699\n",
      "Epoch 72/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0747 - acc: 0.9040 - val_loss: 0.0938 - val_acc: 0.8696\n",
      "Epoch 73/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0745 - acc: 0.9042 - val_loss: 0.0947 - val_acc: 0.8688\n",
      "Epoch 74/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0746 - acc: 0.9040 - val_loss: 0.0947 - val_acc: 0.8691\n",
      "Epoch 75/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0746 - acc: 0.9044 - val_loss: 0.0920 - val_acc: 0.8741\n",
      "Epoch 76/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0745 - acc: 0.9037 - val_loss: 0.0930 - val_acc: 0.8783\n",
      "Epoch 77/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0745 - acc: 0.9038 - val_loss: 0.0927 - val_acc: 0.8780\n",
      "Epoch 78/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0745 - acc: 0.9035 - val_loss: 0.0942 - val_acc: 0.8699\n",
      "Epoch 79/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0745 - acc: 0.9041 - val_loss: 0.0940 - val_acc: 0.8680\n",
      "Epoch 80/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0744 - acc: 0.9037 - val_loss: 0.0928 - val_acc: 0.8778\n",
      "Epoch 81/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0746 - acc: 0.9037 - val_loss: 0.0936 - val_acc: 0.8693\n",
      "Epoch 82/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0743 - acc: 0.9037 - val_loss: 0.0943 - val_acc: 0.8683\n",
      "Epoch 83/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0744 - acc: 0.9035 - val_loss: 0.0952 - val_acc: 0.8675\n",
      "Epoch 84/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0744 - acc: 0.9035 - val_loss: 0.0940 - val_acc: 0.8678\n",
      "Epoch 85/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0743 - acc: 0.9031 - val_loss: 0.0919 - val_acc: 0.8770\n",
      "Epoch 86/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0744 - acc: 0.9040 - val_loss: 0.0930 - val_acc: 0.8680\n",
      "Epoch 87/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0744 - acc: 0.9033 - val_loss: 0.0926 - val_acc: 0.8696\n",
      "Epoch 88/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0743 - acc: 0.9035 - val_loss: 0.0924 - val_acc: 0.8667\n",
      "Epoch 89/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0743 - acc: 0.9027 - val_loss: 0.0930 - val_acc: 0.8680\n",
      "Epoch 90/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9037 - val_loss: 0.0915 - val_acc: 0.8743\n",
      "Epoch 91/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0743 - acc: 0.9025 - val_loss: 0.0921 - val_acc: 0.8780\n",
      "Epoch 92/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0743 - acc: 0.9032 - val_loss: 0.0928 - val_acc: 0.8680\n",
      "Epoch 93/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9033 - val_loss: 0.0921 - val_acc: 0.8749\n",
      "Epoch 94/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9025 - val_loss: 0.0937 - val_acc: 0.8693\n",
      "Epoch 95/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9025 - val_loss: 0.0934 - val_acc: 0.8786\n",
      "Epoch 96/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0743 - acc: 0.9038 - val_loss: 0.0944 - val_acc: 0.8685\n",
      "Epoch 97/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9032 - val_loss: 0.0925 - val_acc: 0.8675\n",
      "Epoch 98/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9031 - val_loss: 0.0935 - val_acc: 0.8707\n",
      "Epoch 99/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9029 - val_loss: 0.0934 - val_acc: 0.8704\n",
      "Epoch 100/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9036 - val_loss: 0.0921 - val_acc: 0.8751\n",
      "Epoch 101/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9048 - val_loss: 0.0929 - val_acc: 0.8696\n",
      "Epoch 102/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9038 - val_loss: 0.0942 - val_acc: 0.8675\n",
      "Epoch 103/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9036 - val_loss: 0.0927 - val_acc: 0.8680\n",
      "Epoch 104/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9021 - val_loss: 0.0915 - val_acc: 0.8746\n",
      "Epoch 105/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0743 - acc: 0.9025 - val_loss: 0.0925 - val_acc: 0.8770\n",
      "Epoch 106/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9041 - val_loss: 0.0919 - val_acc: 0.8751\n",
      "Epoch 107/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9035 - val_loss: 0.0918 - val_acc: 0.8757\n",
      "Epoch 108/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9024 - val_loss: 0.0921 - val_acc: 0.8775\n",
      "Epoch 109/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9036 - val_loss: 0.0958 - val_acc: 0.8707\n",
      "Epoch 110/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9029 - val_loss: 0.0930 - val_acc: 0.8680\n",
      "Epoch 111/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9031 - val_loss: 0.0937 - val_acc: 0.8667\n",
      "Epoch 112/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9032 - val_loss: 0.0914 - val_acc: 0.8775\n",
      "Epoch 113/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9032 - val_loss: 0.0926 - val_acc: 0.8788\n",
      "Epoch 114/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9029 - val_loss: 0.0923 - val_acc: 0.8775\n",
      "Epoch 115/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9035 - val_loss: 0.0920 - val_acc: 0.8751\n",
      "Epoch 116/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9021 - val_loss: 0.0927 - val_acc: 0.8764\n",
      "Epoch 117/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9036 - val_loss: 0.0928 - val_acc: 0.8757\n",
      "Epoch 118/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9028 - val_loss: 0.0942 - val_acc: 0.8701\n",
      "Epoch 119/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9037 - val_loss: 0.0949 - val_acc: 0.8685\n",
      "Epoch 120/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9044 - val_loss: 0.0954 - val_acc: 0.8712\n",
      "Epoch 121/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9029 - val_loss: 0.0919 - val_acc: 0.8762\n",
      "Epoch 122/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9042 - val_loss: 0.0922 - val_acc: 0.8772\n",
      "Epoch 123/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9031 - val_loss: 0.0945 - val_acc: 0.8709\n",
      "Epoch 124/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9032 - val_loss: 0.0930 - val_acc: 0.8783\n",
      "Epoch 125/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0742 - acc: 0.9028 - val_loss: 0.0931 - val_acc: 0.8693\n",
      "Epoch 126/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9037 - val_loss: 0.0922 - val_acc: 0.8844\n",
      "Epoch 127/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9021 - val_loss: 0.0952 - val_acc: 0.8759\n",
      "Epoch 128/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9033 - val_loss: 0.0921 - val_acc: 0.8838\n",
      "Epoch 129/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9032 - val_loss: 0.0914 - val_acc: 0.8836\n",
      "Epoch 130/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9040 - val_loss: 0.0927 - val_acc: 0.8849\n",
      "Epoch 131/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9029 - val_loss: 0.0947 - val_acc: 0.8693\n",
      "Epoch 132/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9041 - val_loss: 0.0930 - val_acc: 0.8817\n",
      "Epoch 133/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9037 - val_loss: 0.0934 - val_acc: 0.8772\n",
      "Epoch 134/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9029 - val_loss: 0.0932 - val_acc: 0.8854\n",
      "Epoch 135/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9042 - val_loss: 0.0922 - val_acc: 0.8838\n",
      "Epoch 136/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9035 - val_loss: 0.0921 - val_acc: 0.8846\n",
      "Epoch 137/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9024 - val_loss: 0.0927 - val_acc: 0.8846\n",
      "Epoch 138/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9057 - val_loss: 0.0943 - val_acc: 0.8707\n",
      "Epoch 139/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9025 - val_loss: 0.0936 - val_acc: 0.8836\n",
      "Epoch 140/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9044 - val_loss: 0.0941 - val_acc: 0.8767\n",
      "Epoch 141/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9025 - val_loss: 0.0935 - val_acc: 0.8696\n",
      "Epoch 142/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9028 - val_loss: 0.0958 - val_acc: 0.8772\n",
      "Epoch 143/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9035 - val_loss: 0.0938 - val_acc: 0.8778\n",
      "Epoch 144/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9041 - val_loss: 0.0923 - val_acc: 0.8838\n",
      "Epoch 145/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9025 - val_loss: 0.0928 - val_acc: 0.8809\n",
      "Epoch 146/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9035 - val_loss: 0.0956 - val_acc: 0.8699\n",
      "Epoch 147/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9033 - val_loss: 0.0944 - val_acc: 0.8751\n",
      "Epoch 148/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9036 - val_loss: 0.0957 - val_acc: 0.8767\n",
      "Epoch 149/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9042 - val_loss: 0.0940 - val_acc: 0.8691\n",
      "Epoch 150/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9023 - val_loss: 0.0928 - val_acc: 0.8849\n",
      "Epoch 151/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9037 - val_loss: 0.0969 - val_acc: 0.8757\n",
      "Epoch 152/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9037 - val_loss: 0.0955 - val_acc: 0.8691\n",
      "Epoch 153/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0741 - acc: 0.9036 - val_loss: 0.0936 - val_acc: 0.8846\n",
      "Epoch 154/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9032 - val_loss: 0.0936 - val_acc: 0.8846\n",
      "Epoch 155/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9029 - val_loss: 0.0949 - val_acc: 0.8749\n",
      "Epoch 156/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9049 - val_loss: 0.0955 - val_acc: 0.8764\n",
      "Epoch 157/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9037 - val_loss: 0.0941 - val_acc: 0.8767\n",
      "Epoch 158/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9032 - val_loss: 0.0939 - val_acc: 0.8822\n",
      "Epoch 159/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9038 - val_loss: 0.0927 - val_acc: 0.8846\n",
      "Epoch 160/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9027 - val_loss: 0.0956 - val_acc: 0.8759\n",
      "Epoch 161/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9049 - val_loss: 0.0938 - val_acc: 0.8822\n",
      "Epoch 162/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9044 - val_loss: 0.0944 - val_acc: 0.8762\n",
      "Epoch 163/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9041 - val_loss: 0.0936 - val_acc: 0.8841\n",
      "Epoch 164/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9038 - val_loss: 0.0947 - val_acc: 0.8754\n",
      "Epoch 165/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9023 - val_loss: 0.0948 - val_acc: 0.8762\n",
      "Epoch 166/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9027 - val_loss: 0.0960 - val_acc: 0.8746\n",
      "Epoch 167/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9041 - val_loss: 0.0955 - val_acc: 0.8688\n",
      "Epoch 168/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9027 - val_loss: 0.0944 - val_acc: 0.8759\n",
      "Epoch 169/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0966 - val_acc: 0.8707\n",
      "Epoch 170/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9036 - val_loss: 0.0951 - val_acc: 0.8678\n",
      "Epoch 171/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9027 - val_loss: 0.0950 - val_acc: 0.8656\n",
      "Epoch 172/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9023 - val_loss: 0.0956 - val_acc: 0.8675\n",
      "Epoch 173/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9042 - val_loss: 0.0975 - val_acc: 0.8749\n",
      "Epoch 174/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9031 - val_loss: 0.0940 - val_acc: 0.8670\n",
      "Epoch 175/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9038 - val_loss: 0.0969 - val_acc: 0.8680\n",
      "Epoch 176/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9031 - val_loss: 0.0961 - val_acc: 0.8672\n",
      "Epoch 177/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9029 - val_loss: 0.0943 - val_acc: 0.8764\n",
      "Epoch 178/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9025 - val_loss: 0.0984 - val_acc: 0.8609\n",
      "Epoch 179/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9037 - val_loss: 0.0977 - val_acc: 0.8601\n",
      "Epoch 180/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0946 - val_acc: 0.8751\n",
      "Epoch 181/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0740 - acc: 0.9035 - val_loss: 0.0943 - val_acc: 0.8751\n",
      "Epoch 182/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0948 - val_acc: 0.8751\n",
      "Epoch 183/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0971 - val_acc: 0.8596\n",
      "Epoch 184/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9020 - val_loss: 0.0940 - val_acc: 0.8749\n",
      "Epoch 185/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9045 - val_loss: 0.0959 - val_acc: 0.8667\n",
      "Epoch 186/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9048 - val_loss: 0.0945 - val_acc: 0.8757\n",
      "Epoch 187/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9048 - val_loss: 0.0939 - val_acc: 0.8749\n",
      "Epoch 188/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9029 - val_loss: 0.0950 - val_acc: 0.8675\n",
      "Epoch 189/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9033 - val_loss: 0.0967 - val_acc: 0.8609\n",
      "Epoch 190/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9035 - val_loss: 0.0951 - val_acc: 0.8749\n",
      "Epoch 191/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9027 - val_loss: 0.0959 - val_acc: 0.8606\n",
      "Epoch 192/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9027 - val_loss: 0.0959 - val_acc: 0.8609\n",
      "Epoch 193/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0961 - val_acc: 0.8609\n",
      "Epoch 194/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0956 - val_acc: 0.8751\n",
      "Epoch 195/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9027 - val_loss: 0.0959 - val_acc: 0.8599\n",
      "Epoch 196/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9028 - val_loss: 0.0973 - val_acc: 0.8609\n",
      "Epoch 197/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9036 - val_loss: 0.0980 - val_acc: 0.8614\n",
      "Epoch 198/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9020 - val_loss: 0.0967 - val_acc: 0.8612\n",
      "Epoch 199/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0952 - val_acc: 0.8751\n",
      "Epoch 200/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9015 - val_loss: 0.0976 - val_acc: 0.8670\n",
      "Epoch 201/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9041 - val_loss: 0.0957 - val_acc: 0.8683\n",
      "Epoch 202/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9046 - val_loss: 0.0972 - val_acc: 0.8580\n",
      "Epoch 203/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9033 - val_loss: 0.0949 - val_acc: 0.8749\n",
      "Epoch 204/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0961 - val_acc: 0.8693\n",
      "Epoch 205/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0979 - val_acc: 0.8604\n",
      "Epoch 206/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9048 - val_loss: 0.0940 - val_acc: 0.8738\n",
      "Epoch 207/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9031 - val_loss: 0.0962 - val_acc: 0.8588\n",
      "Epoch 208/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9024 - val_loss: 0.0964 - val_acc: 0.8606\n",
      "Epoch 209/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0960 - val_acc: 0.8693\n",
      "Epoch 210/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0967 - val_acc: 0.8606\n",
      "Epoch 211/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9027 - val_loss: 0.0978 - val_acc: 0.8609\n",
      "Epoch 212/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9037 - val_loss: 0.0971 - val_acc: 0.8593\n",
      "Epoch 213/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0983 - val_acc: 0.8612\n",
      "Epoch 214/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9023 - val_loss: 0.0971 - val_acc: 0.8614\n",
      "Epoch 215/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9040 - val_loss: 0.0954 - val_acc: 0.8680\n",
      "Epoch 216/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9041 - val_loss: 0.0955 - val_acc: 0.8667\n",
      "Epoch 217/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0977 - val_acc: 0.8601\n",
      "Epoch 218/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0946 - val_acc: 0.8672\n",
      "Epoch 219/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0971 - val_acc: 0.8604\n",
      "Epoch 220/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0975 - val_acc: 0.8609\n",
      "Epoch 221/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9025 - val_loss: 0.0960 - val_acc: 0.8680\n",
      "Epoch 222/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9027 - val_loss: 0.0980 - val_acc: 0.8606\n",
      "Epoch 223/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0987 - val_acc: 0.8606\n",
      "Epoch 224/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0966 - val_acc: 0.8693\n",
      "Epoch 225/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0972 - val_acc: 0.8606\n",
      "Epoch 226/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0972 - val_acc: 0.8593\n",
      "Epoch 227/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0968 - val_acc: 0.8601\n",
      "Epoch 228/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0946 - val_acc: 0.8754\n",
      "Epoch 229/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9020 - val_loss: 0.0989 - val_acc: 0.8664\n",
      "Epoch 230/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0963 - val_acc: 0.8664\n",
      "Epoch 231/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0966 - val_acc: 0.8659\n",
      "Epoch 232/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0981 - val_acc: 0.8612\n",
      "Epoch 233/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0965 - val_acc: 0.8688\n",
      "Epoch 234/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0957 - val_acc: 0.8754\n",
      "Epoch 235/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9044 - val_loss: 0.0977 - val_acc: 0.8593\n",
      "Epoch 236/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0958 - val_acc: 0.8754\n",
      "Epoch 237/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0954 - val_acc: 0.8757\n",
      "Epoch 238/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0983 - val_acc: 0.8606\n",
      "Epoch 239/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0995 - val_acc: 0.8670\n",
      "Epoch 240/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0967 - val_acc: 0.8670\n",
      "Epoch 241/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0965 - val_acc: 0.8751\n",
      "Epoch 242/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0965 - val_acc: 0.8757\n",
      "Epoch 243/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9017 - val_loss: 0.0964 - val_acc: 0.8683\n",
      "Epoch 244/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0978 - val_acc: 0.8604\n",
      "Epoch 245/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1006 - val_acc: 0.8596\n",
      "Epoch 246/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0995 - val_acc: 0.8620\n",
      "Epoch 247/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9033 - val_loss: 0.0980 - val_acc: 0.8609\n",
      "Epoch 248/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0977 - val_acc: 0.8670\n",
      "Epoch 249/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0970 - val_acc: 0.8606\n",
      "Epoch 250/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0971 - val_acc: 0.8612\n",
      "Epoch 251/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0968 - val_acc: 0.8651\n",
      "Epoch 252/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9028 - val_loss: 0.0992 - val_acc: 0.8670\n",
      "Epoch 253/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0987 - val_acc: 0.8601\n",
      "Epoch 254/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0965 - val_acc: 0.8678\n",
      "Epoch 255/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9027 - val_loss: 0.0970 - val_acc: 0.8675\n",
      "Epoch 256/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0956 - val_acc: 0.8683\n",
      "Epoch 257/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9024 - val_loss: 0.0977 - val_acc: 0.8596\n",
      "Epoch 258/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0973 - val_acc: 0.8693\n",
      "Epoch 259/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0984 - val_acc: 0.8599\n",
      "Epoch 260/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0970 - val_acc: 0.8664\n",
      "Epoch 261/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9032 - val_loss: 0.0980 - val_acc: 0.8591\n",
      "Epoch 262/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0985 - val_acc: 0.8612\n",
      "Epoch 263/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0982 - val_acc: 0.8696\n",
      "Epoch 264/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0982 - val_acc: 0.8683\n",
      "Epoch 265/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9042 - val_loss: 0.0979 - val_acc: 0.8606\n",
      "Epoch 266/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0986 - val_acc: 0.8609\n",
      "Epoch 267/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0996 - val_acc: 0.8620\n",
      "Epoch 268/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0973 - val_acc: 0.8754\n",
      "Epoch 269/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0983 - val_acc: 0.8606\n",
      "Epoch 270/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0985 - val_acc: 0.8580\n",
      "Epoch 271/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9021 - val_loss: 0.0976 - val_acc: 0.8743\n",
      "Epoch 272/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0979 - val_acc: 0.8693\n",
      "Epoch 273/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0992 - val_acc: 0.8617\n",
      "Epoch 274/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9023 - val_loss: 0.0997 - val_acc: 0.8659\n",
      "Epoch 275/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9031 - val_loss: 0.1006 - val_acc: 0.8609\n",
      "Epoch 276/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0980 - val_acc: 0.8738\n",
      "Epoch 277/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0989 - val_acc: 0.8596\n",
      "Epoch 278/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9021 - val_loss: 0.0973 - val_acc: 0.8736\n",
      "Epoch 279/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0984 - val_acc: 0.8688\n",
      "Epoch 280/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1005 - val_acc: 0.8614\n",
      "Epoch 281/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9021 - val_loss: 0.0991 - val_acc: 0.8606\n",
      "Epoch 282/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0986 - val_acc: 0.8659\n",
      "Epoch 283/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0995 - val_acc: 0.8622\n",
      "Epoch 284/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9023 - val_loss: 0.0970 - val_acc: 0.8741\n",
      "Epoch 285/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9024 - val_loss: 0.0987 - val_acc: 0.8656\n",
      "Epoch 286/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0986 - val_acc: 0.8596\n",
      "Epoch 287/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9054 - val_loss: 0.1002 - val_acc: 0.8617\n",
      "Epoch 288/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0974 - val_acc: 0.8749\n",
      "Epoch 289/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0990 - val_acc: 0.8612\n",
      "Epoch 290/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0996 - val_acc: 0.8662\n",
      "Epoch 291/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0984 - val_acc: 0.8591\n",
      "Epoch 292/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0986 - val_acc: 0.8696\n",
      "Epoch 293/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0985 - val_acc: 0.8591\n",
      "Epoch 294/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9027 - val_loss: 0.0992 - val_acc: 0.8701\n",
      "Epoch 295/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 296/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0987 - val_acc: 0.8659\n",
      "Epoch 297/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0998 - val_acc: 0.8614\n",
      "Epoch 298/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9037 - val_loss: 0.0988 - val_acc: 0.8596\n",
      "Epoch 299/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0990 - val_acc: 0.8612\n",
      "Epoch 300/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9021 - val_loss: 0.0984 - val_acc: 0.8575\n",
      "Epoch 301/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9028 - val_loss: 0.1014 - val_acc: 0.8628\n",
      "Epoch 302/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0984 - val_acc: 0.8675\n",
      "Epoch 303/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0997 - val_acc: 0.8599\n",
      "Epoch 304/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0985 - val_acc: 0.8591\n",
      "Epoch 305/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0982 - val_acc: 0.8688\n",
      "Epoch 306/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1014 - val_acc: 0.8664\n",
      "Epoch 307/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0980 - val_acc: 0.8749\n",
      "Epoch 308/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0996 - val_acc: 0.8617\n",
      "Epoch 309/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9048 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 310/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9041 - val_loss: 0.0992 - val_acc: 0.8606\n",
      "Epoch 311/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1002 - val_acc: 0.8614\n",
      "Epoch 312/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0983 - val_acc: 0.8667\n",
      "Epoch 313/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1006 - val_acc: 0.8620\n",
      "Epoch 314/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8609\n",
      "Epoch 315/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1018 - val_acc: 0.8593\n",
      "Epoch 316/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1027 - val_acc: 0.8606\n",
      "Epoch 317/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0995 - val_acc: 0.8617\n",
      "Epoch 318/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0980 - val_acc: 0.8685\n",
      "Epoch 319/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.1008 - val_acc: 0.8612\n",
      "Epoch 320/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0991 - val_acc: 0.8583\n",
      "Epoch 321/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8591\n",
      "Epoch 322/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9021 - val_loss: 0.0986 - val_acc: 0.8675\n",
      "Epoch 323/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0988 - val_acc: 0.8696\n",
      "Epoch 324/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0969 - val_acc: 0.8738\n",
      "Epoch 325/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0983 - val_acc: 0.8683\n",
      "Epoch 326/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0985 - val_acc: 0.8596\n",
      "Epoch 327/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0998 - val_acc: 0.8617\n",
      "Epoch 328/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.1000 - val_acc: 0.8593\n",
      "Epoch 329/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0989 - val_acc: 0.8683\n",
      "Epoch 330/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0991 - val_acc: 0.8583\n",
      "Epoch 331/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0996 - val_acc: 0.8614\n",
      "Epoch 332/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0983 - val_acc: 0.8593\n",
      "Epoch 333/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0986 - val_acc: 0.8672\n",
      "Epoch 334/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1008 - val_acc: 0.8609\n",
      "Epoch 335/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9024 - val_loss: 0.0991 - val_acc: 0.8606\n",
      "Epoch 336/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1014 - val_acc: 0.8609\n",
      "Epoch 337/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0986 - val_acc: 0.8609\n",
      "Epoch 338/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0980 - val_acc: 0.8670\n",
      "Epoch 339/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.1010 - val_acc: 0.8609\n",
      "Epoch 340/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0984 - val_acc: 0.8685\n",
      "Epoch 341/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9032 - val_loss: 0.0968 - val_acc: 0.8736\n",
      "Epoch 342/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0989 - val_acc: 0.8599\n",
      "Epoch 343/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1016 - val_acc: 0.8591\n",
      "Epoch 344/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.1004 - val_acc: 0.8599\n",
      "Epoch 345/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0990 - val_acc: 0.8580\n",
      "Epoch 346/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0985 - val_acc: 0.8685\n",
      "Epoch 347/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0990 - val_acc: 0.8667\n",
      "Epoch 348/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0974 - val_acc: 0.8743\n",
      "Epoch 349/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0981 - val_acc: 0.8670\n",
      "Epoch 350/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1015 - val_acc: 0.8614\n",
      "Epoch 351/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0977 - val_acc: 0.8685\n",
      "Epoch 352/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0972 - val_acc: 0.8741\n",
      "Epoch 353/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1025 - val_acc: 0.8604\n",
      "Epoch 354/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.1006 - val_acc: 0.8622\n",
      "Epoch 355/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0997 - val_acc: 0.8612\n",
      "Epoch 356/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0997 - val_acc: 0.8622\n",
      "Epoch 357/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1004 - val_acc: 0.8591\n",
      "Epoch 358/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1002 - val_acc: 0.8599\n",
      "Epoch 359/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1009 - val_acc: 0.8628\n",
      "Epoch 360/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0991 - val_acc: 0.8593\n",
      "Epoch 361/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0996 - val_acc: 0.8614\n",
      "Epoch 362/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 363/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.1004 - val_acc: 0.8585\n",
      "Epoch 364/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0989 - val_acc: 0.8591\n",
      "Epoch 365/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0979 - val_acc: 0.8743\n",
      "Epoch 366/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0993 - val_acc: 0.8593\n",
      "Epoch 367/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0989 - val_acc: 0.8601\n",
      "Epoch 368/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0983 - val_acc: 0.8680\n",
      "Epoch 369/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0982 - val_acc: 0.8675\n",
      "Epoch 370/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0985 - val_acc: 0.8691\n",
      "Epoch 371/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0982 - val_acc: 0.8664\n",
      "Epoch 372/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0994 - val_acc: 0.8664\n",
      "Epoch 373/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1004 - val_acc: 0.8596\n",
      "Epoch 374/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1002 - val_acc: 0.8606\n",
      "Epoch 375/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.1014 - val_acc: 0.8625\n",
      "Epoch 376/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.1005 - val_acc: 0.8601\n",
      "Epoch 377/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0991 - val_acc: 0.8596\n",
      "Epoch 378/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1005 - val_acc: 0.8622\n",
      "Epoch 379/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0969 - val_acc: 0.8741\n",
      "Epoch 380/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1033 - val_acc: 0.8617\n",
      "Epoch 381/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0974 - val_acc: 0.8691\n",
      "Epoch 382/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 383/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0996 - val_acc: 0.8675\n",
      "Epoch 384/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0993 - val_acc: 0.8588\n",
      "Epoch 385/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8591\n",
      "Epoch 386/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9033 - val_loss: 0.0992 - val_acc: 0.8646\n",
      "Epoch 387/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.1006 - val_acc: 0.8625\n",
      "Epoch 388/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0996 - val_acc: 0.8701\n",
      "Epoch 389/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1015 - val_acc: 0.8617\n",
      "Epoch 390/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.1001 - val_acc: 0.8604\n",
      "Epoch 391/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1010 - val_acc: 0.8609\n",
      "Epoch 392/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0999 - val_acc: 0.8656\n",
      "Epoch 393/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0990 - val_acc: 0.8699\n",
      "Epoch 394/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0983 - val_acc: 0.8741\n",
      "Epoch 395/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0991 - val_acc: 0.8691\n",
      "Epoch 396/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8683\n",
      "Epoch 397/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0988 - val_acc: 0.8596\n",
      "Epoch 398/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0987 - val_acc: 0.8599\n",
      "Epoch 399/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0981 - val_acc: 0.8722\n",
      "Epoch 400/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9032 - val_loss: 0.0980 - val_acc: 0.8675\n",
      "Epoch 401/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9036 - val_loss: 0.1001 - val_acc: 0.8599\n",
      "Epoch 402/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0994 - val_acc: 0.8609\n",
      "Epoch 403/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1001 - val_acc: 0.8612\n",
      "Epoch 404/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0988 - val_acc: 0.8738\n",
      "Epoch 405/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1003 - val_acc: 0.8591\n",
      "Epoch 406/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.1029 - val_acc: 0.8630\n",
      "Epoch 407/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9019 - val_loss: 0.0987 - val_acc: 0.8738\n",
      "Epoch 408/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1012 - val_acc: 0.8617\n",
      "Epoch 409/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0983 - val_acc: 0.8683\n",
      "Epoch 410/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0986 - val_acc: 0.8688\n",
      "Epoch 411/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0982 - val_acc: 0.8701\n",
      "Epoch 412/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9056 - val_loss: 0.0981 - val_acc: 0.8685\n",
      "Epoch 413/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0987 - val_acc: 0.8685\n",
      "Epoch 414/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9019 - val_loss: 0.0979 - val_acc: 0.8683\n",
      "Epoch 415/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0980 - val_acc: 0.8667\n",
      "Epoch 416/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0983 - val_acc: 0.8680\n",
      "Epoch 417/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 418/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0993 - val_acc: 0.8609\n",
      "Epoch 419/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0995 - val_acc: 0.8693\n",
      "Epoch 420/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0993 - val_acc: 0.8601\n",
      "Epoch 421/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0994 - val_acc: 0.8693\n",
      "Epoch 422/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0983 - val_acc: 0.8678\n",
      "Epoch 423/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0993 - val_acc: 0.8588\n",
      "Epoch 424/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.1020 - val_acc: 0.8620\n",
      "Epoch 425/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.1007 - val_acc: 0.8614\n",
      "Epoch 426/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0974 - val_acc: 0.8683\n",
      "Epoch 427/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0996 - val_acc: 0.8614\n",
      "Epoch 428/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1003 - val_acc: 0.8612\n",
      "Epoch 429/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0990 - val_acc: 0.8675\n",
      "Epoch 430/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.1012 - val_acc: 0.8596\n",
      "Epoch 431/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0990 - val_acc: 0.8693\n",
      "Epoch 432/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0992 - val_acc: 0.8591\n",
      "Epoch 433/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0979 - val_acc: 0.8680\n",
      "Epoch 434/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0989 - val_acc: 0.8680\n",
      "Epoch 435/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0991 - val_acc: 0.8591\n",
      "Epoch 436/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1004 - val_acc: 0.8620\n",
      "Epoch 437/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1003 - val_acc: 0.8599\n",
      "Epoch 438/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1032 - val_acc: 0.8606\n",
      "Epoch 439/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 440/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1002 - val_acc: 0.8593\n",
      "Epoch 441/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8601\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0983 - val_acc: 0.8738\n",
      "Epoch 443/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0994 - val_acc: 0.8667\n",
      "Epoch 444/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 445/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0984 - val_acc: 0.8696\n",
      "Epoch 446/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0996 - val_acc: 0.8612\n",
      "Epoch 447/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1004 - val_acc: 0.8617\n",
      "Epoch 448/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0994 - val_acc: 0.8609\n",
      "Epoch 449/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0987 - val_acc: 0.8596\n",
      "Epoch 450/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9050 - val_loss: 0.1032 - val_acc: 0.8609\n",
      "Epoch 451/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0981 - val_acc: 0.8667\n",
      "Epoch 452/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1020 - val_acc: 0.8599\n",
      "Epoch 453/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0989 - val_acc: 0.8601\n",
      "Epoch 454/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0999 - val_acc: 0.8599\n",
      "Epoch 455/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.1007 - val_acc: 0.8622\n",
      "Epoch 456/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8593\n",
      "Epoch 457/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0991 - val_acc: 0.8596\n",
      "Epoch 458/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1005 - val_acc: 0.8614\n",
      "Epoch 459/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0984 - val_acc: 0.8672\n",
      "Epoch 460/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1015 - val_acc: 0.8585\n",
      "Epoch 461/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9057 - val_loss: 0.0995 - val_acc: 0.8612\n",
      "Epoch 462/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0996 - val_acc: 0.8604\n",
      "Epoch 463/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.1000 - val_acc: 0.8609\n",
      "Epoch 464/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0990 - val_acc: 0.8693\n",
      "Epoch 465/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 466/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0994 - val_acc: 0.8601\n",
      "Epoch 467/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0977 - val_acc: 0.8670\n",
      "Epoch 468/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0989 - val_acc: 0.8599\n",
      "Epoch 469/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0997 - val_acc: 0.8614\n",
      "Epoch 470/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0996 - val_acc: 0.8622\n",
      "Epoch 471/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0997 - val_acc: 0.8606\n",
      "Epoch 472/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 473/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0983 - val_acc: 0.8680\n",
      "Epoch 474/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9053 - val_loss: 0.0999 - val_acc: 0.8617\n",
      "Epoch 475/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0987 - val_acc: 0.8591\n",
      "Epoch 476/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0980 - val_acc: 0.8683\n",
      "Epoch 477/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0976 - val_acc: 0.8688\n",
      "Epoch 478/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0988 - val_acc: 0.8691\n",
      "Epoch 479/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1004 - val_acc: 0.8588\n",
      "Epoch 480/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0993 - val_acc: 0.8696\n",
      "Epoch 481/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0979 - val_acc: 0.8659\n",
      "Epoch 482/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0988 - val_acc: 0.8675\n",
      "Epoch 483/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9060 - val_loss: 0.0982 - val_acc: 0.8701\n",
      "Epoch 484/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0980 - val_acc: 0.8688\n",
      "Epoch 485/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0991 - val_acc: 0.8604\n",
      "Epoch 486/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.1017 - val_acc: 0.8599\n",
      "Epoch 487/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9052 - val_loss: 0.0980 - val_acc: 0.8675\n",
      "Epoch 488/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0973 - val_acc: 0.8693\n",
      "Epoch 489/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8659\n",
      "Epoch 490/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0985 - val_acc: 0.8672\n",
      "Epoch 491/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.1004 - val_acc: 0.8593\n",
      "Epoch 492/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1021 - val_acc: 0.8622\n",
      "Epoch 493/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1013 - val_acc: 0.8604\n",
      "Epoch 494/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9024 - val_loss: 0.1001 - val_acc: 0.8601\n",
      "Epoch 495/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0979 - val_acc: 0.8749\n",
      "Epoch 496/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0973 - val_acc: 0.8749\n",
      "Epoch 497/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9020 - val_loss: 0.0990 - val_acc: 0.8596\n",
      "Epoch 498/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0995 - val_acc: 0.8614\n",
      "Epoch 499/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0991 - val_acc: 0.8667\n",
      "Epoch 500/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0998 - val_acc: 0.8707\n",
      "Epoch 501/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0987 - val_acc: 0.8693\n",
      "Epoch 502/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0992 - val_acc: 0.8591\n",
      "Epoch 503/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1000 - val_acc: 0.8580\n",
      "Epoch 504/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0993 - val_acc: 0.8601\n",
      "Epoch 505/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0990 - val_acc: 0.8588\n",
      "Epoch 506/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0980 - val_acc: 0.8670\n",
      "Epoch 507/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.1012 - val_acc: 0.8596\n",
      "Epoch 508/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0998 - val_acc: 0.8593\n",
      "Epoch 509/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9027 - val_loss: 0.0987 - val_acc: 0.8685\n",
      "Epoch 510/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1007 - val_acc: 0.8606\n",
      "Epoch 511/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9024 - val_loss: 0.0993 - val_acc: 0.8604\n",
      "Epoch 512/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0982 - val_acc: 0.8667\n",
      "Epoch 513/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0973 - val_acc: 0.8738\n",
      "Epoch 514/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9041 - val_loss: 0.0998 - val_acc: 0.8599\n",
      "Epoch 515/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0993 - val_acc: 0.8604\n",
      "Epoch 516/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0990 - val_acc: 0.8672\n",
      "Epoch 517/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8591\n",
      "Epoch 518/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1011 - val_acc: 0.8620\n",
      "Epoch 519/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0982 - val_acc: 0.8733\n",
      "Epoch 520/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0998 - val_acc: 0.8601\n",
      "Epoch 521/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0997 - val_acc: 0.8599\n",
      "Epoch 522/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1012 - val_acc: 0.8599\n",
      "Epoch 523/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1004 - val_acc: 0.8593\n",
      "Epoch 524/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1006 - val_acc: 0.8606\n",
      "Epoch 525/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0992 - val_acc: 0.8601\n",
      "Epoch 526/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0988 - val_acc: 0.8675\n",
      "Epoch 527/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0988 - val_acc: 0.8599\n",
      "Epoch 528/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0996 - val_acc: 0.8604\n",
      "Epoch 529/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0991 - val_acc: 0.8580\n",
      "Epoch 530/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1004 - val_acc: 0.8591\n",
      "Epoch 531/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1006 - val_acc: 0.8599\n",
      "Epoch 532/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0998 - val_acc: 0.8596\n",
      "Epoch 533/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1010 - val_acc: 0.8614\n",
      "Epoch 534/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0981 - val_acc: 0.8678\n",
      "Epoch 535/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1021 - val_acc: 0.8593\n",
      "Epoch 536/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0997 - val_acc: 0.8593\n",
      "Epoch 537/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0984 - val_acc: 0.8688\n",
      "Epoch 538/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1000 - val_acc: 0.8696\n",
      "Epoch 539/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0995 - val_acc: 0.8585\n",
      "Epoch 540/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0995 - val_acc: 0.8601\n",
      "Epoch 541/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0991 - val_acc: 0.8606\n",
      "Epoch 542/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0989 - val_acc: 0.8601\n",
      "Epoch 543/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0981 - val_acc: 0.8685\n",
      "Epoch 544/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0990 - val_acc: 0.8609\n",
      "Epoch 545/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.1016 - val_acc: 0.8622\n",
      "Epoch 546/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1013 - val_acc: 0.8628\n",
      "Epoch 547/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.1012 - val_acc: 0.8625\n",
      "Epoch 548/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.1003 - val_acc: 0.8596\n",
      "Epoch 549/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0989 - val_acc: 0.8601\n",
      "Epoch 550/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 551/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0975 - val_acc: 0.8678\n",
      "Epoch 552/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0985 - val_acc: 0.8691\n",
      "Epoch 553/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0989 - val_acc: 0.8691\n",
      "Epoch 554/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0986 - val_acc: 0.8691\n",
      "Epoch 555/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0983 - val_acc: 0.8667\n",
      "Epoch 556/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9053 - val_loss: 0.1005 - val_acc: 0.8599\n",
      "Epoch 557/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0993 - val_acc: 0.8604\n",
      "Epoch 558/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0974 - val_acc: 0.8685\n",
      "Epoch 559/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1006 - val_acc: 0.8604\n",
      "Epoch 560/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0988 - val_acc: 0.8688\n",
      "Epoch 561/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0979 - val_acc: 0.8680\n",
      "Epoch 562/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1002 - val_acc: 0.8614\n",
      "Epoch 563/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0996 - val_acc: 0.8591\n",
      "Epoch 564/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9065 - val_loss: 0.0989 - val_acc: 0.8675\n",
      "Epoch 565/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0993 - val_acc: 0.8604\n",
      "Epoch 566/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0995 - val_acc: 0.8612\n",
      "Epoch 567/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0977 - val_acc: 0.8683\n",
      "Epoch 568/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0990 - val_acc: 0.8585\n",
      "Epoch 569/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0988 - val_acc: 0.8688\n",
      "Epoch 570/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0975 - val_acc: 0.8738\n",
      "Epoch 571/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0995 - val_acc: 0.8599\n",
      "Epoch 572/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0994 - val_acc: 0.8612\n",
      "Epoch 573/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0983 - val_acc: 0.8675\n",
      "Epoch 574/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0983 - val_acc: 0.8672\n",
      "Epoch 575/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0989 - val_acc: 0.8691\n",
      "Epoch 576/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8693\n",
      "Epoch 577/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.1001 - val_acc: 0.8617\n",
      "Epoch 578/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0991 - val_acc: 0.8599\n",
      "Epoch 579/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.1000 - val_acc: 0.8612\n",
      "Epoch 580/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8693\n",
      "Epoch 581/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1014 - val_acc: 0.8614\n",
      "Epoch 582/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0996 - val_acc: 0.8604\n",
      "Epoch 583/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8601\n",
      "Epoch 584/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9049 - val_loss: 0.0970 - val_acc: 0.8685\n",
      "Epoch 585/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.1000 - val_acc: 0.8612\n",
      "Epoch 586/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.1005 - val_acc: 0.8601\n",
      "Epoch 587/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0986 - val_acc: 0.8591\n",
      "Epoch 588/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0998 - val_acc: 0.8601\n",
      "Epoch 589/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0992 - val_acc: 0.8609\n",
      "Epoch 590/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.1024 - val_acc: 0.8617\n",
      "Epoch 591/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0993 - val_acc: 0.8596\n",
      "Epoch 592/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1034 - val_acc: 0.8628\n",
      "Epoch 593/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0994 - val_acc: 0.8696\n",
      "Epoch 594/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0985 - val_acc: 0.8688\n",
      "Epoch 595/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0997 - val_acc: 0.8704\n",
      "Epoch 596/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0988 - val_acc: 0.8596\n",
      "Epoch 597/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0988 - val_acc: 0.8583\n",
      "Epoch 598/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.1016 - val_acc: 0.8617\n",
      "Epoch 599/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1003 - val_acc: 0.8596\n",
      "Epoch 600/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.1001 - val_acc: 0.8591\n",
      "Epoch 601/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0975 - val_acc: 0.8656\n",
      "Epoch 602/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9056 - val_loss: 0.1000 - val_acc: 0.8622\n",
      "Epoch 603/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0997 - val_acc: 0.8617\n",
      "Epoch 604/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0985 - val_acc: 0.8675\n",
      "Epoch 605/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0988 - val_acc: 0.8685\n",
      "Epoch 606/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9048 - val_loss: 0.0999 - val_acc: 0.8614\n",
      "Epoch 607/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 608/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0982 - val_acc: 0.8738\n",
      "Epoch 609/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0996 - val_acc: 0.8593\n",
      "Epoch 610/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0992 - val_acc: 0.8612\n",
      "Epoch 611/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0987 - val_acc: 0.8688\n",
      "Epoch 612/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1006 - val_acc: 0.8609\n",
      "Epoch 613/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0998 - val_acc: 0.8599\n",
      "Epoch 614/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1010 - val_acc: 0.8606\n",
      "Epoch 615/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0990 - val_acc: 0.8604\n",
      "Epoch 616/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8591\n",
      "Epoch 617/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.0992 - val_acc: 0.8601\n",
      "Epoch 618/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9023 - val_loss: 0.0979 - val_acc: 0.8667\n",
      "Epoch 619/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.1005 - val_acc: 0.8604\n",
      "Epoch 620/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.1006 - val_acc: 0.8614\n",
      "Epoch 621/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0992 - val_acc: 0.8606\n",
      "Epoch 622/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0991 - val_acc: 0.8699\n",
      "Epoch 623/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0997 - val_acc: 0.8580\n",
      "Epoch 624/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1002 - val_acc: 0.8585\n",
      "Epoch 625/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0986 - val_acc: 0.8678\n",
      "Epoch 626/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0993 - val_acc: 0.8612\n",
      "Epoch 627/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0987 - val_acc: 0.8691\n",
      "Epoch 628/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0988 - val_acc: 0.8580\n",
      "Epoch 629/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0990 - val_acc: 0.8609\n",
      "Epoch 630/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0983 - val_acc: 0.8672\n",
      "Epoch 631/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0991 - val_acc: 0.8606\n",
      "Epoch 632/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.0993 - val_acc: 0.8596\n",
      "Epoch 633/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0984 - val_acc: 0.8691\n",
      "Epoch 634/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1002 - val_acc: 0.8620\n",
      "Epoch 635/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0991 - val_acc: 0.8691\n",
      "Epoch 636/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0977 - val_acc: 0.8688\n",
      "Epoch 637/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1004 - val_acc: 0.8609\n",
      "Epoch 638/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1006 - val_acc: 0.8604\n",
      "Epoch 639/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0992 - val_acc: 0.8601\n",
      "Epoch 640/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1000 - val_acc: 0.8707\n",
      "Epoch 641/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0970 - val_acc: 0.8738\n",
      "Epoch 642/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.1012 - val_acc: 0.8614\n",
      "Epoch 643/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1013 - val_acc: 0.8606\n",
      "Epoch 644/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1021 - val_acc: 0.8614\n",
      "Epoch 645/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0996 - val_acc: 0.8614\n",
      "Epoch 646/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.1009 - val_acc: 0.8628\n",
      "Epoch 647/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9035 - val_loss: 0.1005 - val_acc: 0.86170.8\n",
      "Epoch 648/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0989 - val_acc: 0.8670\n",
      "Epoch 649/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1006 - val_acc: 0.8606\n",
      "Epoch 650/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0985 - val_acc: 0.8691\n",
      "Epoch 651/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0979 - val_acc: 0.8664\n",
      "Epoch 652/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0987 - val_acc: 0.8601\n",
      "Epoch 653/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0975 - val_acc: 0.8662\n",
      "Epoch 654/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1003 - val_acc: 0.8609\n",
      "Epoch 655/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0991 - val_acc: 0.8604\n",
      "Epoch 656/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0981 - val_acc: 0.8664\n",
      "Epoch 657/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 658/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0995 - val_acc: 0.8601\n",
      "Epoch 659/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0992 - val_acc: 0.8675\n",
      "Epoch 660/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.1035 - val_acc: 0.8625\n",
      "Epoch 661/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0993 - val_acc: 0.8614\n",
      "Epoch 662/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1007 - val_acc: 0.8614\n",
      "Epoch 663/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0996 - val_acc: 0.8614\n",
      "Epoch 664/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1002 - val_acc: 0.8612\n",
      "Epoch 665/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0984 - val_acc: 0.8699\n",
      "Epoch 666/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0997 - val_acc: 0.8588\n",
      "Epoch 667/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0989 - val_acc: 0.8588\n",
      "Epoch 668/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1005 - val_acc: 0.8606\n",
      "Epoch 669/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0998 - val_acc: 0.8617\n",
      "Epoch 670/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0993 - val_acc: 0.8606\n",
      "Epoch 671/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0986 - val_acc: 0.8667\n",
      "Epoch 672/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0978 - val_acc: 0.8680\n",
      "Epoch 673/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9025 - val_loss: 0.0991 - val_acc: 0.8596\n",
      "Epoch 674/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0990 - val_acc: 0.8691\n",
      "Epoch 675/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0993 - val_acc: 0.8604\n",
      "Epoch 676/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0991 - val_acc: 0.8604\n",
      "Epoch 677/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1009 - val_acc: 0.8620\n",
      "Epoch 678/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9054 - val_loss: 0.1012 - val_acc: 0.8588\n",
      "Epoch 679/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.0999 - val_acc: 0.8601\n",
      "Epoch 680/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0992 - val_acc: 0.8693\n",
      "Epoch 681/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9038 - val_loss: 0.0978 - val_acc: 0.8659\n",
      "Epoch 682/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.1007 - val_acc: 0.8625\n",
      "Epoch 683/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.1004 - val_acc: 0.8606\n",
      "Epoch 684/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0989 - val_acc: 0.8604\n",
      "Epoch 685/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1001 - val_acc: 0.8612\n",
      "Epoch 686/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0985 - val_acc: 0.8680\n",
      "Epoch 687/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0997 - val_acc: 0.8612\n",
      "Epoch 688/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.0993 - val_acc: 0.8596\n",
      "Epoch 689/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0998 - val_acc: 0.8599\n",
      "Epoch 690/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0984 - val_acc: 0.8678\n",
      "Epoch 691/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0997 - val_acc: 0.8622\n",
      "Epoch 692/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.0994 - val_acc: 0.8591\n",
      "Epoch 693/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1000 - val_acc: 0.8588\n",
      "Epoch 694/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1003 - val_acc: 0.8612\n",
      "Epoch 695/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0995 - val_acc: 0.8609\n",
      "Epoch 696/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1002 - val_acc: 0.8612\n",
      "Epoch 697/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1002 - val_acc: 0.8606\n",
      "Epoch 698/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1009 - val_acc: 0.8604\n",
      "Epoch 699/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0995 - val_acc: 0.8693\n",
      "Epoch 700/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0996 - val_acc: 0.8601\n",
      "Epoch 701/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 702/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1000 - val_acc: 0.8609\n",
      "Epoch 703/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0989 - val_acc: 0.8699\n",
      "Epoch 704/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0992 - val_acc: 0.8693\n",
      "Epoch 705/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8670\n",
      "Epoch 706/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.1025 - val_acc: 0.8630\n",
      "Epoch 707/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0992 - val_acc: 0.8593\n",
      "Epoch 708/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.0984 - val_acc: 0.8678\n",
      "Epoch 709/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0991 - val_acc: 0.8693\n",
      "Epoch 710/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0980 - val_acc: 0.8683\n",
      "Epoch 711/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0968 - val_acc: 0.8738\n",
      "Epoch 712/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1018 - val_acc: 0.8630\n",
      "Epoch 713/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0985 - val_acc: 0.8678\n",
      "Epoch 714/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1007 - val_acc: 0.8604\n",
      "Epoch 715/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0997 - val_acc: 0.8596\n",
      "Epoch 716/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1000 - val_acc: 0.8609\n",
      "Epoch 717/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9035 - val_loss: 0.0979 - val_acc: 0.8678\n",
      "Epoch 718/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0978 - val_acc: 0.8672\n",
      "Epoch 719/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9031 - val_loss: 0.1004 - val_acc: 0.8609\n",
      "Epoch 720/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0992 - val_acc: 0.8591\n",
      "Epoch 721/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1000 - val_acc: 0.8604\n",
      "Epoch 722/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0989 - val_acc: 0.8688\n",
      "Epoch 723/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9027 - val_loss: 0.0995 - val_acc: 0.8601\n",
      "Epoch 724/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0979 - val_acc: 0.8667\n",
      "Epoch 725/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1009 - val_acc: 0.8612\n",
      "Epoch 726/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.0992 - val_acc: 0.8601\n",
      "Epoch 727/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0978 - val_acc: 0.8685\n",
      "Epoch 728/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0989 - val_acc: 0.8596\n",
      "Epoch 729/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 730/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9025 - val_loss: 0.1003 - val_acc: 0.8617\n",
      "Epoch 731/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1023 - val_acc: 0.8620\n",
      "Epoch 732/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1002 - val_acc: 0.8622\n",
      "Epoch 733/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0983 - val_acc: 0.8699\n",
      "Epoch 734/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.0995 - val_acc: 0.8577\n",
      "Epoch 735/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0994 - val_acc: 0.8609\n",
      "Epoch 736/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1003 - val_acc: 0.8588\n",
      "Epoch 737/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.1011 - val_acc: 0.8633\n",
      "Epoch 738/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0998 - val_acc: 0.8712\n",
      "Epoch 739/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0978 - val_acc: 0.8664\n",
      "Epoch 740/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.1006 - val_acc: 0.8633\n",
      "Epoch 741/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.1002 - val_acc: 0.8614\n",
      "Epoch 742/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0989 - val_acc: 0.8599\n",
      "Epoch 743/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0998 - val_acc: 0.8606\n",
      "Epoch 744/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.0999 - val_acc: 0.8604\n",
      "Epoch 745/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0979 - val_acc: 0.8670\n",
      "Epoch 746/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9021 - val_loss: 0.0996 - val_acc: 0.8593\n",
      "Epoch 747/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0987 - val_acc: 0.8683\n",
      "Epoch 748/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0995 - val_acc: 0.8601\n",
      "Epoch 749/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0974 - val_acc: 0.8675\n",
      "Epoch 750/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1006 - val_acc: 0.8599\n",
      "Epoch 751/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0999 - val_acc: 0.8596\n",
      "Epoch 752/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0989 - val_acc: 0.8675\n",
      "Epoch 753/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9053 - val_loss: 0.0990 - val_acc: 0.8693\n",
      "Epoch 754/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0990 - val_acc: 0.8599\n",
      "Epoch 755/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0982 - val_acc: 0.8683\n",
      "Epoch 756/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0997 - val_acc: 0.8606\n",
      "Epoch 757/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9035 - val_loss: 0.0980 - val_acc: 0.8675\n",
      "Epoch 758/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1001 - val_acc: 0.8599\n",
      "Epoch 759/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0983 - val_acc: 0.8670\n",
      "Epoch 760/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0992 - val_acc: 0.8601\n",
      "Epoch 761/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.0983 - val_acc: 0.8672\n",
      "Epoch 762/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1004 - val_acc: 0.8614\n",
      "Epoch 763/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1002 - val_acc: 0.8612\n",
      "Epoch 764/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0998 - val_acc: 0.8577\n",
      "Epoch 765/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0996 - val_acc: 0.8599\n",
      "Epoch 766/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0984 - val_acc: 0.8664\n",
      "Epoch 767/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0980 - val_acc: 0.8685\n",
      "Epoch 768/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1007 - val_acc: 0.8622\n",
      "Epoch 769/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0988 - val_acc: 0.8685\n",
      "Epoch 770/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0991 - val_acc: 0.8693\n",
      "Epoch 771/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.1019 - val_acc: 0.8617\n",
      "Epoch 772/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.1002 - val_acc: 0.8612\n",
      "Epoch 773/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1001 - val_acc: 0.8630\n",
      "Epoch 774/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0979 - val_acc: 0.8678\n",
      "Epoch 775/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1006 - val_acc: 0.8593\n",
      "Epoch 776/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0997 - val_acc: 0.8575\n",
      "Epoch 777/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.1000 - val_acc: 0.8591\n",
      "Epoch 778/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1016 - val_acc: 0.8601\n",
      "Epoch 779/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0996 - val_acc: 0.8609\n",
      "Epoch 780/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0978 - val_acc: 0.8738\n",
      "Epoch 781/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0984 - val_acc: 0.8693\n",
      "Epoch 782/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.1012 - val_acc: 0.8633\n",
      "Epoch 783/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0991 - val_acc: 0.8688\n",
      "Epoch 784/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0992 - val_acc: 0.8691\n",
      "Epoch 785/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1016 - val_acc: 0.8612\n",
      "Epoch 786/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0985 - val_acc: 0.8736\n",
      "Epoch 787/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0989 - val_acc: 0.8678\n",
      "Epoch 788/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0998 - val_acc: 0.8620\n",
      "Epoch 789/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.1012 - val_acc: 0.8612\n",
      "Epoch 790/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0983 - val_acc: 0.8688\n",
      "Epoch 791/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0982 - val_acc: 0.8688\n",
      "Epoch 792/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0985 - val_acc: 0.8675\n",
      "Epoch 793/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9031 - val_loss: 0.0997 - val_acc: 0.8606\n",
      "Epoch 794/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0989 - val_acc: 0.8588\n",
      "Epoch 795/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.1022 - val_acc: 0.8628\n",
      "Epoch 796/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0990 - val_acc: 0.8667\n",
      "Epoch 797/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1008 - val_acc: 0.8609\n",
      "Epoch 798/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0981 - val_acc: 0.8659\n",
      "Epoch 799/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1000 - val_acc: 0.8604\n",
      "Epoch 800/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0985 - val_acc: 0.8688\n",
      "Epoch 801/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0993 - val_acc: 0.8701\n",
      "Epoch 802/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8693\n",
      "Epoch 803/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9035 - val_loss: 0.0995 - val_acc: 0.8693\n",
      "Epoch 804/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1014 - val_acc: 0.8617\n",
      "Epoch 805/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9025 - val_loss: 0.0992 - val_acc: 0.8599\n",
      "Epoch 806/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0993 - val_acc: 0.8599\n",
      "Epoch 807/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.0995 - val_acc: 0.8580\n",
      "Epoch 808/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1002 - val_acc: 0.8585\n",
      "Epoch 809/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 810/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0980 - val_acc: 0.8664\n",
      "Epoch 811/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9028 - val_loss: 0.0994 - val_acc: 0.8580\n",
      "Epoch 812/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0989 - val_acc: 0.8688\n",
      "Epoch 813/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1005 - val_acc: 0.8628\n",
      "Epoch 814/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.1015 - val_acc: 0.8614\n",
      "Epoch 815/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8612\n",
      "Epoch 816/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1007 - val_acc: 0.8622\n",
      "Epoch 817/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0975 - val_acc: 0.8754\n",
      "Epoch 818/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1008 - val_acc: 0.8596\n",
      "Epoch 819/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9052 - val_loss: 0.1003 - val_acc: 0.8617\n",
      "Epoch 820/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.1004 - val_acc: 0.8599\n",
      "Epoch 821/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1009 - val_acc: 0.8596\n",
      "Epoch 822/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1014 - val_acc: 0.8596\n",
      "Epoch 823/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.0985 - val_acc: 0.8664\n",
      "Epoch 824/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1003 - val_acc: 0.8614\n",
      "Epoch 825/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8591\n",
      "Epoch 826/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.1008 - val_acc: 0.8612\n",
      "Epoch 827/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1010 - val_acc: 0.8601\n",
      "Epoch 828/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1026 - val_acc: 0.8625\n",
      "Epoch 829/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0972 - val_acc: 0.8685\n",
      "Epoch 830/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1011 - val_acc: 0.8628\n",
      "Epoch 831/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0988 - val_acc: 0.8699\n",
      "Epoch 832/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0985 - val_acc: 0.8670\n",
      "Epoch 833/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0981 - val_acc: 0.8672\n",
      "Epoch 834/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0981 - val_acc: 0.8678\n",
      "Epoch 835/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0988 - val_acc: 0.8688\n",
      "Epoch 836/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0994 - val_acc: 0.8685\n",
      "Epoch 837/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.1002 - val_acc: 0.8625\n",
      "Epoch 838/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0979 - val_acc: 0.8678\n",
      "Epoch 839/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.0987 - val_acc: 0.8593\n",
      "Epoch 840/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0989 - val_acc: 0.8704\n",
      "Epoch 841/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0978 - val_acc: 0.8672\n",
      "Epoch 842/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.1004 - val_acc: 0.8593\n",
      "Epoch 843/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0991 - val_acc: 0.8612\n",
      "Epoch 844/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1006 - val_acc: 0.8604\n",
      "Epoch 845/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9024 - val_loss: 0.1007 - val_acc: 0.8606\n",
      "Epoch 846/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8599\n",
      "Epoch 847/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0986 - val_acc: 0.8670\n",
      "Epoch 848/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0997 - val_acc: 0.8617\n",
      "Epoch 849/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1006 - val_acc: 0.8617\n",
      "Epoch 850/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0979 - val_acc: 0.8685\n",
      "Epoch 851/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.0996 - val_acc: 0.8599\n",
      "Epoch 852/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0989 - val_acc: 0.8591\n",
      "Epoch 853/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0988 - val_acc: 0.8675\n",
      "Epoch 854/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0997 - val_acc: 0.8614\n",
      "Epoch 855/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1006 - val_acc: 0.8612\n",
      "Epoch 856/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 857/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1001 - val_acc: 0.8604\n",
      "Epoch 858/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8675\n",
      "Epoch 859/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1016 - val_acc: 0.8625\n",
      "Epoch 860/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0992 - val_acc: 0.8612\n",
      "Epoch 861/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0990 - val_acc: 0.8672\n",
      "Epoch 862/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0995 - val_acc: 0.8580\n",
      "Epoch 863/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1001 - val_acc: 0.8628\n",
      "Epoch 864/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0999 - val_acc: 0.8612\n",
      "Epoch 865/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0980 - val_acc: 0.8691\n",
      "Epoch 866/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8688\n",
      "Epoch 867/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0993 - val_acc: 0.8588\n",
      "Epoch 868/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0984 - val_acc: 0.8664\n",
      "Epoch 869/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1004 - val_acc: 0.8599\n",
      "Epoch 870/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0977 - val_acc: 0.8662\n",
      "Epoch 871/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1004 - val_acc: 0.8620\n",
      "Epoch 872/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.1016 - val_acc: 0.8606\n",
      "Epoch 873/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0991 - val_acc: 0.8591\n",
      "Epoch 874/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0991 - val_acc: 0.8696\n",
      "Epoch 875/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1005 - val_acc: 0.8599\n",
      "Epoch 876/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8588\n",
      "Epoch 877/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9062 - val_loss: 0.1025 - val_acc: 0.8635\n",
      "Epoch 878/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1007 - val_acc: 0.8591\n",
      "Epoch 879/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0993 - val_acc: 0.8599\n",
      "Epoch 880/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.1019 - val_acc: 0.8614\n",
      "Epoch 881/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1016 - val_acc: 0.8604\n",
      "Epoch 882/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1001 - val_acc: 0.8599\n",
      "Epoch 883/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.0989 - val_acc: 0.8601\n",
      "Epoch 884/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1018 - val_acc: 0.8622\n",
      "Epoch 885/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0981 - val_acc: 0.8664\n",
      "Epoch 886/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0984 - val_acc: 0.8693\n",
      "Epoch 887/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0978 - val_acc: 0.8678\n",
      "Epoch 888/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 889/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1021 - val_acc: 0.8625\n",
      "Epoch 890/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0988 - val_acc: 0.8704\n",
      "Epoch 891/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0990 - val_acc: 0.8596\n",
      "Epoch 892/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1003 - val_acc: 0.8601\n",
      "Epoch 893/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0996 - val_acc: 0.8612\n",
      "Epoch 894/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9027 - val_loss: 0.1023 - val_acc: 0.8622\n",
      "Epoch 895/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0990 - val_acc: 0.8685\n",
      "Epoch 896/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.0984 - val_acc: 0.8680\n",
      "Epoch 897/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0984 - val_acc: 0.8672\n",
      "Epoch 898/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.1016 - val_acc: 0.8599\n",
      "Epoch 899/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0993 - val_acc: 0.8612\n",
      "Epoch 900/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0982 - val_acc: 0.8667\n",
      "Epoch 901/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1003 - val_acc: 0.8609\n",
      "Epoch 902/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1002 - val_acc: 0.8606\n",
      "Epoch 903/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0969 - val_acc: 0.8675\n",
      "Epoch 904/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1007 - val_acc: 0.8606\n",
      "Epoch 905/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.1011 - val_acc: 0.8599\n",
      "Epoch 906/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0987 - val_acc: 0.8691\n",
      "Epoch 907/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1005 - val_acc: 0.8583\n",
      "Epoch 908/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0994 - val_acc: 0.8588\n",
      "Epoch 909/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0975 - val_acc: 0.8672\n",
      "Epoch 910/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9037 - val_loss: 0.0983 - val_acc: 0.8691\n",
      "Epoch 911/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0991 - val_acc: 0.8601\n",
      "Epoch 912/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0998 - val_acc: 0.8601\n",
      "Epoch 913/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 914/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1019 - val_acc: 0.8593\n",
      "Epoch 915/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0999 - val_acc: 0.8606\n",
      "Epoch 916/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0985 - val_acc: 0.8688\n",
      "Epoch 917/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1008 - val_acc: 0.8604\n",
      "Epoch 918/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1005 - val_acc: 0.8620\n",
      "Epoch 919/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0990 - val_acc: 0.8691\n",
      "Epoch 920/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.1006 - val_acc: 0.8620\n",
      "Epoch 921/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0990 - val_acc: 0.8593\n",
      "Epoch 922/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0987 - val_acc: 0.8670\n",
      "Epoch 923/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1001 - val_acc: 0.8614\n",
      "Epoch 924/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 925/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9056 - val_loss: 0.0991 - val_acc: 0.8693\n",
      "Epoch 926/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1009 - val_acc: 0.8606\n",
      "Epoch 927/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0991 - val_acc: 0.8685\n",
      "Epoch 928/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0977 - val_acc: 0.8662\n",
      "Epoch 929/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9027 - val_loss: 0.0975 - val_acc: 0.8672\n",
      "Epoch 930/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0999 - val_acc: 0.8606\n",
      "Epoch 931/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0990 - val_acc: 0.8604\n",
      "Epoch 932/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0985 - val_acc: 0.8667\n",
      "Epoch 933/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0999 - val_acc: 0.8599\n",
      "Epoch 934/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0991 - val_acc: 0.8583\n",
      "Epoch 935/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1001 - val_acc: 0.8588\n",
      "Epoch 936/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1021 - val_acc: 0.8617\n",
      "Epoch 937/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0992 - val_acc: 0.8696\n",
      "Epoch 938/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1001 - val_acc: 0.8588\n",
      "Epoch 939/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9025 - val_loss: 0.0997 - val_acc: 0.8596\n",
      "Epoch 940/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0982 - val_acc: 0.8672\n",
      "Epoch 941/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9058 - val_loss: 0.1012 - val_acc: 0.8580\n",
      "Epoch 942/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0980 - val_acc: 0.8675\n",
      "Epoch 943/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0986 - val_acc: 0.8667\n",
      "Epoch 944/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0995 - val_acc: 0.8614\n",
      "Epoch 945/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9032 - val_loss: 0.1013 - val_acc: 0.8628\n",
      "Epoch 946/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0983 - val_acc: 0.8667\n",
      "Epoch 947/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0983 - val_acc: 0.8667\n",
      "Epoch 948/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1013 - val_acc: 0.8606\n",
      "Epoch 949/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.1008 - val_acc: 0.8596\n",
      "Epoch 950/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.1026 - val_acc: 0.8612\n",
      "Epoch 951/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0980 - val_acc: 0.8670\n",
      "Epoch 952/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0990 - val_acc: 0.8678\n",
      "Epoch 953/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1013 - val_acc: 0.8614\n",
      "Epoch 954/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0993 - val_acc: 0.8593\n",
      "Epoch 955/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.1014 - val_acc: 0.8593\n",
      "Epoch 956/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0992 - val_acc: 0.8654\n",
      "Epoch 957/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1002 - val_acc: 0.8591\n",
      "Epoch 958/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0986 - val_acc: 0.8688\n",
      "Epoch 959/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0993 - val_acc: 0.8599\n",
      "Epoch 960/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0998 - val_acc: 0.8614\n",
      "Epoch 961/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1010 - val_acc: 0.8622\n",
      "Epoch 962/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0986 - val_acc: 0.8667\n",
      "Epoch 963/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0978 - val_acc: 0.8741\n",
      "Epoch 964/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0981 - val_acc: 0.8683\n",
      "Epoch 965/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1009 - val_acc: 0.8620\n",
      "Epoch 966/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1022 - val_acc: 0.8625\n",
      "Epoch 967/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1004 - val_acc: 0.8612\n",
      "Epoch 968/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0977 - val_acc: 0.8683\n",
      "Epoch 969/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0984 - val_acc: 0.8701\n",
      "Epoch 970/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1016 - val_acc: 0.8593\n",
      "Epoch 971/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9024 - val_loss: 0.1005 - val_acc: 0.8593\n",
      "Epoch 972/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9056 - val_loss: 0.0988 - val_acc: 0.8667\n",
      "Epoch 973/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1000 - val_acc: 0.8646\n",
      "Epoch 974/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0981 - val_acc: 0.8691\n",
      "Epoch 975/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0988 - val_acc: 0.8675\n",
      "Epoch 976/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0997 - val_acc: 0.8614\n",
      "Epoch 977/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1005 - val_acc: 0.8606\n",
      "Epoch 978/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0984 - val_acc: 0.8664\n",
      "Epoch 979/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0989 - val_acc: 0.8588\n",
      "Epoch 980/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0998 - val_acc: 0.8604\n",
      "Epoch 981/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0990 - val_acc: 0.8604\n",
      "Epoch 982/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0992 - val_acc: 0.8599\n",
      "Epoch 983/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9038 - val_loss: 0.0974 - val_acc: 0.8670\n",
      "Epoch 984/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 985/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0994 - val_acc: 0.8685\n",
      "Epoch 986/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0991 - val_acc: 0.8583\n",
      "Epoch 987/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1000 - val_acc: 0.8585\n",
      "Epoch 988/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1000 - val_acc: 0.8704\n",
      "Epoch 989/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0981 - val_acc: 0.8693\n",
      "Epoch 990/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8599\n",
      "Epoch 991/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0979 - val_acc: 0.8688\n",
      "Epoch 992/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0982 - val_acc: 0.8693\n",
      "Epoch 993/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.1017 - val_acc: 0.8614\n",
      "Epoch 994/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9060 - val_loss: 0.0993 - val_acc: 0.8614\n",
      "Epoch 995/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0998 - val_acc: 0.8609\n",
      "Epoch 996/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0990 - val_acc: 0.8678\n",
      "Epoch 997/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0986 - val_acc: 0.8678\n",
      "Epoch 998/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1008 - val_acc: 0.8617\n",
      "Epoch 999/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0998 - val_acc: 0.8612\n",
      "Epoch 1000/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9061 - val_loss: 0.0981 - val_acc: 0.8683\n",
      "Epoch 1001/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9033 - val_loss: 0.0978 - val_acc: 0.8675\n",
      "Epoch 1002/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.1006 - val_acc: 0.8599\n",
      "Epoch 1003/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0998 - val_acc: 0.8601\n",
      "Epoch 1004/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 1005/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0995 - val_acc: 0.8696\n",
      "Epoch 1006/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0995 - val_acc: 0.8601\n",
      "Epoch 1007/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.0978 - val_acc: 0.8736\n",
      "Epoch 1008/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1001 - val_acc: 0.8609\n",
      "Epoch 1009/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0993 - val_acc: 0.8614\n",
      "Epoch 1010/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0996 - val_acc: 0.8617\n",
      "Epoch 1011/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.1023 - val_acc: 0.8601\n",
      "Epoch 1012/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0998 - val_acc: 0.8614\n",
      "Epoch 1013/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9050 - val_loss: 0.0996 - val_acc: 0.8588\n",
      "Epoch 1014/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0977 - val_acc: 0.8670\n",
      "Epoch 1015/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0983 - val_acc: 0.8664\n",
      "Epoch 1016/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1005 - val_acc: 0.8612\n",
      "Epoch 1017/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9032 - val_loss: 0.1003 - val_acc: 0.8609\n",
      "Epoch 1018/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1005 - val_acc: 0.8599\n",
      "Epoch 1019/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0997 - val_acc: 0.8583\n",
      "Epoch 1020/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0993 - val_acc: 0.8609\n",
      "Epoch 1021/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0985 - val_acc: 0.8670\n",
      "Epoch 1022/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0994 - val_acc: 0.8670\n",
      "Epoch 1023/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0988 - val_acc: 0.8685\n",
      "Epoch 1024/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0975 - val_acc: 0.8751\n",
      "Epoch 1025/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1014 - val_acc: 0.8588\n",
      "Epoch 1026/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0997 - val_acc: 0.8685\n",
      "Epoch 1027/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0982 - val_acc: 0.8678\n",
      "Epoch 1028/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1022 - val_acc: 0.8628\n",
      "Epoch 1029/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.1007 - val_acc: 0.8588\n",
      "Epoch 1030/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0985 - val_acc: 0.8685\n",
      "Epoch 1031/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9050 - val_loss: 0.1029 - val_acc: 0.8583\n",
      "Epoch 1032/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0985 - val_acc: 0.8670\n",
      "Epoch 1033/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1001 - val_acc: 0.8612\n",
      "Epoch 1034/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0994 - val_acc: 0.8591\n",
      "Epoch 1035/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1001 - val_acc: 0.8601\n",
      "Epoch 1036/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0997 - val_acc: 0.8612\n",
      "Epoch 1037/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9017 - val_loss: 0.1000 - val_acc: 0.8604\n",
      "Epoch 1038/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0985 - val_acc: 0.8678\n",
      "Epoch 1039/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0990 - val_acc: 0.8591\n",
      "Epoch 1040/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0982 - val_acc: 0.8691\n",
      "Epoch 1041/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0988 - val_acc: 0.8672\n",
      "Epoch 1042/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0985 - val_acc: 0.8664\n",
      "Epoch 1043/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0979 - val_acc: 0.8659\n",
      "Epoch 1044/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9056 - val_loss: 0.0977 - val_acc: 0.8667\n",
      "Epoch 1045/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1000 - val_acc: 0.8601\n",
      "Epoch 1046/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0995 - val_acc: 0.8580\n",
      "Epoch 1047/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1026 - val_acc: 0.8630\n",
      "Epoch 1048/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0986 - val_acc: 0.8685\n",
      "Epoch 1049/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9035 - val_loss: 0.0991 - val_acc: 0.8601\n",
      "Epoch 1050/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1002 - val_acc: 0.8606\n",
      "Epoch 1051/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1002 - val_acc: 0.8601\n",
      "Epoch 1052/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0974 - val_acc: 0.8675\n",
      "Epoch 1053/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0986 - val_acc: 0.8675\n",
      "Epoch 1054/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1004 - val_acc: 0.8606\n",
      "Epoch 1055/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0976 - val_acc: 0.8662\n",
      "Epoch 1056/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0991 - val_acc: 0.8675\n",
      "Epoch 1057/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0991 - val_acc: 0.8604\n",
      "Epoch 1058/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 1059/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0999 - val_acc: 0.8612\n",
      "Epoch 1060/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9048 - val_loss: 0.1002 - val_acc: 0.8593\n",
      "Epoch 1061/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.0991 - val_acc: 0.8599\n",
      "Epoch 1062/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0988 - val_acc: 0.8691\n",
      "Epoch 1063/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0983 - val_acc: 0.8693\n",
      "Epoch 1064/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9050 - val_loss: 0.0989 - val_acc: 0.8678\n",
      "Epoch 1065/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0999 - val_acc: 0.8596\n",
      "Epoch 1066/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1001 - val_acc: 0.8620\n",
      "Epoch 1067/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1007 - val_acc: 0.8606\n",
      "Epoch 1068/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0978 - val_acc: 0.8683\n",
      "Epoch 1069/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0998 - val_acc: 0.8599\n",
      "Epoch 1070/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9048 - val_loss: 0.0987 - val_acc: 0.8675\n",
      "Epoch 1071/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.1017 - val_acc: 0.8604\n",
      "Epoch 1072/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9038 - val_loss: 0.0985 - val_acc: 0.8683\n",
      "Epoch 1073/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9048 - val_loss: 0.0993 - val_acc: 0.8593\n",
      "Epoch 1074/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0987 - val_acc: 0.8591\n",
      "Epoch 1075/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9056 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 1076/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9060 - val_loss: 0.1014 - val_acc: 0.8628\n",
      "Epoch 1077/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0999 - val_acc: 0.8609\n",
      "Epoch 1078/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0978 - val_acc: 0.8670\n",
      "Epoch 1079/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9037 - val_loss: 0.0984 - val_acc: 0.8678\n",
      "Epoch 1080/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0982 - val_acc: 0.8685\n",
      "Epoch 1081/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0996 - val_acc: 0.8604\n",
      "Epoch 1082/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0997 - val_acc: 0.8604\n",
      "Epoch 1083/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1029 - val_acc: 0.8614\n",
      "Epoch 1084/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0978 - val_acc: 0.8685\n",
      "Epoch 1085/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0977 - val_acc: 0.8664\n",
      "Epoch 1086/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0987 - val_acc: 0.8675\n",
      "Epoch 1087/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0991 - val_acc: 0.8656\n",
      "Epoch 1088/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1000 - val_acc: 0.8601\n",
      "Epoch 1089/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0995 - val_acc: 0.8599\n",
      "Epoch 1090/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0977 - val_acc: 0.8675\n",
      "Epoch 1091/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0993 - val_acc: 0.8606\n",
      "Epoch 1092/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1005 - val_acc: 0.8612\n",
      "Epoch 1093/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1015 - val_acc: 0.8588\n",
      "Epoch 1094/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0982 - val_acc: 0.8670\n",
      "Epoch 1095/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 1096/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1033 - val_acc: 0.8620\n",
      "Epoch 1097/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9058 - val_loss: 0.0985 - val_acc: 0.8683\n",
      "Epoch 1098/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 1099/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.1003 - val_acc: 0.8593\n",
      "Epoch 1100/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.1003 - val_acc: 0.8604\n",
      "Epoch 1101/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0987 - val_acc: 0.8699\n",
      "Epoch 1102/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1024 - val_acc: 0.8596\n",
      "Epoch 1103/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0992 - val_acc: 0.8693\n",
      "Epoch 1104/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 1105/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9024 - val_loss: 0.0999 - val_acc: 0.8604\n",
      "Epoch 1106/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1010 - val_acc: 0.8609\n",
      "Epoch 1107/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1006 - val_acc: 0.8606\n",
      "Epoch 1108/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0987 - val_acc: 0.8656\n",
      "Epoch 1109/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0986 - val_acc: 0.8654\n",
      "Epoch 1110/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0992 - val_acc: 0.8688\n",
      "Epoch 1111/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0996 - val_acc: 0.8596\n",
      "Epoch 1112/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9024 - val_loss: 0.1009 - val_acc: 0.8612\n",
      "Epoch 1113/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1008 - val_acc: 0.8599\n",
      "Epoch 1114/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1003 - val_acc: 0.8617\n",
      "Epoch 1115/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0987 - val_acc: 0.8675\n",
      "Epoch 1116/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.1001 - val_acc: 0.8612\n",
      "Epoch 1117/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0994 - val_acc: 0.8609\n",
      "Epoch 1118/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0981 - val_acc: 0.8683\n",
      "Epoch 1119/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0989 - val_acc: 0.8675\n",
      "Epoch 1120/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1009 - val_acc: 0.8606\n",
      "Epoch 1121/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1004 - val_acc: 0.8612\n",
      "Epoch 1122/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1008 - val_acc: 0.8628\n",
      "Epoch 1123/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1001 - val_acc: 0.8620\n",
      "Epoch 1124/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0997 - val_acc: 0.8593\n",
      "Epoch 1125/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0999 - val_acc: 0.8712\n",
      "Epoch 1126/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0983 - val_acc: 0.8664\n",
      "Epoch 1127/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1004 - val_acc: 0.8591\n",
      "Epoch 1128/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1003 - val_acc: 0.8591\n",
      "Epoch 1129/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0989 - val_acc: 0.8685\n",
      "Epoch 1130/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0986 - val_acc: 0.8678\n",
      "Epoch 1131/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0990 - val_acc: 0.8688\n",
      "Epoch 1132/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0988 - val_acc: 0.8599\n",
      "Epoch 1133/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.1007 - val_acc: 0.8604\n",
      "Epoch 1134/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1002 - val_acc: 0.8614\n",
      "Epoch 1135/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0987 - val_acc: 0.8691\n",
      "Epoch 1136/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0994 - val_acc: 0.8612\n",
      "Epoch 1137/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0982 - val_acc: 0.8688\n",
      "Epoch 1138/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0987 - val_acc: 0.8685\n",
      "Epoch 1139/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0988 - val_acc: 0.8599\n",
      "Epoch 1140/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.1009 - val_acc: 0.8601\n",
      "Epoch 1141/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1012 - val_acc: 0.8630\n",
      "Epoch 1142/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0997 - val_acc: 0.8596\n",
      "Epoch 1143/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0983 - val_acc: 0.8683\n",
      "Epoch 1144/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0988 - val_acc: 0.8675\n",
      "Epoch 1145/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0986 - val_acc: 0.8736\n",
      "Epoch 1146/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.1012 - val_acc: 0.8596\n",
      "Epoch 1147/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0990 - val_acc: 0.8593\n",
      "Epoch 1148/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0998 - val_acc: 0.8620\n",
      "Epoch 1149/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1002 - val_acc: 0.8614\n",
      "Epoch 1150/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0982 - val_acc: 0.8675\n",
      "Epoch 1151/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0979 - val_acc: 0.8680\n",
      "Epoch 1152/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0994 - val_acc: 0.8585\n",
      "Epoch 1153/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1004 - val_acc: 0.8604\n",
      "Epoch 1154/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1022 - val_acc: 0.8593\n",
      "Epoch 1155/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0989 - val_acc: 0.8688\n",
      "Epoch 1156/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0988 - val_acc: 0.8678\n",
      "Epoch 1157/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0997 - val_acc: 0.8593\n",
      "Epoch 1158/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0996 - val_acc: 0.8599\n",
      "Epoch 1159/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0987 - val_acc: 0.8693\n",
      "Epoch 1160/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1003 - val_acc: 0.8628\n",
      "Epoch 1161/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1031 - val_acc: 0.8622\n",
      "Epoch 1162/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.1000 - val_acc: 0.8599\n",
      "Epoch 1163/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0988 - val_acc: 0.8683\n",
      "Epoch 1164/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1001 - val_acc: 0.8614\n",
      "Epoch 1165/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9050 - val_loss: 0.0981 - val_acc: 0.8662\n",
      "Epoch 1166/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9056 - val_loss: 0.0992 - val_acc: 0.8614\n",
      "Epoch 1167/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0977 - val_acc: 0.8685\n",
      "Epoch 1168/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0992 - val_acc: 0.8609\n",
      "Epoch 1169/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0988 - val_acc: 0.8585\n",
      "Epoch 1170/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0981 - val_acc: 0.8672\n",
      "Epoch 1171/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0968 - val_acc: 0.8664\n",
      "Epoch 1172/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1020 - val_acc: 0.8601\n",
      "Epoch 1173/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0998 - val_acc: 0.8596\n",
      "Epoch 1174/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.1008 - val_acc: 0.8601\n",
      "Epoch 1175/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0986 - val_acc: 0.8691\n",
      "Epoch 1176/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.0990 - val_acc: 0.8707\n",
      "Epoch 1177/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.1003 - val_acc: 0.8606\n",
      "Epoch 1178/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1005 - val_acc: 0.8601\n",
      "Epoch 1179/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0999 - val_acc: 0.8609\n",
      "Epoch 1180/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0998 - val_acc: 0.8604\n",
      "Epoch 1181/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0990 - val_acc: 0.8685\n",
      "Epoch 1182/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9024 - val_loss: 0.0985 - val_acc: 0.8588\n",
      "Epoch 1183/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0989 - val_acc: 0.8596\n",
      "Epoch 1184/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0982 - val_acc: 0.8696\n",
      "Epoch 1185/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0988 - val_acc: 0.8699\n",
      "Epoch 1186/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1012 - val_acc: 0.8614\n",
      "Epoch 1187/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0994 - val_acc: 0.8596\n",
      "Epoch 1188/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 1189/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0985 - val_acc: 0.8693\n",
      "Epoch 1190/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 1191/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0993 - val_acc: 0.8599\n",
      "Epoch 1192/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0991 - val_acc: 0.8583\n",
      "Epoch 1193/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.0991 - val_acc: 0.8675\n",
      "Epoch 1194/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9023 - val_loss: 0.0981 - val_acc: 0.8664\n",
      "Epoch 1195/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1003 - val_acc: 0.8604\n",
      "Epoch 1196/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.1005 - val_acc: 0.8609\n",
      "Epoch 1197/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0974 - val_acc: 0.8675\n",
      "Epoch 1198/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.0979 - val_acc: 0.8688\n",
      "Epoch 1199/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0987 - val_acc: 0.8680\n",
      "Epoch 1200/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0997 - val_acc: 0.8609\n",
      "Epoch 1201/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9056 - val_loss: 0.1007 - val_acc: 0.8606\n",
      "Epoch 1202/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.1003 - val_acc: 0.8599\n",
      "Epoch 1203/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1025 - val_acc: 0.8612\n",
      "Epoch 1204/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8683\n",
      "Epoch 1205/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0989 - val_acc: 0.8685\n",
      "Epoch 1206/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8691\n",
      "Epoch 1207/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.1007 - val_acc: 0.8612\n",
      "Epoch 1208/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0979 - val_acc: 0.8691\n",
      "Epoch 1209/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0989 - val_acc: 0.8685\n",
      "Epoch 1210/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0986 - val_acc: 0.8685\n",
      "Epoch 1211/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0992 - val_acc: 0.8612\n",
      "Epoch 1212/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.0998 - val_acc: 0.8588\n",
      "Epoch 1213/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0987 - val_acc: 0.8670\n",
      "Epoch 1214/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9032 - val_loss: 0.0992 - val_acc: 0.8596\n",
      "Epoch 1215/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0992 - val_acc: 0.8585\n",
      "Epoch 1216/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0999 - val_acc: 0.8599\n",
      "Epoch 1217/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1004 - val_acc: 0.8585\n",
      "Epoch 1218/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1006 - val_acc: 0.8601\n",
      "Epoch 1219/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9058 - val_loss: 0.1008 - val_acc: 0.8585\n",
      "Epoch 1220/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9031 - val_loss: 0.0999 - val_acc: 0.8601\n",
      "Epoch 1221/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.1003 - val_acc: 0.8596\n",
      "Epoch 1222/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0998 - val_acc: 0.8604\n",
      "Epoch 1223/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1001 - val_acc: 0.8635\n",
      "Epoch 1224/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0977 - val_acc: 0.8680\n",
      "Epoch 1225/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0988 - val_acc: 0.8688\n",
      "Epoch 1226/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0983 - val_acc: 0.8678\n",
      "Epoch 1227/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1004 - val_acc: 0.8622\n",
      "Epoch 1228/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0999 - val_acc: 0.8606\n",
      "Epoch 1229/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1017 - val_acc: 0.8625\n",
      "Epoch 1230/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0991 - val_acc: 0.8691\n",
      "Epoch 1231/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8693\n",
      "Epoch 1232/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.0986 - val_acc: 0.8593\n",
      "Epoch 1233/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0983 - val_acc: 0.8680\n",
      "Epoch 1234/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9049 - val_loss: 0.0973 - val_acc: 0.8672\n",
      "Epoch 1235/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0994 - val_acc: 0.8701\n",
      "Epoch 1236/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0995 - val_acc: 0.8617\n",
      "Epoch 1237/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0992 - val_acc: 0.8609\n",
      "Epoch 1238/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 1239/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1005 - val_acc: 0.8614\n",
      "Epoch 1240/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0983 - val_acc: 0.8675\n",
      "Epoch 1241/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0988 - val_acc: 0.8596\n",
      "Epoch 1242/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0988 - val_acc: 0.8688\n",
      "Epoch 1243/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1008 - val_acc: 0.8614\n",
      "Epoch 1244/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1018 - val_acc: 0.8599\n",
      "Epoch 1245/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 1246/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1026 - val_acc: 0.8593\n",
      "Epoch 1247/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0984 - val_acc: 0.8693\n",
      "Epoch 1248/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0996 - val_acc: 0.8617\n",
      "Epoch 1249/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1007 - val_acc: 0.8628\n",
      "Epoch 1250/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.1002 - val_acc: 0.8583\n",
      "Epoch 1251/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0995 - val_acc: 0.8601\n",
      "Epoch 1252/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1008 - val_acc: 0.8604\n",
      "Epoch 1253/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0993 - val_acc: 0.8606\n",
      "Epoch 1254/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0991 - val_acc: 0.8606\n",
      "Epoch 1255/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0996 - val_acc: 0.8593\n",
      "Epoch 1256/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0998 - val_acc: 0.8701\n",
      "Epoch 1257/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0999 - val_acc: 0.8606\n",
      "Epoch 1258/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9032 - val_loss: 0.1025 - val_acc: 0.8606\n",
      "Epoch 1259/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0989 - val_acc: 0.8675\n",
      "Epoch 1260/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1005 - val_acc: 0.8599\n",
      "Epoch 1261/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0994 - val_acc: 0.8614\n",
      "Epoch 1262/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0983 - val_acc: 0.8688\n",
      "Epoch 1263/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.1004 - val_acc: 0.8601\n",
      "Epoch 1264/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1005 - val_acc: 0.8625\n",
      "Epoch 1265/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0998 - val_acc: 0.8583\n",
      "Epoch 1266/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1004 - val_acc: 0.8630\n",
      "Epoch 1267/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1004 - val_acc: 0.8606\n",
      "Epoch 1268/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1013 - val_acc: 0.8588\n",
      "Epoch 1269/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1006 - val_acc: 0.8599\n",
      "Epoch 1270/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1014 - val_acc: 0.8625\n",
      "Epoch 1271/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0999 - val_acc: 0.8604\n",
      "Epoch 1272/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0994 - val_acc: 0.8601\n",
      "Epoch 1273/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0989 - val_acc: 0.8693\n",
      "Epoch 1274/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0985 - val_acc: 0.8680\n",
      "Epoch 1275/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1013 - val_acc: 0.8609\n",
      "Epoch 1276/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1012 - val_acc: 0.8609\n",
      "Epoch 1277/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0989 - val_acc: 0.8683\n",
      "Epoch 1278/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0987 - val_acc: 0.8693\n",
      "Epoch 1279/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.1008 - val_acc: 0.8606\n",
      "Epoch 1280/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9052 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 1281/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0998 - val_acc: 0.8599\n",
      "Epoch 1282/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0995 - val_acc: 0.8596\n",
      "Epoch 1283/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1011 - val_acc: 0.8628\n",
      "Epoch 1284/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.1019 - val_acc: 0.8625\n",
      "Epoch 1285/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1003 - val_acc: 0.8614\n",
      "Epoch 1286/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0999 - val_acc: 0.8596\n",
      "Epoch 1287/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0996 - val_acc: 0.8625\n",
      "Epoch 1288/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1015 - val_acc: 0.8628\n",
      "Epoch 1289/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.0982 - val_acc: 0.8693\n",
      "Epoch 1290/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9048 - val_loss: 0.1016 - val_acc: 0.8625\n",
      "Epoch 1291/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1004 - val_acc: 0.8614\n",
      "Epoch 1292/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0988 - val_acc: 0.8701\n",
      "Epoch 1293/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1000 - val_acc: 0.8596\n",
      "Epoch 1294/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.1004 - val_acc: 0.8614\n",
      "Epoch 1295/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.1008 - val_acc: 0.8588\n",
      "Epoch 1296/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0992 - val_acc: 0.8606\n",
      "Epoch 1297/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0995 - val_acc: 0.8593\n",
      "Epoch 1298/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0975 - val_acc: 0.8680\n",
      "Epoch 1299/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0976 - val_acc: 0.8659\n",
      "Epoch 1300/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9063 - val_loss: 0.0987 - val_acc: 0.8678\n",
      "Epoch 1301/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1001 - val_acc: 0.8612\n",
      "Epoch 1302/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0993 - val_acc: 0.8591\n",
      "Epoch 1303/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0978 - val_acc: 0.8667\n",
      "Epoch 1304/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0975 - val_acc: 0.8670\n",
      "Epoch 1305/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.1002 - val_acc: 0.8614\n",
      "Epoch 1306/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0979 - val_acc: 0.8693\n",
      "Epoch 1307/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0989 - val_acc: 0.8699\n",
      "Epoch 1308/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1028 - val_acc: 0.8591\n",
      "Epoch 1309/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.1013 - val_acc: 0.8593\n",
      "Epoch 1310/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0974 - val_acc: 0.8667\n",
      "Epoch 1311/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0981 - val_acc: 0.8670\n",
      "Epoch 1312/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0988 - val_acc: 0.8693\n",
      "Epoch 1313/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1003 - val_acc: 0.8612\n",
      "Epoch 1314/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0978 - val_acc: 0.8696\n",
      "Epoch 1315/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0995 - val_acc: 0.8693\n",
      "Epoch 1316/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0990 - val_acc: 0.8606\n",
      "Epoch 1317/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9028 - val_loss: 0.1002 - val_acc: 0.8620\n",
      "Epoch 1318/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0988 - val_acc: 0.8693\n",
      "Epoch 1319/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0992 - val_acc: 0.8685\n",
      "Epoch 1320/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9060 - val_loss: 0.0975 - val_acc: 0.8683\n",
      "Epoch 1321/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9048 - val_loss: 0.1008 - val_acc: 0.8591\n",
      "Epoch 1322/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1004 - val_acc: 0.8614\n",
      "Epoch 1323/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0975 - val_acc: 0.8678\n",
      "Epoch 1324/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0997 - val_acc: 0.8599\n",
      "Epoch 1325/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.1007 - val_acc: 0.8606\n",
      "Epoch 1326/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0992 - val_acc: 0.8606\n",
      "Epoch 1327/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0995 - val_acc: 0.8588\n",
      "Epoch 1328/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0987 - val_acc: 0.8662\n",
      "Epoch 1329/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.1028 - val_acc: 0.8606\n",
      "Epoch 1330/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0995 - val_acc: 0.8593\n",
      "Epoch 1331/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0999 - val_acc: 0.8585\n",
      "Epoch 1332/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0993 - val_acc: 0.8693\n",
      "Epoch 1333/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1012 - val_acc: 0.8630\n",
      "Epoch 1334/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9025 - val_loss: 0.1037 - val_acc: 0.8604\n",
      "Epoch 1335/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0999 - val_acc: 0.8604\n",
      "Epoch 1336/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1007 - val_acc: 0.8601\n",
      "Epoch 1337/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1003 - val_acc: 0.8614\n",
      "Epoch 1338/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0994 - val_acc: 0.8596\n",
      "Epoch 1339/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0971 - val_acc: 0.8685\n",
      "Epoch 1340/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.1002 - val_acc: 0.8585\n",
      "Epoch 1341/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0996 - val_acc: 0.8593\n",
      "Epoch 1342/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0991 - val_acc: 0.8693\n",
      "Epoch 1343/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0997 - val_acc: 0.8604\n",
      "Epoch 1344/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1003 - val_acc: 0.8596\n",
      "Epoch 1345/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0991 - val_acc: 0.8691\n",
      "Epoch 1346/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0983 - val_acc: 0.8670\n",
      "Epoch 1347/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0992 - val_acc: 0.8612\n",
      "Epoch 1348/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1002 - val_acc: 0.8606\n",
      "Epoch 1349/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.1001 - val_acc: 0.8588\n",
      "Epoch 1350/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0992 - val_acc: 0.8596\n",
      "Epoch 1351/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0981 - val_acc: 0.8667\n",
      "Epoch 1352/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8685\n",
      "Epoch 1353/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1013 - val_acc: 0.8625\n",
      "Epoch 1354/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0992 - val_acc: 0.8596\n",
      "Epoch 1355/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1011 - val_acc: 0.8628\n",
      "Epoch 1356/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0983 - val_acc: 0.8696\n",
      "Epoch 1357/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0982 - val_acc: 0.8680\n",
      "Epoch 1358/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0993 - val_acc: 0.8599\n",
      "Epoch 1359/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.1029 - val_acc: 0.8620\n",
      "Epoch 1360/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.1000 - val_acc: 0.8625\n",
      "Epoch 1361/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 1362/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8614\n",
      "Epoch 1363/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1006 - val_acc: 0.8599\n",
      "Epoch 1364/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1024 - val_acc: 0.8601\n",
      "Epoch 1365/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1000 - val_acc: 0.8609\n",
      "Epoch 1366/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.1011 - val_acc: 0.8620\n",
      "Epoch 1367/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1006 - val_acc: 0.8612\n",
      "Epoch 1368/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1006 - val_acc: 0.8622\n",
      "Epoch 1369/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1022 - val_acc: 0.8612\n",
      "Epoch 1370/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0994 - val_acc: 0.8609\n",
      "Epoch 1371/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1012 - val_acc: 0.8606\n",
      "Epoch 1372/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.1007 - val_acc: 0.8599\n",
      "Epoch 1373/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0986 - val_acc: 0.8670\n",
      "Epoch 1374/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0985 - val_acc: 0.8678\n",
      "Epoch 1375/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1001 - val_acc: 0.8617\n",
      "Epoch 1376/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9032 - val_loss: 0.1002 - val_acc: 0.8601\n",
      "Epoch 1377/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0993 - val_acc: 0.8591\n",
      "Epoch 1378/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9023 - val_loss: 0.1004 - val_acc: 0.8593\n",
      "Epoch 1379/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9025 - val_loss: 0.0991 - val_acc: 0.8704\n",
      "Epoch 1380/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0984 - val_acc: 0.8680\n",
      "Epoch 1381/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 1382/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1005 - val_acc: 0.8628\n",
      "Epoch 1383/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.1028 - val_acc: 0.8628\n",
      "Epoch 1384/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9044 - val_loss: 0.1000 - val_acc: 0.8612\n",
      "Epoch 1385/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9025 - val_loss: 0.0995 - val_acc: 0.8580\n",
      "Epoch 1386/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1009 - val_acc: 0.8599\n",
      "Epoch 1387/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0999 - val_acc: 0.8601\n",
      "Epoch 1388/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9024 - val_loss: 0.0996 - val_acc: 0.8583\n",
      "Epoch 1389/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.0982 - val_acc: 0.8733\n",
      "Epoch 1390/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.1007 - val_acc: 0.8622\n",
      "Epoch 1391/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0996 - val_acc: 0.8617\n",
      "Epoch 1392/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0997 - val_acc: 0.8614\n",
      "Epoch 1393/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1003 - val_acc: 0.8614\n",
      "Epoch 1394/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0976 - val_acc: 0.8672\n",
      "Epoch 1395/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0979 - val_acc: 0.8672\n",
      "Epoch 1396/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.0989 - val_acc: 0.8691\n",
      "Epoch 1397/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0990 - val_acc: 0.8688\n",
      "Epoch 1398/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1024 - val_acc: 0.8596\n",
      "Epoch 1399/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0978 - val_acc: 0.8664\n",
      "Epoch 1400/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1004 - val_acc: 0.8591\n",
      "Epoch 1401/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0985 - val_acc: 0.8662\n",
      "Epoch 1402/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0987 - val_acc: 0.8664\n",
      "Epoch 1403/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0990 - val_acc: 0.8696\n",
      "Epoch 1404/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0976 - val_acc: 0.8672\n",
      "Epoch 1405/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.1007 - val_acc: 0.8625\n",
      "Epoch 1406/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1011 - val_acc: 0.8612\n",
      "Epoch 1407/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1014 - val_acc: 0.8588\n",
      "Epoch 1408/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0995 - val_acc: 0.8588\n",
      "Epoch 1409/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1007 - val_acc: 0.8620\n",
      "Epoch 1410/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0989 - val_acc: 0.8606\n",
      "Epoch 1411/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9058 - val_loss: 0.0989 - val_acc: 0.8609\n",
      "Epoch 1412/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0998 - val_acc: 0.8593\n",
      "Epoch 1413/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9056 - val_loss: 0.1000 - val_acc: 0.8612\n",
      "Epoch 1414/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1006 - val_acc: 0.8604\n",
      "Epoch 1415/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0998 - val_acc: 0.8606\n",
      "Epoch 1416/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0989 - val_acc: 0.8693\n",
      "Epoch 1417/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0994 - val_acc: 0.8596\n",
      "Epoch 1418/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.1002 - val_acc: 0.8617\n",
      "Epoch 1419/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0986 - val_acc: 0.8691\n",
      "Epoch 1420/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.1025 - val_acc: 0.8614\n",
      "Epoch 1421/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0977 - val_acc: 0.8680\n",
      "Epoch 1422/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0993 - val_acc: 0.8593\n",
      "Epoch 1423/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0986 - val_acc: 0.8672\n",
      "Epoch 1424/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1015 - val_acc: 0.8604\n",
      "Epoch 1425/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0984 - val_acc: 0.8678\n",
      "Epoch 1426/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1012 - val_acc: 0.8612\n",
      "Epoch 1427/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0980 - val_acc: 0.8664\n",
      "Epoch 1428/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1001 - val_acc: 0.8604\n",
      "Epoch 1429/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0993 - val_acc: 0.8601\n",
      "Epoch 1430/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.1021 - val_acc: 0.8601\n",
      "Epoch 1431/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1001 - val_acc: 0.8614\n",
      "Epoch 1432/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.1021 - val_acc: 0.8609\n",
      "Epoch 1433/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 1434/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0983 - val_acc: 0.8685\n",
      "Epoch 1435/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0978 - val_acc: 0.8680\n",
      "Epoch 1436/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1016 - val_acc: 0.8599\n",
      "Epoch 1437/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.1005 - val_acc: 0.8585\n",
      "Epoch 1438/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0999 - val_acc: 0.8591\n",
      "Epoch 1439/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0986 - val_acc: 0.8701\n",
      "Epoch 1440/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1000 - val_acc: 0.8596\n",
      "Epoch 1441/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8709\n",
      "Epoch 1442/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1033 - val_acc: 0.8622\n",
      "Epoch 1443/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.1002 - val_acc: 0.8591\n",
      "Epoch 1444/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0990 - val_acc: 0.8696\n",
      "Epoch 1445/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9033 - val_loss: 0.0992 - val_acc: 0.8588\n",
      "Epoch 1446/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0995 - val_acc: 0.8604\n",
      "Epoch 1447/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0995 - val_acc: 0.8609\n",
      "Epoch 1448/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1010 - val_acc: 0.8620\n",
      "Epoch 1449/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0994 - val_acc: 0.8596\n",
      "Epoch 1450/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0991 - val_acc: 0.8604\n",
      "Epoch 1451/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0991 - val_acc: 0.8696\n",
      "Epoch 1452/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1002 - val_acc: 0.8604\n",
      "Epoch 1453/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0985 - val_acc: 0.8672\n",
      "Epoch 1454/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0998 - val_acc: 0.8601\n",
      "Epoch 1455/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0990 - val_acc: 0.8659\n",
      "Epoch 1456/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0993 - val_acc: 0.8606\n",
      "Epoch 1457/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0981 - val_acc: 0.8683\n",
      "Epoch 1458/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0989 - val_acc: 0.8688\n",
      "Epoch 1459/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0993 - val_acc: 0.8585\n",
      "Epoch 1460/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0991 - val_acc: 0.8614\n",
      "Epoch 1461/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0999 - val_acc: 0.8606\n",
      "Epoch 1462/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0988 - val_acc: 0.8680\n",
      "Epoch 1463/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0979 - val_acc: 0.8683\n",
      "Epoch 1464/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0993 - val_acc: 0.8696\n",
      "Epoch 1465/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.1039 - val_acc: 0.8614\n",
      "Epoch 1466/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1004 - val_acc: 0.8609\n",
      "Epoch 1467/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0996 - val_acc: 0.8609\n",
      "Epoch 1468/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1010 - val_acc: 0.8656\n",
      "Epoch 1469/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0993 - val_acc: 0.8672\n",
      "Epoch 1470/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1004 - val_acc: 0.8628\n",
      "Epoch 1471/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0994 - val_acc: 0.8599\n",
      "Epoch 1472/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0989 - val_acc: 0.8691\n",
      "Epoch 1473/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1001 - val_acc: 0.8583\n",
      "Epoch 1474/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1002 - val_acc: 0.8612\n",
      "Epoch 1475/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.0985 - val_acc: 0.8654\n",
      "Epoch 1476/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1023 - val_acc: 0.8617\n",
      "Epoch 1477/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1011 - val_acc: 0.8591\n",
      "Epoch 1478/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8693\n",
      "Epoch 1479/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0983 - val_acc: 0.8667\n",
      "Epoch 1480/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0990 - val_acc: 0.8588\n",
      "Epoch 1481/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0990 - val_acc: 0.8577\n",
      "Epoch 1482/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1013 - val_acc: 0.8609\n",
      "Epoch 1483/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1002 - val_acc: 0.8614\n",
      "Epoch 1484/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0998 - val_acc: 0.8614\n",
      "Epoch 1485/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0977 - val_acc: 0.8685\n",
      "Epoch 1486/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0987 - val_acc: 0.8685\n",
      "Epoch 1487/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1012 - val_acc: 0.8622\n",
      "Epoch 1488/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1006 - val_acc: 0.8617\n",
      "Epoch 1489/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0977 - val_acc: 0.8670\n",
      "Epoch 1490/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.1006 - val_acc: 0.8604\n",
      "Epoch 1491/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0984 - val_acc: 0.8685\n",
      "Epoch 1492/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0999 - val_acc: 0.8596\n",
      "Epoch 1493/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1004 - val_acc: 0.8614\n",
      "Epoch 1494/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1000 - val_acc: 0.8628\n",
      "Epoch 1495/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0984 - val_acc: 0.8667\n",
      "Epoch 1496/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0994 - val_acc: 0.8699\n",
      "Epoch 1497/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9035 - val_loss: 0.0982 - val_acc: 0.8675\n",
      "Epoch 1498/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0999 - val_acc: 0.8601\n",
      "Epoch 1499/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0980 - val_acc: 0.8667\n",
      "Epoch 1500/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0982 - val_acc: 0.8672\n",
      "Epoch 1501/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0988 - val_acc: 0.8693\n",
      "Epoch 1502/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.1013 - val_acc: 0.8617\n",
      "Epoch 1503/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1005 - val_acc: 0.8580\n",
      "Epoch 1504/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0981 - val_acc: 0.8693\n",
      "Epoch 1505/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1006 - val_acc: 0.8628\n",
      "Epoch 1506/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9033 - val_loss: 0.0998 - val_acc: 0.8588\n",
      "Epoch 1507/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.1013 - val_acc: 0.8609\n",
      "Epoch 1508/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1044 - val_acc: 0.8628\n",
      "Epoch 1509/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0992 - val_acc: 0.8707\n",
      "Epoch 1510/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1004 - val_acc: 0.8612\n",
      "Epoch 1511/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0985 - val_acc: 0.8691\n",
      "Epoch 1512/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.1000 - val_acc: 0.8596\n",
      "Epoch 1513/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0991 - val_acc: 0.8675\n",
      "Epoch 1514/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9025 - val_loss: 0.0987 - val_acc: 0.8691\n",
      "Epoch 1515/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0987 - val_acc: 0.8596\n",
      "Epoch 1516/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1005 - val_acc: 0.8620\n",
      "Epoch 1517/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0991 - val_acc: 0.8591\n",
      "Epoch 1518/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1009 - val_acc: 0.8593\n",
      "Epoch 1519/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0987 - val_acc: 0.8662\n",
      "Epoch 1520/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 1521/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0984 - val_acc: 0.8680\n",
      "Epoch 1522/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0996 - val_acc: 0.8591\n",
      "Epoch 1523/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0989 - val_acc: 0.8670\n",
      "Epoch 1524/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0972 - val_acc: 0.8738\n",
      "Epoch 1525/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0992 - val_acc: 0.8606\n",
      "Epoch 1526/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1010 - val_acc: 0.8606\n",
      "Epoch 1527/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1005 - val_acc: 0.8614\n",
      "Epoch 1528/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0995 - val_acc: 0.8614\n",
      "Epoch 1529/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0983 - val_acc: 0.8743\n",
      "Epoch 1530/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.1009 - val_acc: 0.8620\n",
      "Epoch 1531/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9031 - val_loss: 0.0983 - val_acc: 0.8691\n",
      "Epoch 1532/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0998 - val_acc: 0.8596\n",
      "Epoch 1533/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0992 - val_acc: 0.8599\n",
      "Epoch 1534/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 1535/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0981 - val_acc: 0.8678\n",
      "Epoch 1536/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9067 - val_loss: 0.0985 - val_acc: 0.8662\n",
      "Epoch 1537/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0984 - val_acc: 0.8688\n",
      "Epoch 1538/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.1000 - val_acc: 0.8599\n",
      "Epoch 1539/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0991 - val_acc: 0.8688\n",
      "Epoch 1540/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0995 - val_acc: 0.8617\n",
      "Epoch 1541/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.1013 - val_acc: 0.8596\n",
      "Epoch 1542/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1002 - val_acc: 0.8606\n",
      "Epoch 1543/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0991 - val_acc: 0.8688\n",
      "Epoch 1544/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9032 - val_loss: 0.0994 - val_acc: 0.8707\n",
      "Epoch 1545/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.1009 - val_acc: 0.8630\n",
      "Epoch 1546/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0992 - val_acc: 0.8691\n",
      "Epoch 1547/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0974 - val_acc: 0.8675\n",
      "Epoch 1548/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1002 - val_acc: 0.8596\n",
      "Epoch 1549/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8609\n",
      "Epoch 1550/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9057 - val_loss: 0.0998 - val_acc: 0.8604\n",
      "Epoch 1551/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1012 - val_acc: 0.8614\n",
      "Epoch 1552/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0976 - val_acc: 0.8678\n",
      "Epoch 1553/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.1009 - val_acc: 0.8628\n",
      "Epoch 1554/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.1016 - val_acc: 0.8580\n",
      "Epoch 1555/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0987 - val_acc: 0.8678\n",
      "Epoch 1556/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1019 - val_acc: 0.8614\n",
      "Epoch 1557/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0985 - val_acc: 0.8593\n",
      "Epoch 1558/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0984 - val_acc: 0.8693\n",
      "Epoch 1559/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.1003 - val_acc: 0.8630\n",
      "Epoch 1560/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9027 - val_loss: 0.1007 - val_acc: 0.8604\n",
      "Epoch 1561/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0985 - val_acc: 0.8683\n",
      "Epoch 1562/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0982 - val_acc: 0.8688\n",
      "Epoch 1563/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0996 - val_acc: 0.8596\n",
      "Epoch 1564/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.1003 - val_acc: 0.8591\n",
      "Epoch 1565/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 1566/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1011 - val_acc: 0.8609\n",
      "Epoch 1567/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0999 - val_acc: 0.8575\n",
      "Epoch 1568/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1007 - val_acc: 0.8606\n",
      "Epoch 1569/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1010 - val_acc: 0.8614\n",
      "Epoch 1570/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0981 - val_acc: 0.8691\n",
      "Epoch 1571/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0986 - val_acc: 0.8683\n",
      "Epoch 1572/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.0998 - val_acc: 0.8620\n",
      "Epoch 1573/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0999 - val_acc: 0.8588\n",
      "Epoch 1574/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0979 - val_acc: 0.8670\n",
      "Epoch 1575/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0994 - val_acc: 0.8596\n",
      "Epoch 1576/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0988 - val_acc: 0.8685\n",
      "Epoch 1577/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0993 - val_acc: 0.8609\n",
      "Epoch 1578/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1016 - val_acc: 0.8612\n",
      "Epoch 1579/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1008 - val_acc: 0.8606\n",
      "Epoch 1580/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.1018 - val_acc: 0.8612\n",
      "Epoch 1581/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0992 - val_acc: 0.8591\n",
      "Epoch 1582/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0989 - val_acc: 0.8612\n",
      "Epoch 1583/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0991 - val_acc: 0.8593\n",
      "Epoch 1584/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0989 - val_acc: 0.8593\n",
      "Epoch 1585/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0990 - val_acc: 0.8685\n",
      "Epoch 1586/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0986 - val_acc: 0.8688\n",
      "Epoch 1587/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0976 - val_acc: 0.8678\n",
      "Epoch 1588/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.1009 - val_acc: 0.8604\n",
      "Epoch 1589/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0997 - val_acc: 0.8704\n",
      "Epoch 1590/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.1008 - val_acc: 0.8609\n",
      "Epoch 1591/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0998 - val_acc: 0.8591\n",
      "Epoch 1592/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0980 - val_acc: 0.8680\n",
      "Epoch 1593/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1012 - val_acc: 0.8606\n",
      "Epoch 1594/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.1004 - val_acc: 0.8612\n",
      "Epoch 1595/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0999 - val_acc: 0.8609\n",
      "Epoch 1596/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0996 - val_acc: 0.8617\n",
      "Epoch 1597/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0990 - val_acc: 0.8693\n",
      "Epoch 1598/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0995 - val_acc: 0.8599\n",
      "Epoch 1599/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0999 - val_acc: 0.8599\n",
      "Epoch 1600/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0988 - val_acc: 0.8691\n",
      "Epoch 1601/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1003 - val_acc: 0.8609\n",
      "Epoch 1602/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0990 - val_acc: 0.8693\n",
      "Epoch 1603/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0984 - val_acc: 0.8678\n",
      "Epoch 1604/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9061 - val_loss: 0.1002 - val_acc: 0.8609\n",
      "Epoch 1605/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1011 - val_acc: 0.8625\n",
      "Epoch 1606/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9054 - val_loss: 0.0986 - val_acc: 0.8675\n",
      "Epoch 1607/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1004 - val_acc: 0.8630\n",
      "Epoch 1608/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0971 - val_acc: 0.8691\n",
      "Epoch 1609/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0999 - val_acc: 0.8609\n",
      "Epoch 1610/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1029 - val_acc: 0.8606\n",
      "Epoch 1611/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1006 - val_acc: 0.8596\n",
      "Epoch 1612/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0996 - val_acc: 0.8596\n",
      "Epoch 1613/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8604\n",
      "Epoch 1614/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.1015 - val_acc: 0.8617\n",
      "Epoch 1615/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0998 - val_acc: 0.8606\n",
      "Epoch 1616/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.0999 - val_acc: 0.8609\n",
      "Epoch 1617/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0995 - val_acc: 0.8593\n",
      "Epoch 1618/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8699\n",
      "Epoch 1619/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0990 - val_acc: 0.8609\n",
      "Epoch 1620/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1004 - val_acc: 0.8593\n",
      "Epoch 1621/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0987 - val_acc: 0.8696\n",
      "Epoch 1622/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9029 - val_loss: 0.0980 - val_acc: 0.8672\n",
      "Epoch 1623/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0992 - val_acc: 0.8612\n",
      "Epoch 1624/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1004 - val_acc: 0.8612\n",
      "Epoch 1625/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0990 - val_acc: 0.8609\n",
      "Epoch 1626/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0980 - val_acc: 0.8678\n",
      "Epoch 1627/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 1628/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0979 - val_acc: 0.8699\n",
      "Epoch 1629/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.1000 - val_acc: 0.8617\n",
      "Epoch 1630/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9038 - val_loss: 0.1033 - val_acc: 0.8633\n",
      "Epoch 1631/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9035 - val_loss: 0.0982 - val_acc: 0.8678\n",
      "Epoch 1632/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1005 - val_acc: 0.8614\n",
      "Epoch 1633/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9023 - val_loss: 0.0974 - val_acc: 0.8741\n",
      "Epoch 1634/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1002 - val_acc: 0.8591\n",
      "Epoch 1635/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.0978 - val_acc: 0.8662\n",
      "Epoch 1636/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0986 - val_acc: 0.8696\n",
      "Epoch 1637/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0981 - val_acc: 0.8667\n",
      "Epoch 1638/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9025 - val_loss: 0.0999 - val_acc: 0.8609\n",
      "Epoch 1639/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9038 - val_loss: 0.1013 - val_acc: 0.8630\n",
      "Epoch 1640/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0994 - val_acc: 0.8614\n",
      "Epoch 1641/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.1006 - val_acc: 0.8606\n",
      "Epoch 1642/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1000 - val_acc: 0.8606\n",
      "Epoch 1643/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1012 - val_acc: 0.8625\n",
      "Epoch 1644/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.1010 - val_acc: 0.8596\n",
      "Epoch 1645/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1012 - val_acc: 0.8622\n",
      "Epoch 1646/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.1006 - val_acc: 0.8630\n",
      "Epoch 1647/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0993 - val_acc: 0.8606\n",
      "Epoch 1648/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.0999 - val_acc: 0.8601\n",
      "Epoch 1649/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.1006 - val_acc: 0.86140\n",
      "Epoch 1650/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0976 - val_acc: 0.8672\n",
      "Epoch 1651/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1017 - val_acc: 0.8609\n",
      "Epoch 1652/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.0999 - val_acc: 0.8593\n",
      "Epoch 1653/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0992 - val_acc: 0.8585\n",
      "Epoch 1654/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0989 - val_acc: 0.8691\n",
      "Epoch 1655/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0993 - val_acc: 0.8609\n",
      "Epoch 1656/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1007 - val_acc: 0.8601\n",
      "Epoch 1657/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0989 - val_acc: 0.8670\n",
      "Epoch 1658/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9056 - val_loss: 0.0998 - val_acc: 0.8580\n",
      "Epoch 1659/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1006 - val_acc: 0.8614\n",
      "Epoch 1660/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0985 - val_acc: 0.8670\n",
      "Epoch 1661/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 1662/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1000 - val_acc: 0.8609\n",
      "Epoch 1663/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1004 - val_acc: 0.8609\n",
      "Epoch 1664/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0975 - val_acc: 0.8743\n",
      "Epoch 1665/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0979 - val_acc: 0.8736\n",
      "Epoch 1666/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.1009 - val_acc: 0.8612\n",
      "Epoch 1667/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0985 - val_acc: 0.8667\n",
      "Epoch 1668/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0982 - val_acc: 0.8662\n",
      "Epoch 1669/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9057 - val_loss: 0.0981 - val_acc: 0.8691\n",
      "Epoch 1670/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0989 - val_acc: 0.8678\n",
      "Epoch 1671/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9024 - val_loss: 0.0994 - val_acc: 0.8612\n",
      "Epoch 1672/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8680\n",
      "Epoch 1673/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0996 - val_acc: 0.8696\n",
      "Epoch 1674/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0994 - val_acc: 0.8617\n",
      "Epoch 1675/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0987 - val_acc: 0.8688\n",
      "Epoch 1676/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0985 - val_acc: 0.8704\n",
      "Epoch 1677/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1012 - val_acc: 0.8628\n",
      "Epoch 1678/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0996 - val_acc: 0.8599\n",
      "Epoch 1679/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.0989 - val_acc: 0.8593\n",
      "Epoch 1680/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1013 - val_acc: 0.8612\n",
      "Epoch 1681/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 1682/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0985 - val_acc: 0.8670\n",
      "Epoch 1683/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9048 - val_loss: 0.0992 - val_acc: 0.8601\n",
      "Epoch 1684/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1011 - val_acc: 0.8612\n",
      "Epoch 1685/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1023 - val_acc: 0.8630\n",
      "Epoch 1686/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0997 - val_acc: 0.8609\n",
      "Epoch 1687/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0972 - val_acc: 0.8685\n",
      "Epoch 1688/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1001 - val_acc: 0.8625\n",
      "Epoch 1689/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.1011 - val_acc: 0.8601\n",
      "Epoch 1690/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9024 - val_loss: 0.0983 - val_acc: 0.8678\n",
      "Epoch 1691/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1012 - val_acc: 0.8609\n",
      "Epoch 1692/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1023 - val_acc: 0.8604\n",
      "Epoch 1693/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0979 - val_acc: 0.8675\n",
      "Epoch 1694/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9032 - val_loss: 0.0986 - val_acc: 0.8693\n",
      "Epoch 1695/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1003 - val_acc: 0.8593\n",
      "Epoch 1696/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1005 - val_acc: 0.8596\n",
      "Epoch 1697/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0991 - val_acc: 0.8596\n",
      "Epoch 1698/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9021 - val_loss: 0.0999 - val_acc: 0.8604\n",
      "Epoch 1699/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 1700/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0995 - val_acc: 0.8609\n",
      "Epoch 1701/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0998 - val_acc: 0.8609\n",
      "Epoch 1702/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 1703/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.0983 - val_acc: 0.8675\n",
      "Epoch 1704/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0994 - val_acc: 0.8612\n",
      "Epoch 1705/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.1016 - val_acc: 0.8614\n",
      "Epoch 1706/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9050 - val_loss: 0.0986 - val_acc: 0.8680\n",
      "Epoch 1707/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1002 - val_acc: 0.8604\n",
      "Epoch 1708/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9053 - val_loss: 0.1007 - val_acc: 0.8609\n",
      "Epoch 1709/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0999 - val_acc: 0.8604\n",
      "Epoch 1710/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0985 - val_acc: 0.8678\n",
      "Epoch 1711/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0991 - val_acc: 0.8591\n",
      "Epoch 1712/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1002 - val_acc: 0.8591\n",
      "Epoch 1713/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1010 - val_acc: 0.8630\n",
      "Epoch 1714/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0977 - val_acc: 0.8670\n",
      "Epoch 1715/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 1716/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1015 - val_acc: 0.8630\n",
      "Epoch 1717/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0981 - val_acc: 0.8688\n",
      "Epoch 1718/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.0998 - val_acc: 0.8699\n",
      "Epoch 1719/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0996 - val_acc: 0.8696\n",
      "Epoch 1720/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9035 - val_loss: 0.0988 - val_acc: 0.8672\n",
      "Epoch 1721/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0986 - val_acc: 0.8667\n",
      "Epoch 1722/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.1010 - val_acc: 0.8625\n",
      "Epoch 1723/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0998 - val_acc: 0.8609\n",
      "Epoch 1724/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.1004 - val_acc: 0.8614\n",
      "Epoch 1725/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.1005 - val_acc: 0.8609\n",
      "Epoch 1726/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0977 - val_acc: 0.8675\n",
      "Epoch 1727/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0993 - val_acc: 0.8593\n",
      "Epoch 1728/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9027 - val_loss: 0.1004 - val_acc: 0.8601\n",
      "Epoch 1729/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 1730/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0985 - val_acc: 0.8693\n",
      "Epoch 1731/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0998 - val_acc: 0.8614\n",
      "Epoch 1732/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0988 - val_acc: 0.8691\n",
      "Epoch 1733/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0974 - val_acc: 0.8678\n",
      "Epoch 1734/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0989 - val_acc: 0.8583\n",
      "Epoch 1735/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0994 - val_acc: 0.8596\n",
      "Epoch 1736/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0979 - val_acc: 0.8664\n",
      "Epoch 1737/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9029 - val_loss: 0.1008 - val_acc: 0.8620\n",
      "Epoch 1738/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1008 - val_acc: 0.8620\n",
      "Epoch 1739/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0980 - val_acc: 0.8672\n",
      "Epoch 1740/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9045 - val_loss: 0.0995 - val_acc: 0.8601\n",
      "Epoch 1741/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0986 - val_acc: 0.8685\n",
      "Epoch 1742/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9050 - val_loss: 0.0995 - val_acc: 0.8606\n",
      "Epoch 1743/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1006 - val_acc: 0.8622\n",
      "Epoch 1744/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1003 - val_acc: 0.8601\n",
      "Epoch 1745/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0981 - val_acc: 0.8693\n",
      "Epoch 1746/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 1747/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0993 - val_acc: 0.8609\n",
      "Epoch 1748/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 1749/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0987 - val_acc: 0.8670\n",
      "Epoch 1750/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0989 - val_acc: 0.8693\n",
      "Epoch 1751/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9048 - val_loss: 0.1003 - val_acc: 0.8599\n",
      "Epoch 1752/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9029 - val_loss: 0.0976 - val_acc: 0.8659\n",
      "Epoch 1753/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0999 - val_acc: 0.8599\n",
      "Epoch 1754/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0995 - val_acc: 0.8614\n",
      "Epoch 1755/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0988 - val_acc: 0.8591\n",
      "Epoch 1756/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1005 - val_acc: 0.8622\n",
      "Epoch 1757/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0992 - val_acc: 0.8612\n",
      "Epoch 1758/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0990 - val_acc: 0.8596\n",
      "Epoch 1759/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0998 - val_acc: 0.8601\n",
      "Epoch 1760/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0995 - val_acc: 0.8609\n",
      "Epoch 1761/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1013 - val_acc: 0.8609\n",
      "Epoch 1762/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0983 - val_acc: 0.8672\n",
      "Epoch 1763/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.1030 - val_acc: 0.8609\n",
      "Epoch 1764/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1001 - val_acc: 0.8617\n",
      "Epoch 1765/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0993 - val_acc: 0.8609\n",
      "Epoch 1766/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.1002 - val_acc: 0.8612\n",
      "Epoch 1767/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0997 - val_acc: 0.8599\n",
      "Epoch 1768/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9038 - val_loss: 0.0982 - val_acc: 0.8699\n",
      "Epoch 1769/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0976 - val_acc: 0.8672\n",
      "Epoch 1770/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0996 - val_acc: 0.8599\n",
      "Epoch 1771/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1004 - val_acc: 0.8604\n",
      "Epoch 1772/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0991 - val_acc: 0.8588\n",
      "Epoch 1773/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0983 - val_acc: 0.8685\n",
      "Epoch 1774/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0988 - val_acc: 0.8693\n",
      "Epoch 1775/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 1776/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0993 - val_acc: 0.8599\n",
      "Epoch 1777/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0988 - val_acc: 0.8691\n",
      "Epoch 1778/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0993 - val_acc: 0.8609\n",
      "Epoch 1779/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0980 - val_acc: 0.8670\n",
      "Epoch 1780/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0983 - val_acc: 0.8667\n",
      "Epoch 1781/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1021 - val_acc: 0.8628\n",
      "Epoch 1782/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0990 - val_acc: 0.8693\n",
      "Epoch 1783/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1001 - val_acc: 0.8617\n",
      "Epoch 1784/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1004 - val_acc: 0.8614\n",
      "Epoch 1785/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1007 - val_acc: 0.8604\n",
      "Epoch 1786/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1001 - val_acc: 0.8614\n",
      "Epoch 1787/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.1013 - val_acc: 0.8612\n",
      "Epoch 1788/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0990 - val_acc: 0.8601\n",
      "Epoch 1789/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0995 - val_acc: 0.8609\n",
      "Epoch 1790/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0993 - val_acc: 0.8691\n",
      "Epoch 1791/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1010 - val_acc: 0.8606\n",
      "Epoch 1792/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0999 - val_acc: 0.8614\n",
      "Epoch 1793/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0994 - val_acc: 0.8596\n",
      "Epoch 1794/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0986 - val_acc: 0.8683\n",
      "Epoch 1795/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.0986 - val_acc: 0.8688\n",
      "Epoch 1796/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0984 - val_acc: 0.8678\n",
      "Epoch 1797/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1019 - val_acc: 0.8617\n",
      "Epoch 1798/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0981 - val_acc: 0.8656\n",
      "Epoch 1799/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0988 - val_acc: 0.8696\n",
      "Epoch 1800/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1005 - val_acc: 0.8609\n",
      "Epoch 1801/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0995 - val_acc: 0.8612\n",
      "Epoch 1802/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 1803/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0983 - val_acc: 0.8672\n",
      "Epoch 1804/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1008 - val_acc: 0.8614\n",
      "Epoch 1805/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0998 - val_acc: 0.8601\n",
      "Epoch 1806/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1003 - val_acc: 0.8591\n",
      "Epoch 1807/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0993 - val_acc: 0.8596\n",
      "Epoch 1808/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0979 - val_acc: 0.8670\n",
      "Epoch 1809/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1004 - val_acc: 0.8606\n",
      "Epoch 1810/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0991 - val_acc: 0.8601\n",
      "Epoch 1811/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.0995 - val_acc: 0.8599\n",
      "Epoch 1812/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.0996 - val_acc: 0.8609\n",
      "Epoch 1813/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9028 - val_loss: 0.0979 - val_acc: 0.8678\n",
      "Epoch 1814/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1012 - val_acc: 0.8593\n",
      "Epoch 1815/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9056 - val_loss: 0.0996 - val_acc: 0.8583\n",
      "Epoch 1816/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1003 - val_acc: 0.8601\n",
      "Epoch 1817/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9033 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 1818/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1013 - val_acc: 0.8591\n",
      "Epoch 1819/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.0992 - val_acc: 0.8612\n",
      "Epoch 1820/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 1821/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.0998 - val_acc: 0.8628\n",
      "Epoch 1822/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1002 - val_acc: 0.8612\n",
      "Epoch 1823/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1002 - val_acc: 0.8599\n",
      "Epoch 1824/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0987 - val_acc: 0.8675\n",
      "Epoch 1825/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9033 - val_loss: 0.1013 - val_acc: 0.8606\n",
      "Epoch 1826/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0993 - val_acc: 0.8693\n",
      "Epoch 1827/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.1010 - val_acc: 0.8614\n",
      "Epoch 1828/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0984 - val_acc: 0.8672\n",
      "Epoch 1829/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.1040 - val_acc: 0.8617\n",
      "Epoch 1830/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.0991 - val_acc: 0.8693\n",
      "Epoch 1831/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0992 - val_acc: 0.8606\n",
      "Epoch 1832/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1001 - val_acc: 0.8601\n",
      "Epoch 1833/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0982 - val_acc: 0.8691\n",
      "Epoch 1834/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1015 - val_acc: 0.8625\n",
      "Epoch 1835/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0990 - val_acc: 0.8696\n",
      "Epoch 1836/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1008 - val_acc: 0.8596\n",
      "Epoch 1837/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0984 - val_acc: 0.8680\n",
      "Epoch 1838/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0991 - val_acc: 0.8707\n",
      "Epoch 1839/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1002 - val_acc: 0.8609\n",
      "Epoch 1840/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9048 - val_loss: 0.0998 - val_acc: 0.8601\n",
      "Epoch 1841/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.1008 - val_acc: 0.8614\n",
      "Epoch 1842/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0993 - val_acc: 0.8612\n",
      "Epoch 1843/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9042 - val_loss: 0.0980 - val_acc: 0.8688\n",
      "Epoch 1844/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.0988 - val_acc: 0.8699\n",
      "Epoch 1845/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9046 - val_loss: 0.1002 - val_acc: 0.8606\n",
      "Epoch 1846/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0987 - val_acc: 0.8691\n",
      "Epoch 1847/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0995 - val_acc: 0.8585\n",
      "Epoch 1848/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.1000 - val_acc: 0.8606\n",
      "Epoch 1849/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1002 - val_acc: 0.8622\n",
      "Epoch 1850/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.1018 - val_acc: 0.8633\n",
      "Epoch 1851/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.1009 - val_acc: 0.8622\n",
      "Epoch 1852/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0986 - val_acc: 0.8693\n",
      "Epoch 1853/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9053 - val_loss: 0.1001 - val_acc: 0.8609\n",
      "Epoch 1854/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0999 - val_acc: 0.8614\n",
      "Epoch 1855/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0982 - val_acc: 0.8685\n",
      "Epoch 1856/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.0990 - val_acc: 0.8601\n",
      "Epoch 1857/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9037 - val_loss: 0.0986 - val_acc: 0.8662\n",
      "Epoch 1858/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0988 - val_acc: 0.8588\n",
      "Epoch 1859/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0986 - val_acc: 0.8678\n",
      "Epoch 1860/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9032 - val_loss: 0.1035 - val_acc: 0.8628\n",
      "Epoch 1861/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0987 - val_acc: 0.8667\n",
      "Epoch 1862/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0981 - val_acc: 0.8672\n",
      "Epoch 1863/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9024 - val_loss: 0.0979 - val_acc: 0.8678\n",
      "Epoch 1864/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.0995 - val_acc: 0.8609\n",
      "Epoch 1865/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9050 - val_loss: 0.1014 - val_acc: 0.8630\n",
      "Epoch 1866/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.1002 - val_acc: 0.8606\n",
      "Epoch 1867/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0998 - val_acc: 0.8604\n",
      "Epoch 1868/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9046 - val_loss: 0.1012 - val_acc: 0.8614\n",
      "Epoch 1869/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9032 - val_loss: 0.1016 - val_acc: 0.8617\n",
      "Epoch 1870/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1003 - val_acc: 0.8614\n",
      "Epoch 1871/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0982 - val_acc: 0.8699\n",
      "Epoch 1872/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 1873/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1001 - val_acc: 0.8606\n",
      "Epoch 1874/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1000 - val_acc: 0.8612\n",
      "Epoch 1875/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0981 - val_acc: 0.8688\n",
      "Epoch 1876/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0995 - val_acc: 0.8707\n",
      "Epoch 1877/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0999 - val_acc: 0.8606\n",
      "Epoch 1878/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1021 - val_acc: 0.8604\n",
      "Epoch 1879/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9036 - val_loss: 0.1008 - val_acc: 0.8593\n",
      "Epoch 1880/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0983 - val_acc: 0.8675\n",
      "Epoch 1881/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9037 - val_loss: 0.0994 - val_acc: 0.8612\n",
      "Epoch 1882/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.1001 - val_acc: 0.8617\n",
      "Epoch 1883/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9061 - val_loss: 0.1034 - val_acc: 0.8625\n",
      "Epoch 1884/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0979 - val_acc: 0.8693\n",
      "Epoch 1885/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1013 - val_acc: 0.8614\n",
      "Epoch 1886/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 1887/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0996 - val_acc: 0.8612\n",
      "Epoch 1888/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0988 - val_acc: 0.8680\n",
      "Epoch 1889/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0990 - val_acc: 0.8688\n",
      "Epoch 1890/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.1010 - val_acc: 0.8604\n",
      "Epoch 1891/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9058 - val_loss: 0.0990 - val_acc: 0.8678\n",
      "Epoch 1892/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1008 - val_acc: 0.8596\n",
      "Epoch 1893/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1000 - val_acc: 0.8612\n",
      "Epoch 1894/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.1003 - val_acc: 0.8659\n",
      "Epoch 1895/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1002 - val_acc: 0.8591\n",
      "Epoch 1896/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1000 - val_acc: 0.8599\n",
      "Epoch 1897/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0990 - val_acc: 0.8678\n",
      "Epoch 1898/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.1009 - val_acc: 0.8604\n",
      "Epoch 1899/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9042 - val_loss: 0.0983 - val_acc: 0.8683\n",
      "Epoch 1900/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 1901/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1005 - val_acc: 0.8609\n",
      "Epoch 1902/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.0982 - val_acc: 0.8688\n",
      "Epoch 1903/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0995 - val_acc: 0.8617\n",
      "Epoch 1904/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0987 - val_acc: 0.8683\n",
      "Epoch 1905/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9033 - val_loss: 0.0983 - val_acc: 0.8680\n",
      "Epoch 1906/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9050 - val_loss: 0.0995 - val_acc: 0.8604\n",
      "Epoch 1907/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0991 - val_acc: 0.8599\n",
      "Epoch 1908/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0985 - val_acc: 0.8672\n",
      "Epoch 1909/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0988 - val_acc: 0.8691\n",
      "Epoch 1910/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0982 - val_acc: 0.8688\n",
      "Epoch 1911/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0999 - val_acc: 0.8620\n",
      "Epoch 1912/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0997 - val_acc: 0.8609\n",
      "Epoch 1913/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1008 - val_acc: 0.8606\n",
      "Epoch 1914/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9049 - val_loss: 0.0987 - val_acc: 0.8683\n",
      "Epoch 1915/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0997 - val_acc: 0.8609\n",
      "Epoch 1916/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0973 - val_acc: 0.8672\n",
      "Epoch 1917/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9042 - val_loss: 0.0992 - val_acc: 0.8599\n",
      "Epoch 1918/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1011 - val_acc: 0.8604\n",
      "Epoch 1919/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9054 - val_loss: 0.1000 - val_acc: 0.8606\n",
      "Epoch 1920/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9024 - val_loss: 0.0994 - val_acc: 0.8604\n",
      "Epoch 1921/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0981 - val_acc: 0.8683\n",
      "Epoch 1922/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0997 - val_acc: 0.8717\n",
      "Epoch 1923/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.1021 - val_acc: 0.8599\n",
      "Epoch 1924/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.1021 - val_acc: 0.8628\n",
      "Epoch 1925/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1013 - val_acc: 0.8614\n",
      "Epoch 1926/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0990 - val_acc: 0.8609\n",
      "Epoch 1927/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1004 - val_acc: 0.8612\n",
      "Epoch 1928/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0998 - val_acc: 0.8617\n",
      "Epoch 1929/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1006 - val_acc: 0.8617\n",
      "Epoch 1930/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0984 - val_acc: 0.8672\n",
      "Epoch 1931/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0981 - val_acc: 0.8701\n",
      "Epoch 1932/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9032 - val_loss: 0.0982 - val_acc: 0.8685\n",
      "Epoch 1933/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9045 - val_loss: 0.1012 - val_acc: 0.8599\n",
      "Epoch 1934/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0988 - val_acc: 0.8685\n",
      "Epoch 1935/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.1001 - val_acc: 0.8601\n",
      "Epoch 1936/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9041 - val_loss: 0.0994 - val_acc: 0.8620\n",
      "Epoch 1937/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9036 - val_loss: 0.1023 - val_acc: 0.8625\n",
      "Epoch 1938/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.1004 - val_acc: 0.8593\n",
      "Epoch 1939/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.1007 - val_acc: 0.8609\n",
      "Epoch 1940/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0998 - val_acc: 0.8604\n",
      "Epoch 1941/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9041 - val_loss: 0.0988 - val_acc: 0.8688\n",
      "Epoch 1942/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.1022 - val_acc: 0.8601\n",
      "Epoch 1943/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.1003 - val_acc: 0.8617\n",
      "Epoch 1944/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1000 - val_acc: 0.8617\n",
      "Epoch 1945/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9049 - val_loss: 0.0990 - val_acc: 0.8699\n",
      "Epoch 1946/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.0998 - val_acc: 0.8591\n",
      "Epoch 1947/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9052 - val_loss: 0.0999 - val_acc: 0.8612\n",
      "Epoch 1948/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.1013 - val_acc: 0.8606\n",
      "Epoch 1949/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9048 - val_loss: 0.0999 - val_acc: 0.8625\n",
      "Epoch 1950/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0984 - val_acc: 0.8680\n",
      "Epoch 1951/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.1016 - val_acc: 0.8609\n",
      "Epoch 1952/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.1009 - val_acc: 0.8625\n",
      "Epoch 1953/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9031 - val_loss: 0.0985 - val_acc: 0.8730\n",
      "Epoch 1954/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0984 - val_acc: 0.8685\n",
      "Epoch 1955/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0991 - val_acc: 0.8601\n",
      "Epoch 1956/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.1005 - val_acc: 0.8628\n",
      "Epoch 1957/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0981 - val_acc: 0.8672\n",
      "Epoch 1958/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8691\n",
      "Epoch 1959/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9040 - val_loss: 0.0996 - val_acc: 0.8606\n",
      "Epoch 1960/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9050 - val_loss: 0.1017 - val_acc: 0.8614\n",
      "Epoch 1961/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0994 - val_acc: 0.8606\n",
      "Epoch 1962/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9054 - val_loss: 0.0998 - val_acc: 0.8622\n",
      "Epoch 1963/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0983 - val_acc: 0.8693\n",
      "Epoch 1964/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9027 - val_loss: 0.0980 - val_acc: 0.8667\n",
      "Epoch 1965/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0977 - val_acc: 0.8678\n",
      "Epoch 1966/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9049 - val_loss: 0.0994 - val_acc: 0.8601\n",
      "Epoch 1967/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.1016 - val_acc: 0.8630\n",
      "Epoch 1968/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9042 - val_loss: 0.1005 - val_acc: 0.8614\n",
      "Epoch 1969/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.1030 - val_acc: 0.8622\n",
      "Epoch 1970/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0995 - val_acc: 0.8612\n",
      "Epoch 1971/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0992 - val_acc: 0.8606\n",
      "Epoch 1972/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.1006 - val_acc: 0.8606\n",
      "Epoch 1973/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0982 - val_acc: 0.8685\n",
      "Epoch 1974/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0992 - val_acc: 0.8609\n",
      "Epoch 1975/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0996 - val_acc: 0.8612\n",
      "Epoch 1976/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9037 - val_loss: 0.0989 - val_acc: 0.8606\n",
      "Epoch 1977/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9040 - val_loss: 0.0989 - val_acc: 0.8672\n",
      "Epoch 1978/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0997 - val_acc: 0.8601\n",
      "Epoch 1979/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0735 - acc: 0.9025 - val_loss: 0.0989 - val_acc: 0.8654\n",
      "Epoch 1980/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9052 - val_loss: 0.0984 - val_acc: 0.8672\n",
      "Epoch 1981/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9048 - val_loss: 0.0984 - val_acc: 0.8662\n",
      "Epoch 1982/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9048 - val_loss: 0.1005 - val_acc: 0.8609\n",
      "Epoch 1983/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9033 - val_loss: 0.0984 - val_acc: 0.8664\n",
      "Epoch 1984/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0735 - acc: 0.9036 - val_loss: 0.1015 - val_acc: 0.8720\n",
      "Epoch 1985/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9038 - val_loss: 0.0994 - val_acc: 0.8612\n",
      "Epoch 1986/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9044 - val_loss: 0.0986 - val_acc: 0.8672\n",
      "Epoch 1987/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9058 - val_loss: 0.0986 - val_acc: 0.8675\n",
      "Epoch 1988/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9035 - val_loss: 0.0998 - val_acc: 0.8617\n",
      "Epoch 1989/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9040 - val_loss: 0.0985 - val_acc: 0.8685\n",
      "Epoch 1990/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9038 - val_loss: 0.0976 - val_acc: 0.8667\n",
      "Epoch 1991/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9044 - val_loss: 0.0994 - val_acc: 0.8612\n",
      "Epoch 1992/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0738 - acc: 0.9031 - val_loss: 0.1010 - val_acc: 0.8620\n",
      "Epoch 1993/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0980 - val_acc: 0.8670\n",
      "Epoch 1994/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9041 - val_loss: 0.0991 - val_acc: 0.8614\n",
      "Epoch 1995/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0736 - acc: 0.9045 - val_loss: 0.0982 - val_acc: 0.8691\n",
      "Epoch 1996/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9036 - val_loss: 0.0979 - val_acc: 0.8678\n",
      "Epoch 1997/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9046 - val_loss: 0.0981 - val_acc: 0.8680\n",
      "Epoch 1998/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9028 - val_loss: 0.0997 - val_acc: 0.8625\n",
      "Epoch 1999/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9042 - val_loss: 0.0998 - val_acc: 0.8606\n",
      "Epoch 2000/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0737 - acc: 0.9023 - val_loss: 0.0994 - val_acc: 0.8699\n"
     ]
    }
   ],
   "source": [
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(3, activation='relu', input_dim=6)) # camada escondida\n",
    "classifier.add(Dense(1, activation='relu')) # \n",
    "classifier.compile(optimizer='adam', \n",
    "                   loss='mean_squared_error', # metrica de erro\n",
    "                   metrics=['accuracy']) # metrica de sucesso\n",
    "\n",
    "history = classifier.fit(X_train, y_train,\n",
    "                         epochs=2000, # quantidade de epocas que a rede neural vai executar\n",
    "                         verbose=1,\n",
    "                         shuffle=True, # utilizado para misturar as amostras a cada epoca\n",
    "                         validation_data=(X_validation, y_validation))\n",
    "#                          callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216/1962 [=================>............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.057721121891740633, 0.91539245673761938]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)\n",
    "# print (test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAgAElEQVR4XuydB5xcVdnG3/RCEnovCb2XUKRLRLo0C+CnfhIEAekqID0bQDoiRdRPSgBRiijSOwECgVASegmQ0EtCSAKE9HzPMzsXJsPs7uzeubs7O//D72Ums/ece87/nHPvc99TbqcgQAACEIAABCAAAQjUFIFONVVaCgsBCEAAAhCAAAQgEAhAGgEEIAABCEAAAhCoMQIIwBqrcIoLAQhAAAIQgAAEEIC0AQhAAAIQgAAEIFBjBBCANVbhFBcCEIAABCAAAQggAGkDEIAABCAAAQhAoMYIIABrrMIpLgQgAAEIQAACEEAA0gYgAAEIQAACEIBAjRFAANZYhVNcCEAAAhCAAAQggACkDUAAAhCAAAQgAIEaI4AArLEKp7gQgAAEIAABCEAAAUgbgAAEIAABCEAAAjVGAAFYYxVOcSEAAQhAAAIQgAACkDYAAQhAAAIQgAAEaowAArDGKpziQgACEIAABCAAAQQgbQACEIAABCAAAQjUGAEEYI1VOMWFAAQgAAEIQAACCEDaAAQgAAEIQAACEKgxAgjAGqtwigsBCEAAAhCAAAQQgLQBCEAAAhCAAAQgUGMEEIA1VuEUFwIQgAAEIAABCCAAaQMQgAAEIAABCECgxgggAGuswikuBCAAAQhAAAIQQADSBiAAAQhAAAIQgECNEUAA1liFU1wIQAACEIAABCCAAKQNQAACEIAABCAAgRojgACssQqnuBCAAAQgAAEIQAABSBuAAAQgAAEIQAACNUYAAVhjFU5xIQABCEAAAhCAAAKQNgABCEAAAhCAAARqjAACsMYqnOJCAAIQgAAEIAABBCBtAAIQgAAEIAABCNQYAQRgjVU4xYUABCAAAQhAAAIIQNoABCAAAQhAAAIQqDECCMAaq3CKWxECayiVl2X/I7uumSn21PFfyo6XndXMuNV0uLlsIDOr1g676oS3yjaRPZU/+b/yeVmnicz478/L9pI5TqXCxHxbOaxSCZIOBCAAgTQEEIBp6BG3vRCYV2ZGvqPjhpd5bGOHIQCbhtiUAFxOSbwtu0J2QAPJLaLfP8wLsZ80fcqvjmgrAThIObCdI5tWlN+2EoAWnBc3wm5d/e2FZrBt7UN764Quw96y1WTdZeNld8kulI1r7QxxPgh0FAIIwI5Sk7Vdjp8VFf/n+vf2sv8t+v1e/fujCqByv+khmymb24L07AWcJZvTgrjVEqUpAehyPCizl3DJPMvish2kH/4i+57sjmYUvJQA7Kb4rjfXWWMhjQewTgkPkS0us+ArDG4vru/ZzShHJQ5NBOCxSuyDEgnaUzqlEifKII2lleY9srVl/5U9ILP3fE2Zve/uR35IIEAAAi0ggABsATSitHsClyiHh8rKbd+9dOx0WbmexHYPoB1ksBwBaM/f32Tfl91cIs8P5W/2y+izOcKplAAsF0lWArDc81f6uEQAWjS90szE7W3zA04p9vbMFXs5m5l8NJXGcCW4pWx32Z1FiTtunczCNm1orJxp0yY+BNotgXJvkO22AGQMAiUINCYAd8rfTH6oz01l9hIuJfMNpa/sBNkOsgEy3/gekf1O9mLBeUoNAVvwbCfbUHapbJDMN8jLZCfJEk9hqTmAngvoc/SXnSHbLX/8jfo8QmZxmoQF9OVc2Y9l9mrZq/kbmYfCmppXaKF7omwX2SqyzjLPkXP+RhScIynf4frNovi3Mouw0bJfycYUHOuvHp6rk60ke01mhvbKNjUHcCEd4yHeW/JpFCabDBGbZTJvblV9P0bmoXz//XOZy+/f3iuIXO4Q8GKKc5HMx7uub5JdLhspK5wDuLH+fZRsK5m9Up/k8+w6S7xn5+m7ORWHxBtYagh4dR18tmyQzCLEfO1BvK9EWZxHt9dfyszN4vhAmYfRGwvlCsBE+B6ixBaUHSxbXuY8uj3YU7inzAxct/baOs/m1pxyNJRGcRm+m+dwgT7dvpsKbsduS+ZUGIrnfjZUTpfRbfdo2flFaWykfzv9/WTD8n9z2zlVtofM39+Sua3+sSjuYP3bbcdt16zG54/7a1MF4u8QyJoAAjBrwqTfFgTKEYAvKWMWaNfKLKo8b8s3WAsA3zR8QffN3jdCC621ZB/nC9OQALSw8jCbb86+mVts2nvxC9mV+biNCUDHGSsbLvuWbLDMNxmLgiR4KMxpOj3flCw6LbzWlzUlAC2aHpdZrPo8FhL2wvlGb+FqJg5J+Zwfi0Yz6SKzt2WyzHOxkuFri1Xn6TnZVTILHntfLcgsMJtaBGLRtbPMguKz/Pn9YVHnOtlCZkHmMDif9m36fF9mEWtB6u/ryZLh3XIEYNd8uhapf5K9IbOQ7ZdPq1AAmv+3ZR6CdBswawuxx2QWow7mZyFtb6bzZHHqYBE/Q1YsAFfQb+bra7Dn6E2V7S8zWw95352Pn5TFx/pBwHVnxubzqMxCqbGQCMDNddDrRQf6oWRS/rdEGLkNuK5d5/7732VeTGMB6L+5XP+Q+WHJDytuU80pR6k0Sk2j8Pw+P/yYq9NvKjRXAJYqpx9EHHwdKAxuh0fKlpBZ8LuNjJItLPMUBbe/QTI/lP1e5nbgYLH7H5mnL5ifuZqzHzb3LToH/4RAqxNAALY6ck7YCgTKEYAeDvPN3zfnJFic+d+FQ8G+IXuSvD1n9rw5NCQA99HfLJKS49y/HPdTmT0nDo0JQHsQLJ6S4BuHhY1vsg4WQ77p22NosZeEf+qLbz5NCUCLHufJ8w+TsKi+2PNhYZGcOymfPSr27licOFggXS/z/MrES+UbqW9ovrElosei0DfTV2VNCcAf6BiLQN8Qry7Il2/6vtGuXPCbxajngBUGC2B7AZ2Ob7YO5QjAn+o4ixt7vP6cj2ehb7Fpj0+hACx13mT4ulCg1CleQ3MAiwWgh74t+HyuROBYkHt1uUWZ570VluUZ/cPCJBmOtZfVYsPiv7GFEIkAzCc334c9mfZeOSQC0Pm0t8pCPwkJT3vBXd7CeZTNLUepNErlzXP/3M7sZSxsr6WO9W/NFYClymlPo71/xUzH67dnZfb2Obj/+cHQfbPQA2shb6+s++sEmb3/fihcVsb0koZqjt/bjAACsM3Qc+IMCZQjAD185yf7hoLFkofC3EcsunwD9sRzh8YEoOMkgsnHeqjHgshDqA6NCUDfULwFSRIs6HyTtwCxMLU38GSZvUfvFByXCMOmBGBBlJx3zoLDnxaQfWT2Ejkk5fuDvhcOa9ojam+HF2f8n2xF2ZuyOtnQwsT13d4mi5WmBKAXR1hoPiGzx7Tw/KfrHy5vqWBhYIHo+jELi+7k2HIEoD2/vqFbABc+BHiYzyuTG9oGxnVhj7E9lhb3FoL2ljnUycoVgPaQ+iGk2IPnMvthw2zHy5KyFApVn2tr2cP5+PZMNhQSAWgvdGGb8fEWck7DIRGAFjH2vBWGJA9uC24ThaG55SiVRqm821NtT6t5lxOaKwBLlTOZduB+5KF5h81kfijwA4M9nw72Flu0WwQWBvdDe8Pt+fPneTLzd7seXk4hOAYCrUkAAdiatDlXaxEoRwDam+XhucLgIRrfoHxh93w8i6MkeBK6n+YdGhKAO+pvHhYqDPYWePgouZE1JgAtyApXZDof9k55jqJXL3uI1V5Gp1EYPDTlv5cjAC1Yfi2zZ9MiNwn2PHmY2yEpn+cueSguCUnej9MPydw1r+QtvDkmx9p7aU9KUwLQx9uLNFhmT4mHWE+TeRiteOGCRarFkb2FZlJ4/Sq8oZcjAD3n0StIkzIn+U7EdKEANN86mX9LPGbJ8YWCxseUIwDN3V4t162FXWFIPJOD9KOnEiRl8eftBQcmgu1H+s0e1IZCIgCbWgSSpGcvmOfdFYYkD4VeVv+9JeUoTqOhfGftASxVTufF7cIebXs6HczCDzxuA/Zw+xrhumvs3mkvoNu0p1a4f9iLbU+hy2RP+/0NFZrfIdCaBBCArUmbc7UWgXIEoL1ynktWGBLvi71b9qp46Nbzkzw0a09XsYeqcCNoX9g9HFksECwALaQS0daYAPS8qmQY1flKBKA9b/aSpRWAybDlv5SWV916GMxz+U6R+QaXiLVEAHoRiFkmoTjvg/SHSgjAbZTOcFlyPnsPLYQ9PFoYzNiLdzxM96TMnlYPrbksw2QWOw6VFoD2Rlko2mNsr98XMnsBPeTsuXj29DjUybISgJ4n6b3vkpAItqY2rG6uAPT8Rc9rKwwJz+I8tEQAFqdRdKqv/unFOW4P5c4BdHvwQ5DzWhhcRx7SNi+HhFupcvrvCS/HsafPws3eaQtth6TMnuLQ0P6KfphKFiW5z7jMvnb406KweKpHUZb5JwRahwACsHU4c5bWJdBSAeghOQu9xNOX5NpCyUNMbS0A0w4BW0D4BpTML0vK97S+WNA0VwBWYgjYefB1yItu3pXZO2nBVTxUaG+sF0FYnBQOUdrj6jlzXsjRHAFY7hCwhwU9dFqcn4H6zdMCCgWgxV+drNQ+gG5DFrBJHhsaOk28n8VDwO1RALru0pYjaYPFn57/Z49Z8TSEho73sfbcJXNtk+NcR54uUK4AtGfZZfJDkT2w3gWgWGS7rXp+q3cLaE6w93CYzKuok4e65sTnWAhUlAACsKI4SaydEGipAPQEdT/x+2abBG8T48UJXpXZ1gLQe6J5iMpexZYsAvEQooWFBWAyKd2rW32jK1ywUa4H0Izs7fDwtm+wLVkEknD2kLIX0NizYi+OharnGybBAtDpe76dPUNJ8NxD36ybKwAbWgTilb3e9iW56SfzHou3B7E31huOFwpAH+O5iPYeFa+4LRaAyeIJC0kvMHDw/FEvqvECjOJFIO1VAKYtR0FVfuOr5yd6Dp699cmq6OQgt7k6mefyOng43cLKgj2ZRuE5ra5P9+tyBaDTsvffnnz3i8Eye8cLFx+5jv1A4L7j/lgYPKc0GTnwdy+0KQxu427rA2QWkgQItBkBBGCboefEGRJoqQBMRIhX73lIyZPQPefOwsPewbYWgEbmYWtvE5JsA+NFBJ5r5xXNydy8htB62MvDT/+W+YbquUme32ShVbhlS3MEoBdSeJjN28AMk/lm2ZxtYJK8+pVkTsPBc6Q8nF4cPNfNYsDzEi2wfAO2QLDHzSK9OR5AD+V5aM8LbywenZ7rutQ2MPaQWtTZG+U5iubv+YpuH4UC8Dv6t8WDeZixF8H404stigVgsg2MhbiHEr0FjlcFe9V1qW1g0gpAC49SbwKxyPJDT2NDow0NAStabkGSF0S0tBxOo6HghVNe4e326GF+TzewEPO/Pf3CItAiyyHZq8916rbg+vGUB3N33pojAJM30LhO3N+KX0NooW5huYrMDyQW8G43bg+eomCvtL3V9kq6X1lIuo+5v/nhxQu9PNeUAIE2JYAAbFP8nDwjAi0VgL6h2LuW7AfnYV9PFrdAsFemPQjAPsqH55xZrHhIyUKuTua5acWLNorx+mbkxRW+MVo02TPi7US8QrRw0+bmCECfw1vQOA8DZM3ZCLo4fxaAFoLOT7JvYuEx9sp4o12LIW/Z4hurh4Mt1guHV8uZA+h0LVY918yCyxP7G9oI2uWySLPg9JxJL3AxR2+/UigAnaZXbTv/XiXs62syHFwsAH2sObu9WTi6PBZSDW0EnVYA+nylQuLpbKkATFuOhvKV/O6pCRZN7pPJwqXx+Trwg0ChF80C2ivBPYxrkWWPrOOac3MEoNuZxbIfEpIVvcX59IItL0iy4LPX0V4/e9HdhtxWPHfYwtFtwQ8ZFo0WgRaU9lq7PRAg0KYEEIBtip+TQ6AiBJKtKppaEVqRk5EIBCAAAQhUPwEEYPXXISWoLQL2UhZvhux9/Cz+7InwSkgCBCAAAQhAoFECCEAaCASqi4Bfv+UhLc/d8twmD196xaSHMr3fIAECEIAABCDQJAEEYJOIOAAC7YqAt6jxPCeLQM+P8hyoYTLPJUvez9uuMkxmIAABCECg/RFAALa/OiFHEIAABCAAAQhAIFMCCMBM8ZI4BCAAAQhAAAIQaH8EEIDtr07IEQQgAAEIQAACEMiUAAIwU7wkDgEIQAACEIAABNofAQRgujoxP+9W7x3jCRCAAAQgAAEIVA+BvsqqN+hOXo1ZPTmvQE4RgOkg+nVDfoE9AQIQgAAEIACB6iPg/VPfq75sp88xAjAdQ7//cco777wT/fr5KwECEIAABCAAgfZOYOrUqbH88ss7m35N39T2nt8s8ocATEc1JwAVEIDpOBIbAhCAAAQg0GoELAAXXNDaDwHYatA72IkQgB2sQikOBCAAAQh0fAIIwAg8gOnaOQIwHT9iQwACEIAABFqdAAIQAZi20SEA0xIkPgQgAAEIQKCVCSAAEYBpmxwCMC1B4kMAAhBoYwLz5s2L2bNnx5w5vE67jauiYqfv0qVLdO3aNTp1Kj3QiQBEAKZtbAjAtASJDwEIQKANCcycOTM++OCDmDZtWhvmglNnQaB3796x9NJLR/fu3b+RPAIQAZi2zSEA0xIkPgQgAIE2IjB37twYO3Zs2Fu0+OKL54RCQx6jNsoip20BAXt0LewnTJiQ8+quuuqq0blz5/lSQgAiAFvQtOaLggBMS5D4EIAABNqIwPTp02PcuHHRv3//sLeI0LEI2Kv71ltvxYorrhg9e/ZEABZVL6uA07V3BGA6fsSGAAQg0GYEEgFYSiC0WaY4ccUINFa/eADxAKZtaAjAtASJDwEIQKCNCCAA2wh8K50WAdg4aDyA6RoiAjAdP2JDAAIQaDMCCMDS6Jdaaqmoq6uLgw8+uM3qphInRgAiACvRjhpKAwGYJV3ShgAEIJAhgWoVgE0tVBkyZEhOwLU0ePFEnz59olevXi1Nol3EQwB2LAF4qIpzjGwp2bOyw2WjymhpP9Yx/5T9V7ZnwfH2gA6V/VK2kOxR2a9kY8tI04cgAMsExWEQgAAE2huBahWAH3744Vcor7/++jjllFPi1Vdf/eo3izdbYfDKWK+I9d54tRIQgB1HAO6jolwts0/6CdlRsr1kq8s+bqSYA/S3EbI3ZZNkhQLwd/r38bJ9ZeNkp8nWla0lm15GJ8lGAL50S8TLspUGRQz8WRnZ4BAIQAACEGgugWoVgIXlHDZsWBx11FExefLk+Yp/1113xc477xx33313HHvssfHiiy/GI488EgsttFAcffTRMWrUqPjyyy9j7bXXjrPOOisGDdL9Jh8Kh4DNyJ5An+fGG2+MBx54IJZffvn44x//mEu/PQcEYOO1U01zAC36npQdli+SN/V5R3ax7KwGitlFvz8su0K2tcxevkQAuuzvy86XnZePv6A+P5INll1XRsPORgAOV3GGnxmx8f4Ru/6hjGxwCAQgAAEINJdAKYFgT9mXs1r/jSC9unVp0R6ETQnADTfcMM4777ycaFtsscXi9ddfjzFjxsTmm28e3bp1i8suuywuvfTS3H6I3jTZoZQA9FY55557bgwcODCXnj2P3mKlXz/fBttnQAA2Xi/VIgC9jbe3af+R7OaCIl2VF3V7NFBMD++uJ/u+bFj+2EQArqR/vyEbKBtTEP+h/L+PLJFmD/1mS0JffXl3ypQple0ECMD2eTUhVxCAQIciUEogTJs5O9Y65e5WL+dLp+4Yvbs3f3i2KQFoT+COO+7YaHlWWWWVOO644+KAAw7IHVdKAJ5++ulx4okn5v4+adKkWHTRRePBBx+cz3PY6tCaOCECsHFA1SIAl1Ex3pNtIRtZUKRz9H0b2aYlirmVfrMXbwPZRNkwWaEH0Gl5zp/T/qAg/g36Pk/mIefiUKcfhhT/iABsb92e/EAAAhBomkAtCMCJEyfmxFoSfL/yIhELQ88l9DuQPRRscXfqqafmDislAG+55ZbYbbfdvkqnR48ecc0118Tee+/dNOg2OgIB2Dj4jioA7Zl7TnaI7M48gmH6TCsAW9kD+AsNAV/QRl2H00IAAhDo2ARqYQjY4q7wLRiDBw+OkSNHxtlnnx0rr7xybn6fhd0ee+yRmwvYkAC88847Y6eddvqqQThNex9//GOvsWyfAQHYMQRgc4eA7fUbLSucyJG8CHCufvfCEXv5mjsEXEwzozmAZ2sO4BmaA4gAbJ+XFXIFAQh0BAK1sAikWAD6vbgHHnhgHHOMN9SI3OKR5ZZbLg477DAEYEdo1M0oQ7V4AF0kLwLxli/e+sXBgu5t2SWy4kUgfunfKkUcTte/7Rn03L7XZLNkXgTiBSBeCOJgQecVxYNlbbgIBAHYjDbMoRCAAARaRKAWBeAuu+wSHhb24g9vC+Oh3xEjRsQhhxyCAGxRK6reSNUkAD0nz4s+DpJZCHobGE8+WEPmlbveIsbzBL2tS6kwTD8WDgH7GG8Dc5yscBsYLxpp221ghiMAq7dLkXMIQKBaCNSiAPQq4P333z+efPLJWGKJJXIC8PLLL88t5mAIuFpabmXyWU0C0CX2FjDJRtBeuXuEzJ5Bh+Gy8bLBDaApJQCTjaAPzItD7xfoeYP2EJYTsh0C3mi/iN3+WE4+OAYCEIAABJpJoCMIwGYWuaYOZw5g49VdbQKwvTXebATgQ1rc/ODvIxCA7a2+yQ8EINCBCCAAO1BlligKAhABmGULRwBmSZe0IQABCGRIAAGYIdx2kDQCEAGYZTNEAGZJl7QhAAEIZEgAAZgh3HaQNAIQAZhlM8xYAA7WHMALs8w/aUMAAhCoWQIIwI5d9QhABGCWLTwjAXiu5gBq15qNEIBZVh5pQwACtU0AAdix6x8BiADMsoUjALOkS9oQgAAEMiSAAMwQbjtIGgGIAMyyGWYrADfU9oS7X5Rl/kkbAhCAQM0SQAB27KpHACIAs2zh2QjAhzUE/ICGgBGAWdYdaUMAAjVOAAHYsRsAAhABmGULRwBmSZe0IQABCGRIAAGYIdx2kDQCEAGYZTNEAGZJl7QhAAEIZEig1gXgz372szCDf/3rXznKW221VWy22WZx3nnnNUh9ueWWi+OOOy4OO8wv5mp5qFQ6jeUAAYgAbHkLbTpmxgLw55oDeHHTueAICEAAAhBoNoFqFYC77bZbzJo1K+66665vlPmRRx6Jb3/72/Hss8/Geuv51fYNh2IBOGnSpOjWrVv07du3YgLwsssuywnGiRMnzpfmhAkTYoEFFojevXs3u97KjYAARACW21ZaclxGAlBPXw+cpjmACMCWVApxIAABCJRDoFoF4M033xw//OEP46233gp70grDL37xi3j++efjySefbBJBsQBsMoIOaK7nriEBWM650h6DAEQApm1DjcVHAGZJl7QhAAEIZEigWgXg7Nmzc0LMw7AnnXTSV4Q+//zzWHrppePcc8+N/fffPw466KB44IEH4qOPPooVVlghd/zhhx/+1fFNDQF/+OGHccABB8T999+fS/eMM86Io48+er4hYJ/rqquuijfffDMWXXTR2GOPPeLss8/Oeffuu+++2H777eerwdNOOy2X52IhOX78+DjiiCNy5+ratWvsvPPOcfHFF8fiiy+ei+849ng6/6ecckpMnjw5dt111/jrX/8affr0KdlKEIAIwAwvH4EAzJIuaUMAAhDIkEBJgTBvXsSsaRmetYGku2kotFOnss977LHHxr///e8YO3asotXHu/LKK+PQQw+NDz74IHr06BFnnXVWTiRZmI0YMSInCP/+97/HD37wg9zxTQnAHXbYITd0+5e//CV3Dgu0MWPG5ARmMgfwggsuiIEDB8aAAQPijTfeiF/96lex0047xUUXXRQzZ86MSy65JH7/+9/Hiy++mDunh5ctDgsF4Ny5c2ODDTaIRRZZJP7whz/k4jkd59siMhGAF154YU4YWgB+8sknsffee8fBBx8cQ4cORQCW3XK+PrD81taCxGsgSrYCcOD/RuxxSQ1gpIgQgAAEWp9ASQE484uIM5Zp/cyc8H5E9wXKPu8rr7wSa665Zjz44IMxaNCgXDzP/evfv39cc801JdOxWLLn7LrrrmtSAL700kux9tprxzPPPJMTeA4vvPBCrLvuujnPXEOLQJz2UUcdFfYeOjQ0BFwoAO+8887Yfffdc0PayyxTz/65556L9ddf/6vz2wNoAeh0LSAdfvOb38SoUaNy4rZUwAPYeHNCAJbd3UoemI0AfOT8iPtPjUAApqsdYkMAAhBohEA1C0AXa8stt4yVV145rr766nj99ddj1VVXnU8QWqgNGzYsJ6xcVnvWNt5443jssceaFIA33XRT/PSnP40vv/zyKw+jI/Xr1y83FJwIwHvuuSfnabQgnTp1asyZMyd3Lpu9kOUIQHv9/vznP+e8mYXB3kIP8f7kJz/JDQHfeuutucUtSbAn8m9/+1u89tprCMAW9HQEYAugFURBAKbjR2wIQAACbUagmoeADe2KK67IzYmzV8wi7Prrr/9qSNhDvQceeGBuSHXTTTfNDb36GA/hPvXUUxURgB7yXWuttXJi0MOxCy+8cDz00EO583722We5uXmVFICeA5jk3QXwdjUenrb4LRXwADbetRCA6S49CMB0/IgNAQhAoM0IVOsikARYsujDQuj000/PzZs74YQTcn/2dy/MuPvuu7/i66FixylHAJYaAvY8vnXWWeerIWALzn333Tfn7UtCXV1dbk5eIgDtnTzyyCPj008/na+eyx0CHj16dG5+YLIIBAFYue6CAEzHMhMB+OQ1J8Ymb1wSzy2+W6x36N/T5ZDYEIAABCDQbA9RtSDzKl0vBvHw69tvv/3VHDp7/k499dS48cYbc/MCPRT8pz/9KTdMXI4AdPm9gtfCzcOzXgRiIec5gckikKeffjo3pOyh5l122SW8B+Hxxx+fW4SSCMCHH344N0fRq5EtHj1/r1evXiUXgXjRh/M9Y8aMOOSQQ3KLQgoXgeABrGyrRACm45mJABxx5Qmx1Vt/iqcX+V5sdMQ/0uWQ2BCAAAQg0GEF4MiRI2OLLbbICbDbb41wUwwAACAASURBVL/9q3LaK+eh2FtuuSU6d+6cm0fnTZctxMoVgBZy3k7GcZZaaqnc3D+vPi58E4i9j+eff35MmTIlJ/T22WefGDx48FcCcJ5WVXv1sUWqV+42tg2Mh7N9rsa2gcEDWLnOjABMxxIBmI4fsSEAAQi0GYFqHwJuM3BVcmLmADZeUQjAdA05UwH4lDyAG+MBTFdDxIYABCDQAAEEYMduGghABGCWLTwTAfjolSfGlm9dEk8vvEtsdOQ/s8w/aUMAAhCoWQIIwI5d9QhABGCWLTwTAThi2Imx1fhL4ikJwI0RgFnWH2lDAAI1TAAB2LErHwGIAMyyhWciAB+VANwSAZhlvZE2BCAAgdz2JePGjYsVV1wxevbsCZEORgABiADMskkjALOkS9oQgAAEMiSAAMwQbjtIGgGIAMyyGSIAs6RL2hCAAAQyJJAIhAEDBuT2piN0LAJ+jd348eNLeni9b+KCCy7oAvt/UztWycsrDauAy+PU0FEZCcCTNAR8MXMA09UNsSEAAQg0SsDvrfV7ZJdYYonwJsSEjkXA+w5+/PHHsdpqq0WXLl3mKxwCMAIBmK69IwDT8SM2BCAAgTYl4M2OJ0+enBOB3ijZb7wgVDcBbz49bdq0nPhbaKGFYumll/5GgRCACMC0rTxjAbizVgFflzaPxIcABCAAgQYIWCx8+OGHORFI6FgELP78BpNSoh4BiABM29qzEYBXaQh43MXaB3An7QN4fdo8Eh8CEIAABJog4OHgWbNmwamDEOjWrds3hn0Li4YARACmbeoZCcCTJQAvQgCmrR3iQwACEIAABEoQQAAiANN2jGwF4ELyAB6FBzBtJREfAhCAAAQggAdw/jbAbNd0fSITAfjY1afEFm9eGE8jANPVDrEhAAEIQAACeABLtgEEYLqugQBMx4/YEIAABCAAgVYnwBAwQ8BpG10mAvBReQC3xAOYtm6IDwEIQAACEChJAAGIAEzbNRCAaQkSHwIQgAAEINDKBBCACMC0TQ4BmJYg8SEAAQhAAAKtTAABiABM2+QyFoA7ahXwDWnzSHwIQAACEIAABAoIIAARgGk7RDYC8JohseUbf9QqYARg2goiPgQgAAEIQKCYAAIQAZi2VyAA0xIkPgQgAAEIQKCVCSAAq08AHqo2coxsKdmzssNloxpoNz/Q7yfIVpF1k42VnS+7puD4Yfq+b1H8u/Xvncpsi9kKwAV3iI1+fWOZWeEwCEAAAhCAAATKIYAArC4BuI8q9WrZwbInZEfJ9pKtLvu4RIUP0m8Ly16RzZTtmheA39OnRZ7DMNmSsv0K4s/Q90/LaUA6JiMBOFRDwH+IpxGAZVYDh0EAAhCAAATKJ4AArC4BaNH3pOywfBV31uc7sotlZ5VZ7c/ouNtlJxcIwIX0fc8y4xcfhgBsITiiQQACEIAABNqKAAKwegRgdzWSabIfyW4uaDBX6bsF3B5NNCK/8WRb2S15sXdvgQC0+LOH0F6/B2QnyT4ps1EiAMsExWEQgAAEIACB9kIAAVg9AnAZNZr3ZFvIRhY0oHP0fRvZpg00qgXz8Xroc47sENkVBcf+WN8tLMfJVpadIftctnn++OJknY4tCX315d0pU6ZEv37WgpUJj10zNLbIDQFvrzmA/6pMoqQCAQhAAAIQgECOAAKw4wtADxOvJOsj+67MQ7/2+A1voA/42Ddk28nuL3FMnX4bUvx7xQXg3yUAX0cAcp2CAAQgAAEIZEEAAVg9AjDtEHDSfi7Tl+VlOzbSoCbobx4G/muJY1rHA4gAzKK/kyYEIAABCEAgRwABWD0C0PXlRSDe8sVbvzjYu/e27BJZuYtAPPxrL9+gBvrAcvk07SX0fMGmQiZzAB9DADbFnb9DAAIQgAAEWkwAAVhdAtDbwHjRx0F5IehtYPaWrSH7SOYtYjxP8Ph8i/DnUzIP6dpzt4vMQvFXMnsCPSzs4dybZB/KPAfQcwo9r29dmbeDaSpkKgCf6bddbPgbZ48AAQhAAAIQgEClCCAAq0sAut69BUyyEfQYfT9CZs+gw3DZeNng/L9P16dFo716X8q8H+CFsuvzf++lT68oHijzSuL3ZffIPE/QgrKckJEAPFVzAM+PpyUAN0IAllMPHAMBCEAAAhAomwACsPoEYNmV20oHZiMAr5UAHIsAbKU65DQQgAAEIFBjBBCACMC0TR4BmJYg8SEAAQhAAAKtTAABiABM2+QyFYDP9Puu5gD+O20eiQ8BCEAAAhCAQAEBBCACMG2HyEgAnq4h4HMDAZi2eogPAQhAAAIQ+CYBBCACMG2/QACmJUh8CEAAAhCAQCsTQAAiANM2uUwF4NMaAt6IIeC0dUR8CEAAAhCAwHwEEIAIwLRdIhMBOPLa02Pz3BDwtpoD+J+0eSQ+BCAAAQhAAAIFBBCACMC0HSIbAfgPCcDXEIBpK4f4EIAABCAAgVIEEIAIwLQ9I1sB2FcewN/iAUxbScSHAAQgAAEIFBJAACIA0/YIBGBagsSHAAQgAAEItDIBBCACMG2Ty1gAfkceQL+tjgABCEAAAhCAQKUIIAARgGnbUiYC8LF//D62eO2ceKYvAjBtBREfAhCAAAQgUEwAAYgATNsrMhGAI/9xhhaBnI0ATFs7xIcABCAAAQiUIIAARACm7RiZCsCn5QHciCHgtHVEfAhAAAIQgMB8BBCACMC0XSJTAcgQcNrqIT4EIAABCEDgmwQQgAjAtP0iGwH4zzNj81fPYgg4be0QHwIQgAAEIMAQcMk20ImWkYoAAjAVPiJDAAIQgAAEWp8AHkA8gGlbXSYC8HF5ADfDA5i2bogPAQhAAAIQKEkAAYgATNs1MhaAg7QP4H/T5pH4EIAABCAAAQgUEEAAIgDTdohMBODI6zQH8BXNAeyzTWx49C1p80h8CEAAAhCAAAQQgPO1AeYApusSmQjAxyUAN0MApqsZYkMAAhCAAAQaIIAHEA9g2s6BAExLkPgQgAAEIACBViaAAEQApm1yCMC0BIkPAQhAAAIQaGUCCEAEYNoml5EAPFtDwGcwBzBt7RAfAhCAAAQgUIIAAhABmLZjIADTEiQ+BCAAAQhAoJUJIAARgGmbXKYCcHSfb8fAo29Nm0fiQwACEIAABCBQQAABiABM2yGyEYDXnxObvfz7QACmrR7iQwACEIAABL5JAAGIAEzbLxCAaQkSHwIQgAAEINDKBBCACMC0TS5TAfiMhoA3ZAg4bR0RHwIQgAAEIDAfAQQgAjBtl8hEAD6hIeBNPQS8wNYx8Jjb0uaR+BCAAAQgAAEIFBBAACIA03aITATg4zdoDuBLCMC0lUN8CEAAAhCAQCkCCEAEYNqegQBMS5D4EIAABCAAgVYmgABEAKZtchkJwHPlATydIeC0tUN8CEAAAhCAQAkCCEAEYNqOkbEA3EpzAG9Pm0fiQwACEIAABCBQQAABiABM2yEyEoDnyQN4mjyACMC0FUR8CEAAAhCAQDEBBCACMG2vyEQAPnHDebEpAjBt3RAfAhCAAAQgUJIAAhABmLZrIADTEiQ+BCAAAQhAoJUJIAARgGmbXMYCcEvNAbwjbR6JDwEIQAACEIBAAQEEIAIwbYfIRgDeeH5s+uKpmgOIAExbQcSHAAQgAAEIFBNAACIA0/YKBGBagsSHAAQgAAEItDIBBCACMG2Ty1YA9pYH8FiGgNNWEvEhAAEIQAAChQQQgNUnAA9VBR4jW0r2rOxw2agGmvUP9PsJslVk3WRjZefLrik4vpO+D5X9UraQ7FHZr/LHltNbMhWAY3pvERsce2c5+eAYCEAAAhCAAATKJIAArC4BuI/q9WrZwbInZEfJ9pKtLvu4RJ0P0m8Ly16RzZTtmheA39Pn3fnjf6fP42X7ysbJTpOtK1tLNr2MdpSNAPzXH2LTF4YGArCMGuAQCEAAAhCAQDMJIACrSwBa9D0pOyxfz531+Y7sYtlZZdb9MzrOr9Y4WWbv3/t5UXhePv6C+vxINlh2XRlpZioAR8sDOBAPYBnVwCEQgAAEIACB8gkgAKtHAHZXtU6T/Uh2c0EVX6XvHrrdo4lqt9jbVnaLbE/ZvbKVZG/IBsrGFMR/KP/vI8toSpkIwFHyAH5LHkAEYBk1wCEQgAAEIACBZhJAAFaPAFxGdfuebAvZyIJ6Pkfft5Ft2kDd26PneD1kc2SHyK7IH+u0POfPaX9QEP8GfZ8n85BzcXA6tiT01Zd3p0yZEv36WQtWJiQCkCHgyvAkFQhAAAIQgEAhAQRgxxeAHia2p6+P7LsyD/3aAzhc1hIBWKd4Q4q7UaUF4BM3XRCbPl+HB5DrFQQgAAEIQCADAgjA6hGAaYeAk+Zzmb4sL9sxLwybOwTcOh5ACcBvIQAz6PIkCQEIQAACEIhAAFaPAHR79SIQb/nirV8c7N17W3aJrNxFIB7+tUdwkCxZBOIFIN4exsHjuF5RPFjWZotARiEAuT5BAAIQgAAEMiOAAKwuAeg5eV70cZDMQtDbwOwtW0PmlbveIsbz/byti4M/n5LZy2fP3S4yC0Xv82dPoIO3gTlOVrgNzHr6d5tuA5MIwDG9N9c+gHdl1gFIGAIQgAAEIFCLBBCA1SUA3Ua9BUyyEbRX7h4hs2fQYbhsvGxw/t+n69OicTnZlzLvB3ih7PqCxp5sBH2gfvNq4hEyLxR5rcwOkc0q4Jv+qCHgIdoHEAFYZj1wGAQgAAEIQKBsAgjA6hOAZVduKx2IAGwl0JwGAhCAAAQgUCkCCEAEYNq2lK0A7CUP4O8YAk5bScSHAAQgAAEIFBJAACIA0/aITATgkxoC3sRDwL02kwBM3lqXNqvEhwAEIAABCEDABBCACMC0PSEbAfjvC2OT505BAKatHeJDAAIQgAAEShBAACIA03YMBGBagsSHAAQgAAEItDIBBCACMG2TQwCmJUh8CEAAAhCAQCsTQAAiANM2uYwF4KaaA3hP2jwSHwIQgAAEIACBAgIIQARg2g6RjQD8z0WxybMnaw4gAjBtBREfAhCAAAQgUEwAAYgATNsrEIBpCRIfAhCAAAQg0MoEEIAIwLRNDgGYliDxIQABCEAAAq1MAAGIAEzb5DISgBdrCPikeLbXt2L9392bNo/EhwAEIAABCECggAACEAGYtkNkIwBvlgAcgwBMWznEhwAEIAABCJQigABEAKbtGZkKwDE9vxUbHIcHMG0lER8CEIAABCBQSAABiABM2yMyEYBPyQO4sT2APTeJ9Y+7L20eiQ8BCEAAAhCAAEPA87WBTrSIVAQyEYBP3nyJhoBPRACmqhoiQwACEIAABEoTwAOIBzBt30AApiVIfAhAAAIQgEArE0AAIgDTNrlMBOBT8gBujAcwbd0QHwIQgAAEIFCSAAIQAZi2ayAA0xIkPgQgAAEIQKCVCSAAEYBpm1w2AvC/f4qNR5+gOYAbaxHI/WnzSHwIQAACEIAABAoIIAARgGk7BAIwLUHiQwACEIAABFqZAAIQAZi2ySEA0xIkPgQgAAEIQKCVCSAAEYBpm1ymAvA5DQGvxxBw2joiPgQgAAEIQGA+AgjA1hOAPUR+Rgdsf5kIwKdv+XNs9MxxgQDsgC2GIkEAAhCAQJsTQABmJwB3Vu3+WLa1bHlZZ9kXstGye2RXyt5v8xaQPgMIwPQMSQECEIAABCDQqgQQgJUXgN9XDZ4t6yu7QzYqL/S+1OcisnXyonBzfQ6TnSyb0Kq1XtmTZSsAe2gI+HhWAVe2ykgNAhCAAARqnQACsPICcKQa1emyO2VzG2lgy+pvh8s+kl1QxQ0xYwG4kQTgA1WMh6xDAAIQgAAE2h8BBGDlBWD7q+Vsc5SNALxVcwCf1hzAHgjAbKuP1CEAAQhAoBYJIAARgGnbPQIwLUHiQwACEIAABFqZAAIwGwH4kupxK9mkfH1eqs9TZBPz/15Cn+NlvVu5vrM4HQIwC6qkCQEIQAACEMiQAAIwGwHouX9LyT7O191UfW4gezP/7yX1+YHMK4OrPWQqAJ/vsWGse/yD1c6I/EMAAhCAAATaFQEEYOsIwM9U6+sXCUBvAdOlXbWGlmUmIwH4F80B/J3mAG6oRSAIwJZVDbEgAAEIQAACpQkgABGAaftGNgLwtr/GRk8diwBMWzvEhwAEIAABCJQggADMRgDOEWsPASf7+9kDuJ5sXL4OPASMB7CRLvk0ApALFgQgAAEIQCAzAgjAbASg5wC+IJudrzmLv1dkM/P/7qrPtWUMATfQtBMB+Hz3gbHuCcMz6wAkDAEIQAACEKhFAgjAbATgkDIb09Ayj2vPh2UyBPzMbf8XGz51TCAA23PVkzcIQAACEKhWAgjAbARgtbaHluQbAdgSasSBAAQgAAEItCEBBGDrCsBtVNcLyPy6uE/bsN4reepMBeBzGgJejyHgStYXaUEAAhCAAAQCAZiNAPyd2lYf2cn5NtZJn3438A75f3t/wO/KXuwAbTAbAXi7hoCf9BDwBpoD+FAHwEQRIAABCEAAAu2HAAIwGwH4jKr4bNn1+areS59XybaXvSy7WjZNtnf7aQotzklGAvBvEoBHIwBbXC1EhAAEIAABCDRMAAGYjQD08O4WebFn+lfKvOL35/mq2EyfN8qW7wCNEwHYASqRIkAAAhCAQG0RQABmIwCL3/zhLWD+KPtLvnmtoM9XZb06QHPLRACOvv1vMRAPYAdoHhQBAhCAAATaIwEEYDYCcExe8A3Tp8XeeNk6spfyjcDewRtky7WgURyqOMfIvNH0s7LDZaMaSOeX+t1eR5/b4WnZCUXHO4/7FsW/W//eqcy8IQDLBMVhEIAABCAAgfZCAAGYjQC08LpA5jmAHu6dLNuyoNJP0vdNZbs1syHso+M9f/Bg2ROyo2SeX7i6zAtLisO1+uFR2WOy6TIvTvm+zJtQv5c/eJg+/WaS/Qoiz9D3clcpZyIAn7n9Ms0B/C1zAJvZQDgcAhCAAAQgUA4BBGA2AtDsfyGzwPtQ5g2f/ZmES/XlXtl/yqmkgmMs+p6UHZb/rbM+35FdLDurjLQ8D9HCzvEtJB2GyRaS7VlG/FKHZCIAR99xWQwchQBsYZ0QDQIQgAAEINAoAQRgdgKw0k2vuxL0yuEfyW4uSNyriy3g9ijjhH11jD2F9hreViAALf78mjqLwwdk9lB+UkZ6PgQBWCYoDoMABCAAAQi0FwIIwOoRgMuo0XjY1vMHvZF0Es7RF28w7SHlpoI9jzvKPATsIWGHH8ssLMfJVpadIftctrlsTokEe+g3WxIsKt+dMmVK9OtnLViZMEYewA3kAXyh+/qxzgkPVyZRUoEABCAAAQhAIEcAAZiNACwlnEo1OQ/JlhvSCsDjdKJjZYNkzzVy0pX0tzdk28nuL3FcnX77xruOKy0AR99xuYaAf4MALLd1cBwEIAABCECgGQQQgNkIwLmqg7dkHp4d3Uh9/LcZdZVmCPhoncfDuhZ1T5Vxzgn54/9a4thW8QAiAMuoJQ6BAAQgAAEItJAAAjAbAbix6mN/mYdXPbR6hcwrcstdWdtQdXoRiLd88dYvDl4E8rbsEllDi0Ds9TtR5qHfx8toJ96axml6XuAtZRyfyRzAMXdeHhs8YQ/gehoCfqSMbHAIBCAAAQhAAALlEkAAZiMAE/499cWLNrzFireDuVV2ucwrgFsSvA2MvYoHySwEvQ2MXye3huwjmVf2ep7g8fnEve3LqbKfyLwdTBI8x8/m9xV7OPcmmVcpew6g5xR6Xt+6Mm8H01TISABeIQH4awRgU/T5OwQgAAEIQKAFBBCA2QrAwipZUf+w+POCjcVlk1pQX47iLVySjaC94fQRMnsGHYbLxssG5//t7/1LnMfb0tTJ/CYSrygeKPNK4vdl98hOlllQlhOyFYDd5AE8EQ9gORXBMRCAAAQgAIFyCSAAsxeAHlK1ILP1ltlL5/l4s8utpHZ+HAKwnVcQ2YMABCAAAQgUE0AAZiMAvWDDb9zwPMCtZXfKPA/Qn+WuEK6W1pqpAHyx27qx9okjqoUF+YQABCAAAQhUBQEEYDYC0JsofybzfL1rZKVe0+YGMrUqWknjmcxEAI6+68oY+PhR8YIE4DoIwA7QTCgCBCAAAQi0JwIIwGwEoLeBScK8EhXeSb/59+bsA9ie2k1hXjIRgGMkADdAALbXOidfEIAABCBQ5QQQgNkIQC/0KCc8VM5B7fwYBGA7ryCyBwEIQAACECgmgADMRgDWUkvLVAC+2G0dzQEs3MGmltBSVghAAAIQgEA2BBCAlReAC6iqvmhGdTX3+GYk3SqHZiIAn717WKw/8shAALZKHXISCEAAAhCoMQIIwMoLwA/Uhi6UeQGIv5cKngPo17L9Rvaw7MwqbncIwCquPLIOAQhAAAK1SQABWHkBuLqa0hmy78melfndu95gebpsYdlass1l3gfQws/v263mrWEQgLV57aDUEIAABCBQxQQQgJUXgElzWEFf9pJ5H0C/jcNv3ZgoGy27W9ZR9gTMSABepSHgIzQEvLbmAD5WxV2MrEMAAhCAAATaHwEEYHYCsP3VdjY5ykYA3nN1rP/Y4QjAbOqMVCEAAQhAoMYJIAARgGm7AAIwLUHiQwACEIAABFqZAAIQAZi2yWUiAJ+TB3A9PIBp64b4EIAABCAAgZIEEIAIwLRdI1MB+FLXtWOtk5gDmLaSiA8BCEAAAhAoJIAARACm7RGZCMBnkzmAEoBrIwDT1hHxIQABCEAAAvMRQAAiANN2iUwE4HP3agj4US0CQQCmrR/iQwACEIAABL5BAAGYrQDcScQ/l43Ikz9Un7+UvSTz9087QJtEAHaASqQIEIAABCBQWwQQgNkKwOfVnH4nu0O2ruxJ2R9k35G9ItuvAzS3TAXgS13X0hzAkR0AE0WAAAQgAAEItB8CCMBsBaC9f+vIxsvq8t9/pM8N86JwqfbTFFqck2wE4H3XxHojDgsEYIvrhYgQgAAEIACBBgkgALMVgJNEfiuZh3w9DHy17P9kA/K/9e4AbRMB2AEqkSJAAAIQgEBtEUAAZisAb1Fz6i57VHaybEXZe7IdZJfIVusAzQ0B2AEqkSJAAAIQgEBtEUAAZisA/T7gS2XLyy6SXZ5vXhfos4vsiA7Q3DIRgM/f9/dYd8Sh8XLXNWPNkx7vAJgoAgQgAAEIQKD9EEAAZisA209NZ5eTjATgtRKAhyAAs6s3UoYABCAAgRomgADMVgB6sccsmVcDO+wh88pfzwmsk83sAG0vUwH4kjyAa+EB7ADNhCJAAAIQgEB7IoAAzFYAetuXs2Q3yVaSvSj7j2wT2e2yo9pTY2hhXrIRgPfLA/jIIVoFjABsYb0QDQIQgAAEINAgAQRgtgJwisjbC/iGzPsBbivbUbal7DqZ5wZWe8hUAL7cdQ3NAXyi2hmRfwhAAAIQgEC7IoAAzFYATlVtbyQbK7tXdpvsQpkXh7wq69WuWkPLMpORAPyHPIC/0hxABGDLqoVYEIAABCAAgYYJIACzFYAPCP07svtkXgG8lux12Tayq2QDOkDjRAB2gEqkCBCAAAQgUFsEEIDZCsD11JyuzXv8/Aq4ofnmdbE+F5X9pAM0NwRgB6hEigABCEAAArVFAAGYrQBsqDX11B/myLxCuNpDtgKwy+qx5smjqp0R+YcABCAAAQi0KwIIwNYRgJ4HuGa+5r0FzDPtqhWky0wmAvCFB/4Z6zx8cLyMAExXO8SGAAQgAAEIlCCAAMxWAC4h5tfLPOdvcp7/Qvp8UPZj2YQO0CoRgB2gEikCBCAAAQjUFgEEYLYC0OLP+//9XPZyvml5IYgXgHgxyP90gOaWqQB8RR7ANRgC7gDNhCJAAAIQgEB7IoAAzFYAeh/A7WTeELowfEv/uEdmb2C1h4wE4HUaAj4oEIDV3jzIPwQgAAEItEcCCMBsBeBnqvStZWOKKn+g/v2QzOKp2gMCsNprkPxDAAIQgEDNEUAAZisA/5v38nmo9/1861pWn94a5lPZ9ztAi8tEAL744HWx9kN4ADtA+6AIEIAABCDQDgkgALMVgH7V2y2ytWXeENrBv70g2132bjtsE83NUsYCcDXNASweQW9uFjkeAhCAAAQgAIFCAgjAbAWgWXeSeR7gGnnwXgziN4N0lJCRALxBHsBfag4gArCjNBTKAQEIQAAC7YcAAjB7AViqtpfTj6fIDmw/TaHFOclEAL40/IZYazgCsMW1QkQIQAACEIBAIwQQgG0jANdXnXgz6C4doHVmIgBflgBcEwHYAZoHRYAABCAAgfZIAAGIAEzbLjMWgKtqDuBTafNIfAhAAAIQgAAECgggABGAaTtENgLwoRtjzQcPiFc6SwCeggBMW0nEhwAEIAABCBQSQABWnwA8VBV4jGwp2bOyw2WjGmjWv9TvfgvJOvm/P63PE4qO9yKVoTIf642pH5X9Sja2zK6CACwTFIdBAAIQgAAE2gsBBGA2AvDfTVSwhZbfD9zcOYD7KM7VsoNlT8iOku0lW132cYlzer9BC7rHZNNlv5N570FvS/Ne/nj/drxsX9k42WmydWV+ZZ3jNBUyEYCvPHxjrPEAHsCm4PN3CEAAAhCAQEsIIACzEYBXllkZ+5V5XHKYRZ83xTss/0NnfXp/wYtlZ5WRlgWnN6B2fAtJe/+8QfX5svPy8RfU50eywbLrykgzYwG4ioaA7bgkQAACEIAABCBQKQIIwGwEYKXqpzCd7vrHNNmPZDcX/OEqfbdHcY8yTtpXx9hTaK/hbbKVZG/I/Gq6wtfV+TV1/veRJdLsod9sSXCa706ZMiX69avcm+1eefhf8gDurzmACMAy6pVDIAABCEAAAs0igACsHgG4jGrWw7ZbyEYW1PI5+u7h5E3LqPlLdcyOMg8Be3jXaXmI2Gl/UBD/Bn2fJ/OQc3Go0w9Din+stAB89ZGbYvX7f4EALKNSOQQCEIAABCDQXAIIwNoRgMepcRwrGyR7Lt9QWiIAW8UD+NqIBLCkpAAAIABJREFUm2K1+xCAze3QHA8BCEAAAhAohwACsHoEYJoh4KPVGE6S+ZV0hXuqtGQIuLhdZTIHMBGAr3ZeOVY/xXtmEyAAAQhAAAIQqBQBBGD1CEDXuReBeMsXb/3i4EUgb8sukTW0CMRevxNlHvp9vKjhJItAvADEC0EcLOg8T3CwrM0Wgbw24t/yAO4XCMBKdXXSgQAEIAABCHxNAAFYXQLQc/K86OMgmYWgt4HZW7aGzCt3vbLX8wS9rYuDt3g5VfYTmef6JeFzfbElx3h4uHAbmPX07zbdBmbso/+OVe/dT3MAV9YqYDyAXLQgAAEIQAAClSSAAKwuAei69xYuyUbQXql7hMyeQYfhsvGywfl/+3v/Eg3GGz/X5X9PNoI+UP/2auIRskNkr5XZ0DIZAkYAlkmfwyAAAQhAAAItIIAArD4B2IJqzjRKJgLwdXkAV5EH8NVOK8XqQ0ZnWgAShwAEIAABCNQaAQQgAjBtm89GAD72n1jlnsEIwLS1Q3wIQAACEIBACQIIQARg2o6BAExLkPgQgAAEIACBViaAAEQApm1ymQjAN0beHCvfvW+8oiHgNRgCTltHxIcABCAAAQjMRwABiABM2yUyEYBvSgCuJAHIHMC01UN8CEAAAhCAwDcJIAARgGn7RUYC8L8SgD9HAKatHeJDAAIQgAAEShBAACIA03aMbATg4xKAd1kArqhVwN7thgABCEAAAhCAQKUIIAARgGnbUiYCcNzjt8SKd/0vAjBt7RAfAhCAAAQggAewZBvwRsiElhPIRACOlwAcgABsea0QEwIQgAAEINAIATyAeADTdpBsBOATt8aAO3+GBzBt7RAfAhCAAAQggAcQD2AGvQABmAFUkoQABCAAAQhkSQAPIB7AtO0rGwE4Sh7AO+QBDC0CqWMRSNpKIj4EIAABCECgkAACEAGYtkdkIgDfGnVb9L/jp/Fa9I/V6p5Lm0fiQwACEIAABCBQQAABiABM2yGyEYBP3hH9b/+feD1WiFXqnk+bR+JDAAIQgAAEIIAAnK8NsAo4XZfIRgA+fXf0v3XveCOWi5XrXkyXQ2JDAAIQgAAEIDAfATyAeADTdolsBOAz90T/W/aKcbFsrFj3Uto8Eh8CEIAABCAAATyAeAAr2AsyEYBvj74/VvjvD2J8LBMD6l6uYHZJCgIQgAAEIAABPIB4ANP2gkwE4FtjHoz+N+8Z78RSsXzdq2nzSHwIQAACEIAABPAA4gGsYC/IRAC+/ezwWOE/e8S7sUQsVze2gtklKQhAAAIQgAAE8ADiAUzbC7IRgM8/EivctGu8H4vHMnWvp80j8SEAAQhAAAIQwAOIB7CCvSATAfjOC4/G8v/aJT6IRWPpujcrmF2SggAEIAABCEAADyAewLS9IBMB+PaLj8cKN+4YH8UisWTduLR5JD4EIAABCEAAAngA8QBWsBdkIwBfeiJWuGGHmBALxeJ1b1UwuyQFAQhAAAIQgAAeQDyAaXtBJgLwnVeejOWv2y4+iQVj0bq30+aR+BCAAAQgAAEI4AHEA1jBXpCRAHxaAnDbmBR9Y5G6dyuYXZKCAAQgAAEIQAAPIB7AtL0gEwH47tgxsdy128TkeX1ioaHvpc0j8SEAAQhAAAIQwAOIB7CCvSATAfjO2Odi+Wu3jinzFogFh75fweySFAQgAAEIQAACeADxAKbtBZkIwHdffyGW+/uW8fm8XtFn6Idp80h8CEAAAhCAAATwAOIBrGAvyEQAvvfmS7Hs1ZvHtHk9ovfQjyuYXZKCAAQgAAEIQAAPIB7AtL0gGwE47tVY9qpvxZfzukevoRPS5pH4EIAABCAAAQjgAcQDWMFekI0AHD82lh22ccyY1y16DJ1YweySFAQgAAEIQAACeADxAKbtBZkIwPfffiOWuWLDmDmvS3QfOiltHokPAQhAAAIQgAAeQDyAFewFmQjA994ZF8tevkHMmdcpugydXMHskhQEIAABCEAAAngA8QCm7QWZCMD3330rlrlsvfq81U1Jm0fiQwACEIAABCCABxAPYAV7QTYC8L23Y5m/rVufzSHyAHbqVMEskxQEIAABCECgtgngAcQDmLYHZCIAP/jgvVj6r2vV5+0UzQHs3CVtPokPAQhAAAIQgECeAAIQAZi2M2QjAD/8MJb+y+r1eTtZq4C7dEubT+JDAAIQgAAEIIAA/KoNMLaYrjtkIgA//PjjWOrSVetzduJHEd16psslsSEAAQhAAAIQ+IoAHkA8gGm7QzYCcMLEWOpPK9fn7YQPIrr3TptP4kMAAhCAAAQggAcQD2CFekE2AnDipFjqkhXrs3j8exE9+lQouyQDAQhAAAIQgAAeQDyAaXtBJgLwo0mTY8mL+tfn7bh3Inr6NAQIQAACEIAABCpBAAFYXQLwUFX6MbKlZM/KDpeNaqAhrK3fT5VtJLOS+rXsj0XH1unfQ4p+e1X/XqMZjSsTAfjxp5/FEhcuV5+N370V0WuhZmSJQyEAAQhAAAIQaIwAArB6BOA+qsirZQfLnpAdJdtL5qWyH5eo5E30296yp2UXyM5uQAD+SL9vVxB/tr435+W72QjAKV/EEhcsU5+tY8dF9F6EngwBCEAAAhCAQIUIIACrRwBa9D0pOyxf9531qbHRuFh2VhPtYXxe/JXyAO6pv22Qoj1lIwCnfhlL/MGOToVj3ohYYLEUWSQqBCAAAQhAAAKFBBCA1SEAu6vSpsnsrbu5oAKv0nePje6RQgB6SNnvWpsuGyk7XvZ2I+n10N9sSeirL+9OmTIl+vWr3Dy9CZ/NiMXPX6L+HEePjeiT/07/hQAEIAABCEAgNQEEYHUIQI+FailsbJEXaUnFn6Mv28g2baEA3FnxvLzW8/6Wlnk+4LKydWSfNZBmXf64+f5caQE48fMZsfC5S0aXTvMifqvs9c17A1M3eRKAAAQgAAEIQAABWNsCsLgH2JuoFRfxG9nlDXSPVvEAfiIB2O/cpaNbpzkx79cvRacFrUsJEIAABCAAAQhUggACsDoEYFZDwKXakOcZ3ifzUHA5IZM5gBaAfc5dNnp0mhVzj3w+Oi+8Qjl54RgIQAACEIAABMoggACsDgHoqvQiEG/54q1fHLwIxHP1LpG1dBFIcRPxcLDTrJNdVEb78SGZCMBJX8yMXucsG706zYw5RzwbXRYZUGZ2OAwCEIAABCAAgaYIIACrRwB6Gxgv+jgoLwS9DYy3efGefXpZbm6LGM8TTDx39hqulW8Ad+jz2rx9rs/X87+fp89bZR729TzDoTKvCHa8CU01nvzfMxGAn0oAdj9nuVig04yYfdjo6LrYSmVmh8MgAAEIQAACEGiKAAKwegSg69JbwCQbQY/R9yNk9gw6DJeNlw3O/3uAPrWB3jfCQ/plUP7X6/T5bdmiMgu+EbITZdp3peyQiQCcPG1mdDl7hejb6cuYfejT0XXxVcrOEAdCAAIQgAAEINA4AQRgdQnA9tieMxOAnc/uH/06TYtZhzwZ3ZZYrT2WnTxBAAIQgAAEqpIAAhABmLbhZiIAp0zT4o+zB8TCnT6PmQc/Ht2XWjNtPokPAQhAAAIQgECeAAIQAZi2M2QjAL+cFbPPWjEW7fRZzDzo0ei+tLcmJEAAAhCAAAQgUAkCCEAEYNp2lIkAnDp9Vsw4c6VYvNPUmHngiOi+zLpp80l8CEAAAhCAAATwAH7VBjrRGlIRyEwATj9zlVii0+SYccDD0WO59VNlksgQgAAEIAABCHxNAA8gHsC0/SETAfiZPIBfnLlqLNXp05ix//DosfzAtPkkPgQgAAEIQAACeADxAFaoF2QiAD+fMTumnrFqLNNpUkzf7/7o2X/jCmWXZCAAAQhAAAIQwAOIBzBtL8hEAE6bOTsm/X71WK7TxJg++J7oOWDTtPkkPgQgAAEIQAACeADxAFaoF2QiAKfPmhMfn7Z6rNB5Qkz7+V3Re6XNK5RdkoEABCAAAQhAAA8gHsC0vSATAThj9pz44NQ1Y0Dnj+KLn90RC6yyZdp8Eh8CEIAABCAAATyAeAAr1AsyEYCz5syNd4auGSt1/jA+/8lt0We1rSuUXZKBAAQgAAEIQAAPIB7AtL0gEwE4WwLwraFrxcqdP4jPfnxz9F3jO2nzSXwIQAACEIAABPAA4gGsUC/IRADOnTsvXq9bO1br/F5M3ec/0W/NbSuUXZKBAAQgAAEIQAAPIB7AtL0gEwE4b968eHXIurFG53diyl43xoJr75A2n8SHAAQgAAEIQAAPIB7ACvWCTASg8/bSKevFWp3fisk/vC4WWnfnCmWXZCAAAQhAAAIQwAOIBzBtL8hMAD53ysBYr/Ob8emef4+FN9gtbT6JDwEIQAACEIAAHkA8gBXqBZkJwNGnbBwDO4+NSbtdGYts9IMKZZdkIAABCEAAAhDAA4gHMG0vyEwAPjlk09ik0yvxyff+FotusnfafBIfAhCAAAQgAAE8gHgAK9QLMhOAI4dsEZt3ejE+2fHSWHTzn1YouyQDAQhAAAIQgAAeQDyAaXtBZgJwxJCtY6tOz8XE7S+KxbbcN20+iQ8BCEAAAhCAAB5APIAV6gWZCcDhQ74Tgzo9ExO3PT8W+/YBFcouyUAAAhCAAAQggAcQD2DaXpCZAHxgyHdj205PxcRB58Rigw5Km0/iQwACEIAABCCABxAPYIV6QWYC8J66HWOHeDwmfPv3sfi2h1UouyQDAQhAAAIQgAAeQDyAaXtBZgLwzrpdYud4NCZsWReLb//rtPkkPgQgAAEIQAACeADxAFaoF2QmAG8bulvsOu/hmLD5SbH4jsdUKLskAwEIQAACEIAAHkA8gGl7QWYC8Jahe8bu8x6Mjzc9LpbY+fi0+SQ+BCAAAQhAAAJ4APEAVqgXZCYA/3XqXvGjuffEhA1/HYvvXleh7JIMBCAAAQhAAAJ4APEApu0FmQnAK079Rfxi7k31+RsyWTXVKW1eiQ8BCEAAAhCAgAggABGAaTtCZgLwgtOOil/PubI+f/vfF7H8JmnzSnwIQAACEIAABBCAuTaAWyldV8hMAB57+plxzuyzvs7dKZ9GdO6cLrfEhgAEIAABCEAADyACMHUvyEwAbnXmfTFixg+/zuDhz0QsunLqDJMABCAAAQhAoNYJMASMBzBtH8hMAG59zgNx/ufHxbc6v1qfx0OeiFhijbT5JT4EIAABCECg5gkgABGAaTtBZgJwm3MfjNOmnhzf7vJ8fR4PeCBiuY3S5pf4EIAABCAAgZongABEAKbtBJkJwO+cNzxOmHJqbN/l6fo8/u/NESt/J21+iQ8BCEAAAhCoeQIIQARg2k6QmQDc9vzhcdjkc+MHXUbU53HvqyPW2iNtfokPAQhAAAIQqHkCCEAEYNpOkJkA3O4PD8WGn9wa53T7W30e9/hTxMCfpc0v8SEAAQhAAAI1TwABiABM2wkyE4A7XPBQjP1oaozrmRd9O54ZsfkhafNLfAhAAAIQgEDNE0AAIgDTdoLMBOBOf3w4Xvnwsxi5zq2x9Ov/jBh0gux3afNLfAhAAAIQgEDNE0AAIgDTdoLMBOCuFz8SL7w3NR7a4MHo/4qGgTc/LGLH36fNL/EhAAEIQAACNU8AAYgATNsJMhOA37/00Rj99uS4d+NRseoLf9T8v//VPMBL0uaX+BCAAARqi8C8eRGffRjRb+naKjelbZQAAhABmLaLZCYA9/7ryBg1blLctulLsc6zp+tdwJvqncD3pM1vbcefPTNi3tyIbj1bxsE3kk5t+PbEqe9H9FwwovsCzc//9CkRn38csdiqzY9LjMoSmDM7okvXyqbZ1ql98GzEu09GbLx/dn1krvpu4eswZ8+IuPPYiFW2j1hz14YJPHxuxAO6hn7v/IhNDsie1Nw59efo3CX7c1XiDOZ6+6/1ooG1IjY96JspfvJGRK+FI3ov8vXf5syKsHXvXYkctEkaCMDqEoCHqpUcI1tKpqtNHC4b1UDLWVu/nyrzzsn9ZWrdITfaN0Jz0ix1qswE4M8ueyJGvD4x/r3ZG7HhmJPrz12nm3ith1nTI567PmK1nSL6Llmahp/2u3Sf/4Jl8fbHdSNmTI04+vWIrvq7g3+/ry5ikRXVWgZ/M73bfhPhm9v/XBfxf4MiVt0uYrcLW78WprwbcYGadd9lIn77cvPPf97qEoDicvCj6kHrNBzfPCa9GbGweBS/e9o3tkrf1D59q75OllLdNBVmfhExXccmnhzn1aFcUW7hNW64NlT/loS0u24zQqH48HnvHxqxuN7Ms/6Plf/PI964X0JEbaOUOP/sIx2vy9Emv4iYNiniennztxtS39669So/EyMvjXjtLrVFzQlu6CHAeftE7XshXfaSNl7qDDM+i3h/tK6OWyr/+j5b/aqvL61NhI/V9l74d8SWR0T06Ft/8LhHIq7KC7C9ropYe8/63xNOi6ntraPXWib58XlfF68tlIZ/m/pBRB/15cL29un4iAWX/7q9vfVYxD/20TSYMyI2FD+HUZoac8fR9d99bSwWiElR6vTQ9NX3Cl9DLY4euzhiq6PUZwbU5+Gv365vkwc+VP772x3Pccyspe98v0f3CffP7eqaqsX5//7m8Iir81uMFd9jkutOJ72HfojeR5+ECzdQW/5E19LXymvDLpfbWFc9fBf31/f0mlOL9O3cp1ZrXt5THI0ArB4BqJ4f2ggvDpbpnWih3hZ7yXRlCbk1vhE20S97y7yL8gWys2XFArC5aZZqapkJwP2uHBUPvjoh/rpD99jx4R/Vn/ukCY1f1FN0hnYd1cLDHqw58uANP0u1eqU2xd5Wm2P/pz7bvnj64jLuYb0veZWIS/JvTBky+euLjW+850jUOOx7m26Qurn4gv324xFX7Fj/e3LxsyC0p20rPTckN4+Vv1t/k3c48jkJzG4SIhJjhcHnHysv7UcvRXz/r7qpLd4w1jv8LKML/ne0uMc3u6XXb1jIWGBcqL9Pm1if3i8fjFh2w8arbNK4iNuU/23kIem/xdfl+O4pEVv/tuG4T14mb4D+7if+H14uUaNyO9yqLvfyLRG/Gtmw8PZN2gzMqs8SEpwSPuZ43U/qz2mB1HuxiCnv1N80uvaIOGuF+vQtyot5mYsF39LrqZe/EnGpvOAOPReqv1HOUJvw90OUJ9eFb8aPSyRZWCzs5z4F5+lBiYadz4l45XZ9tzd9s4hfSEjdJxH2qMT8Pn+XB2m3r5lYlL4lobyuLiH21D3+Z3mQNP923/+Ku9rWpeL58Yv1x7vN3Dg44kW1xQ1+GrGnzp+EsffVc3xQcZO2U0i+37IRv1FbaSq4Pd3wc5VvbP2R3zkxYrLyuJ4uYStKbBSGV+4Q7/+JWEOC7MfXfv0Xt6GXlP/Vd65/MEra9U66NJqD+8/vxLuzyttF9WJhNkKXzC90zVlpUH3d+cZ9purL3DfcN2L3i/IMCgTWNscpf8fX/+7yX1vwPnOz2+/OiNPVNhx2Ul9eVB5pH7O+2ojnOLs+X5TAvEmexP5bqR7y+6AWlvGrfirBMOIP9X/Z8siIZ3SLOEB9tPid6UlZO0kcDdF1oDh4ZMDltvCyuH1b7Wn7074eKfC14171m81+FbGkfQsF4SL1w0lqdxZIp+i4qe/VP6g5HKs+6Pbvv7ntLSPRtOBy3zy/+9zdJ6kOvvy6bX6oa0wP3V7cRibqdaBL6qGtsQedwuubz+s6vlN14T74g/+LmKW0h2sniXV1L3E9JMHXVufthryoPlptzH3Xx4/UlCNz8fXQwW+j6qX68cPMS3oxgcNB6u++dpUKd+naNl5//7EeWCzwntHDgYOvv76WL6V+7QeaWzS/3cEeSPdl93v3G7PLMCAAq0cAWvRpfCHyLSXUo0J3kdCjV+gq0mhQa8qJv2IBmCbN5ISZCcADr34q7nnpo/j9nmvFT+8aqPPphpd0zgw7ReZJe9jAImF5eWESD0JyUnsifLPzzdwXyuSC93fdIF7XzaQ4+ILr9H7fgCdwU12wt9fFyhfWRGgUprGfLj72ivkG7nDYU7roa0jjAl2IHHroAuSbncOArXUxk6ejMCQXWouRCRYoEhZJWHP3iB10E7HX0Bfv1SQy79FF3gJoB4mQm/0so7CMbiDv6wnYN3V7SXwDsVcm8bQ9pAvncAkYD10Xhl9IaC6pfP5TN/tVd6hPf3E/Dyl8qSf1swd8ffQxukGdu3L9v33j3q5O3hPdFB7TBd438XV+UM/xIYkBX6iLy/isLuB362KeBHtALT5cjxYgFgzTJbYTgT1/CvP/ay15h5KbR+FfLES+9ct6ITVXnjp7BP8soeVwhDxGF7kPNBIWk+dgorwRSfjRFRJM8mRa8JUTfi5xtILOZ+GTiJzu8nDZ25Z4t5yOhaSHHZPgh4yhuikmIXlIe1E3yBvFuqng4UuLCj9QvCFhv881EhS6gX+h59r7JHA+1ffGwm8lDuwZGyCxZJFdWAcW1fbSvKNLnUWN69FtZWN5Iv8pz2VzwtISL4MlFM6UIHGwULOYe0Li2MIrCRZi7nMNld9C79l/fH28b/Rur0mw57mpMu9yXn1bsSh/WPVRKliMe8j3Lomgp4d9fYQ3019VfcWiy2JmV/kHrtylvt+5vmfqGlQYFlmp3iOehOQY9wHn9Wr18yRY0Pq69jc9nDr0kgj7skhw7ileX6rN+Fq3qur+byXe7vRLCa0kjcK8uI9spDbl+nTf87XDIyEOj6ocHuZ28Hvjne/TG3gANT9fY/1gViq4HU0Rj+c06lFOMNMFdC7vU7uM+ukY1e9I7Vv70QvlxJ7/mCM12uKHXQtPp2svefFDTvNTLRkDAVgdAtBjddNkdoPlHzty9enHCV95m3o9xngdUywAW5qm7nRhS4LHQN6dMmVK9OvXzCGlJhrxof94Jm5/7oOo222tGPzwNvVCxB4ve76qNXjOjr0h9rr4RvTTG+tLkhNQupHdJi+Tb1RJ6CcR6KfXYbpAlwp+kn0v/6q8xpg05EkojmNvxACJr8IbRmPp+snXF1qLlkoHix57vezNKTd4SNKrxZMn6gbjeR5jfvi03LRr5TgLnQ/GpCttN83RnKXh6tYOnvZgz0othL5a0OHhxKbEYi2wKHlt3FjXRj3QtnawJ/3lWyt7Vo9E+OG43KkeZZ4dAVgdAtDjbHocCbsDCtRB+NFPyijy40IN1vp4/aVYALY0zTqlpfGS+UMWAvDX14+J/4x+L07cZc345SgN29hT1Z42gy5nQYSPsaCzS7/3ohJ+8jYVDumspKdfd24/vXoeDQECEIAABCBQTGA33Tvs/axgQAAiAJsrKlvNA3jsv56NG556N47ZcfU4dKr062gNDW2jjaA9Z6wtg+fbPa3htXulgz3M5qFHzyPx8KHd9vZAeHjCwxQLaC6Jh7IIEIBAbRNYSHMHJ79d2wwofcsJZPAiBARgdQjAlg7XJo1N7qeKDQEXN+DM5gCefPMLcc3jb8Xh264Sv+2iVa+PaD6LQ7KwwfNmPEE+meze8q7VcEzPRbI7fxNNyPaqQ3v0PHfIE3eT4HcUf6i5Hp4L1N7Chpo4Xzg/Kcmf5+Z4wnGpCealytBZ87Pmao5cJYIn53tujL2izQ4ph25X/17Eq5rHVSp4LpFXOntuVLKystn5ayJCqXmUjUXxNAEvqikMR2h49iIN03aE4DlTXnBSPLe0obJ5UYBXTDcn+KHxES2UKNV+vTjBowqeD+ZFAJ5C4DmPl+uhznPUvO2U58cVz4srdf49//L1vNbiv+81TCuDv6/5eHp4fV7TPubpgdHzXL2oqDhsrVW9j2iOWqngvuNtSm7RIp/Cod9NNB/wyfw705vDpjnHmlXxPNzC+F40cm9+t4bC35fVUKznpjan3ornHTYnn6WO/dlNekDXgJkfyovDzprz68VBpa6FpeYwlkrfc5o9v7mpsK34eLHKu9q8w1sGlRu8GvzXLZhP2ET6CMDqEICuRrdcb/nirV8cvAjEj5PeGTnNIpCWppk0rcwE4Dl3vRKXDn8jBm8xIOoW0+Twe7RIwMHbLNjr5kn+Xrn3G23L4AnZvvj4ArlyiUnFpTqC5855ArYvNsXB26h4m4b/5t897IUDm2rRghdjfKa96FozeC6c8/iFVsB6rp3LPlNTQpMVoZ4k7AvQmUWr6zbaT5PAdePzggOLV28h8i/95uBVvBbOnoz9jpqAJ9D7Au2LpPcJ87YID+iCvqXmJK6oxR9eRetgD4a3ofFeel4l52PW1gKK52/ID3XntzTxBcvi/EDVmxeHPKwbmm96FljJymGLZq9Etsj2CmfXr7l71eW3DqxfpOEb287yrJ6a33/rGE1G9/Yl12oBvLdycZ14W5jRmoTveY5e/ehyelHL6/fW59mT1W/VxPxkdaZFvFdRO54XbrgNmGlh8HYSj+VXeHpFrSfId9Wq3V3F8zmV1atRvTLWq5g9id4LMBZWexynbS88D803Z+fj21rp7DJ5sr0nlXuRisWvt30YoXjb6qbxgm5Or2rlqifte8sJzyHyFiYWHZ7343Rc755K4EU9LrfrzEJiu7r6h5JkYYLz8FOlt5hWgn8ujv8Qp+W0IYAXblhseNK+8+P2ZI72WluAeVsRz/3zQheX1Qsz1pDwcZvzliW5BTkqqz/9MODpCl404i0rfB5vCeNJ8MmKVC++8NZBnoO1gSbaD9d55mj+q1ecez9PbwFjj1gSvADHf1th83qh5hXSFmCe4+byeUWyxd9ymvPqsl+u/DmYz/fVTtwnPV/WD2f2vv9Sffddndurpz0p/yOtWH5Cq9LN9jpx9ur2rbW9kVdhf5UHLbxxKN6fMLdFjPLutl48NzZZsJEsyviHHw61MMQr4FfQgiiXy2VwOy8OLpfbQrLQxX3UU0K2F0uPMtytlcReBep68aIgz/8qXKntenR/NGcvakkWTfm65cUNXu3sbUXMw+3OHLzQxsGruKeqrXnFsB+kvZjCi5/wDBSHAAAfpUlEQVQe0q3E83r30epp14Hz5MUsXn3v68IbWpzxlEY9vDrcgtYjHqeq/zicoDpwnjxS4zadeDtP1CrcCbpGu0+5bF4E5uuor9MWRG6Hjne+8mhWZufFDx5Jcf14oYun/1jIezWuV7p70Zive74+OP+jFMf92w+13ubIedxFDoOPtaDO7S3Zq89b+HTvUz8q42ucR2jcPs3OzM3E7dh91ef3IjMLNn9/Sf3H/N0fPX/Yoz7uG+uJheP7muz+u6AWCT2r65x3OfADuK/Nvqa5LIW7JiT17zbylKYB+VrmvLnvO30/iHqx1XpqU98Vp1Krp7/Zqpr1CwKwegSgt2zxog89/uWEoO7MuW1e9Mga6mG5LWI8TzC//0DYa5hfyhm6u4R6dM60F0Lo6pwLTaVZTmPKTAD+5aE34qw7X4kfbLhs/GFHXTSSrQWKc7WkVkuuo4uRl+Y7eJWdN0V1R3Jn9pOxO633z0qCNxROVrr6BuKVkr6BLKB5ertKMFypi6e3HsgquKP7aXqW1/Yo7C4d74uLb3LeisH7gnnVr7csaGifNF9gfXHeWKLOq4nf0ROlPSlehWhBZVFcuJ+WLzhenbaEmkzhNggNlbEle975HLm96fILLJKbUjnzJRtj/b68XmaVCNFy6sX8fLPx1hPNDb7h+4a4ukRQY9vNtIRRcV68N58FTKEgam5+vXrWAttblbRlSFvP5eZ9sjZAsNCwAGhsq6FS6fmGmwihcs9X7nF+OPIehF7VXOEJ++VmoazjnE8L8uJtRlpSfxZvZloscpubloWWr4uN7d2YFK65aZcFpcIH+RpS+IBR4eQrkRwCsHoEoOvbW8AkG0F7mZ5cEznPoMNw2XjZ4Py/B+hTbohvBLkoYlDBr42lWU4by0wAXvvEW3Hif16I7ddaMv72cw0j/ElP1H6SbGnwBsDeWsAXPm91koivlqbX0nh+0vNToW9C3qfKHhd7NVu6+WlL80E8CEAAAhCoWQIIwOoSgO2xoWYmAG959v044p+jY7OVFonrDtTQ0N0aIvTGnO0x2NN4uIYlrpXHLpln4nknnvPjYT7P6bEr3xuptmfPQHtkS54gAAEIQKDiBBCACMC0jSozAfjgqx/Hflc+GWsv0y9uP0Lz0DzHwnO/yl24kLZkDcX3psKvaCd3z/vyYhBv3OyFIH4tm4cmPP/EQ6wtGXrMKs+kCwEIQAACECgggABEAKbtEJkJwKffmhQ//PPIWH6RXvHIsQWbP3sitif1NxY8KdpCrBJhA61U9DwwT0T3Sr9y5qhU4rykAQEIQAACEMiIAAIQAZi2aWUmAMd+9Flsf8HDsWCvbvHsEG2HURhyL9bWXD6vzvLKNK+y9Ou4vFrMCzy8Ys0r7PweVG/v4VWh/rffIuLVY36vaBIczwspxmrVqN9puYUWWnuF20ID6lePNedl9WlpEh8CEIAABCDQCgQQgAjAtM0sMwH46RczY+Bp9Vt5vHLaTtGzm7eiSBG8zN/z7wrn4HmLh+R9vBaVXj1rMUmAAAQgAAEIdGACCEAEYNrmnZkAnCdBtuYpd8X0WXPjwaMHxYqLaU8qAgQgAAEIQAACqQkgABGAaRtRZgLQGdv9khHx3LtT4qL/GRi7r+/XFxMgAAEIQAACEEhLAAGIAEzbhjIVgENvfTGufHR87Lt5/xi6h96AQIAABCAAAQhAIDUBBCACMG0jylQA3vbc+3HYP0bHOsv2i9sO11YwBAhAAAIQgAAEUhNAACIA0zaiTAXgB1O+jM3PfCC6dO4UL9TtGL26p1wIkra0xIcABCAAAQh0AAIIQARg2macqQB05jY49Z6YPG1W3Hnk1rHm0j4dAQIQgAAEIACBNAQQgAjANO3HcTMXgHv86dF49p3J8eefbhg7r7t02vwSHwIQgAAEIFDzBBCACMC0nSBzAXjUdaPj5jHvx+92WiN+NWjltPklPgQgAAEIQKDmCSAAEYBpO0HmAvCCe1+LC+8fG/tsvHyc/aP10uaX+BCAAAQgAIGaJ4AARACm7QSZC8D/jnkvjrxuTAxcYaH4zyFbps0v8SEAAQhAAAI1TwABiABM2wkyF4BvfzItvn3ug9GtS6d4bggrgdNWGPEhAAEIQAACCEAEYNpekLkA9Cvhtjr7wXhv8pdxwT7rx/cHLpc2z8SHAAQgAAEI1DQBBCACMG0HyFwAOoOXPDA2zrvntVisTw8NA28Ryy/SO22+iQ8BCEAAAhCoWQIIQARg2sbfKgJwivYB3ONPI2K8hoMX7t0t5wVcYZFe0X+xBWKj/gtH3x5do1OnTmnLQnwIQAACEIBATRBAACIA0zb0VhGAzuS7n06Ln18xKt6c8EXJPPeRCJyr4eLeeltIZ4nBpRfsGYss0D3mzItYql+PWGOpfrHwAt2ie5cuMWvO3Ph8xmx5FLvHlC9n6dheuWO7dekcs+fODSUT/Xp2i5lz5ujf83Lf/TYSp+u3kXhYukdXfeo/fzr4Nx2qY9SoEKPz1ZHZmGlnwyHUHAHXP31i/mqHSc11g3ZXYAQgAjBto2w1AeiMWrj5/cDPvDU57nrxw5jw2Yy0+U8dv3vXzjFXys9C0aGH/m2h+OWsOeG/zZw9N3p16xJ9enaNaRKdvhHOVDmkHWOWxGa9eKzPxkLybuYEab+e8bHK5ni9e3SJTz6fqXgRiy7QIz6cOj13XG/9ra+Eqc8zbeZsxe4UM2bPia4SWRalPve0mXNy8brofzkB2zniwynTxXGehtF7xRx9fvLFzNz5F+/bIxbQuabPmhtvT5qWy88yEtFdJYqdVmPBwtvncDG+1Dktoj+aWl83C1gw58voczr4HC6nRfe4iV/Esgv1ip7dOud+66pMOr55fjZ9tsR7z5ikPLqcK8rja74zxPQLsbQYd3nN1J8uo4W9yzNH8acrjo91uYzc53B885/42czc7xb9/i1ffbk25vIsItaTvpiRewuN0zAf14fz4nMst3CvXDlckUkaZuUy+GHE5TI/l8N14Lp6/ePP9SDSN3f8J5/PyLH1uZ3XqdNn5erNx+YeQHp1y+Xfx1k4L9m3px5m5uXys4geZGar7rpqYZQ//Xe3s8nTZsaimiZhne00XE7n3f92vv2b63IB5a+f2qPz5rb6mc7thxyXyxz69eoaH0yenuO7kPLhPH2gdmPGzrvbn9vRQr2753g5uMyu54nKr+vT53Mb7u4yirs/3db6L9o7d6z/7rL37t411y4dPv1iVu6782Tz44Lb4ipL9PmqrC6n24Lz5nMvoPiud7OcrX87XbcNn6On6svM3tf8Yeepl479WP3HZTA758k83M6chsttvmbarWunXP9wPTiYpUcaHFwOP2i6rbrenJ7r0O3G8f1g6fTM93OlvbDaudue8+6+5z7ifuzflnC96jiXx9cRp/GF/u5jXM5FFXdhcXZ6/pvN9eiyuT05Xk+VoYf+nfzNC+Zy59e5kj7g411v/s3/dVHe56if+TMRozN1/XCb9oNyklfHU/Fy/af+OqPriXnnH4hf++izXB9dQua25mNy51Amzczx3X7M0n0geTZ2GZLy5PpI/rrQV+3S7cVt4Qul5Xobr75kJr6WuD583fhUdeD0XL+ub7dP960kJA8cTjdpX77c+trilpWc2+3ExyZOgZ7qgz7GdeJ+4nTdptwGF9S5XS/+t9uHy2AW7iPuOw5uC07P3M1ouph2UwZcl27vrn/n333Sfc3ntVPD9Winha8b5uiRrlybVBnNZJ9NVoifbLrCV+WrxBcEIAIwbTtqVQFYKrO+6Xlo2DexGbp4ddHFb9qMObkL8wx1uufem5K7sM6SfaAbgTtXcnNaXDdLX0B84/ANxzfvRMilBUN8CEAAAhCAQCUI/Gb71eKI765aiaS+SgMBiABM26DaXACmLUCp+BaMyXCln2T9NOhgcWivo5/gLBb9u49LPGx+urUHwE9ufrr2056fTv2k6qfKxINkT4+fDO2hs4D17z4m5xnRv/3EN1Hn8W9+oraHwk+fC+qpsP54ezfqPRdOI/Hc2Zthr4bz3E3f/YSaDI0nHrHpEsD2iNir4KfM/2/vPIAmKcowbE4EFQRUPFHEnFNZ5jOimHMuT6vMOWc9FXNExRx+s2XOOfzmHEsQI4cnIAoiIB4ChvfZf1qHdfffvZvd2dndp6ve2tndmZ7u5+ud+frr7lnywAkukUrOQS/0Iul504PvDXWvM4THdycRjUsd6P0SXaDe9HApG2XYb8+d0kP+Z89Jx9Gm7CAlUkB9OM9eiSD0euXppdN7ZrsMz5MnkRQYYIOePZJ/L+pXRR7Zn/PRo+azErmBP9vUr/TQiZCsRd3yXVjTYyfaUIb6iS6QH71/Fh6xPxEm8j36hG29MhCN5Fwnp17whxPnINpA3pSdSAMczpXe/SkpG+UjEkw+JCIyHEPenIPvsUcvPJxjqd9ROR/1xl60IdofkWDaCJEoOjP77rEWGWV6A/Ug915UNHlSf6I6tEfyxF5EpGinazzXpjyUSCBoyeukf5zWi/DBHX7Yl7ZI1Iv2ckzY7JGpFbQvOl6lIwUT8iIiddjRJ/Y6Ypfaa5fecYcf+7fM2d2t99kxiYDts/tOvfL0fl2YtIqU8qa0j0OTB1Ew2iWRlBLxgQft/UQ45zjaEmm3RN+IXu6VsmEHopAwIBJFhI+2WaaJsD/7rEV8iOb872pAHWgDfF4ia9iDdESikvvG/iTsc/HUA97bTju99xvAjrQlykdbOi6RZCJ9vd9n9RvlN4atsCXl2z3lLu2/RPuIenHOUt5eZJQypqpcP7adyjXmX702yrG0JWzLZ9SLtkT7gAXtkxEH2h550obZH57YlbYAo54t810vQpqywpV9uCZSN9p67zN+h/mcKCRTaCgz/GjznJMysD/50inHTuRPXUiUA2blOkF5aEu9snNNSdnPkeMoN+2F9kqU7ZKJxFEufl8k2sHWTA+iTnufb21xYNWi/juyUq4X8ON3cOrpa1H5cl2nnCQYcv1cm/aTEZvwZ1TlqLQnfm9EBLl20YZ6v528HnLUCfn97dyLTmITEscRSaScRP7WIrIZucg2eVAPjoVFuW4RWdwzdjoiwYzjc00kf+rO9YK8L5b2domcZ5JJB1AHsGl7WkgHsCkUj5eABCQgAQl0mYAOoA5g0/apA9iUoMdLQAISkIAEWiagA6gD2LTJ6QA2JejxEpCABCQggZYJ6ADqADZtcjqATQl6vAQkIAEJSKBlAjqAOoBNm5wOYFOCHi8BCUhAAhJomYAOoA5g0yanA9iUoMdLQAISkIAEWiagA6gD2LTJ6QA2JejxEpCABCQggZYJ6ADqADZtcjqATQl6vAQkIAEJSKBlAjqAOoBNm5wOYFOCHi8BCUhAAhJomYAOoA5g0yanA9iUoMdLQAISkIAEWiagA6gD2LTJ6QA2JejxEpCABCQggZYJ6ADqADZtcjqATQl6vAQkIAEJSKBlAjqAOoBNm5wOYFOCHi8BCUhAAhJomYAOoA5g0yanA9iUoMdLQAISkIAEWiagA6gD2LTJ9RzArVu3nmnXXdk0SUACEpCABCTQdQI4gBs2bKCY541O7Hp5p1G+M08j0yXKc+/U9Q9LVF+rKgEJSEACElgkAhdJZY5cpAqNWxcdwHFJDd4PfheOTmqWzcCjd6mcSxrnNPKfQpG3K0vrt124OrmzNuykWbarUNpwu3B1budFtx/Ap1lH8j4q+nfnLNtCgXQAW4C8g6foDS9Hixqetn472DA6dJg27JAxdrAo2nAHwXXksEW3H5iXoY4zaU46gDPBPtZJF73RW7+xmkGnd9KGnTbPWIXThmNh6uxOi24/HcApNj0dwCnCbZj1ov+wrV/DBtKBw7VhB4zQsAjasCHAGR++6PbTAZxiA9MBnCLchlmfM8c/JXpB9I+GeXXxcOvXRatsX5m04fbx6uLe2rCLVhm/TItuP0gsQx3Ht/gE99QBnCBMs5KABCQgAQlIQALzQEAHcB6sZBklIAEJSEACEpDABAnoAE4QpllJQAISkIAEJCCBeSCgAzgPVrKMEpCABCQgAQlIYIIEdAAnCNOsJCABCUhAAhKQwDwQ0AHsppUelmI9Ibpg9NPoEdH3ulnUM5SKVct3jC4TbYu+FT0p+mVtr9Vs37CvLm/I+wfXPrtotl8X3Sj6W/T2iLxPnzGDzTn/s/rKQN2oL+lc0cuiu0esXPtc9NDomDmoWynilmzsM4Dza/MZ7XI1mif73SDl5bd09ehC0R2ij9bqxzXw2dEDovNF34weEv26ts9u2X51dJvoX9GHokdFtM2SrpSNg6NrRn+u9n/xAI7T+Gi9Op49JzwwOiDaN+Lh8l+MnhzxDwglbclGv935zb2wA3UcZcOVlPG+fWD57d2i9lmXbTiqfsP+peKJqd9Lqjp22X7j3Bcmde3cGB4vjy4fba3aPu3DNICADmD3msXdUqR3RDhE340eHd0lunT0p+4V9wwl+mzevS/6fnS26PnRFaLLRSdXe67m9VfRM2tH/j3b5c+4z5rtn0R/jLhxc9OGx5uip864/ptz/jtHN62VA6f02Oo9Tuutok0RN9rXRDgM162+73LdSpX2yAblLAn7fSHCGV+tNE/2u2XF/4d5/XDU7wDSQeEGhQNxePTc6IoRbfaUCsJn8ko7fFCEQ/W2iDZ+z+p7nsUGExwrHtvE8W+N+O2+8b8kp7exXh35J6EPRvx+6EyePzoowsbXqBVpS7bfUu1XPuYvKMvvdpZ1HGXDlZRzr+h+tfrw6Kzja++7bMNR9SMQUE/sj632i35XfdFl+41zX5jEtfPiYfHz6PXRm6ObRK+MuCbTITD1EdAB7F6TwOnj5vLwqmhnySs9GSIQ9d5490r+/yXCmcBpJWL0terr1bzi4HFzHJS4uH0y4j+WS+QMZ/hFEfmdOsOKb865bx9dZUAZuNES+cEp4IZLIjL4i+ja0XeiLtdtGFYuoLeOLhkRiViN5tV+lL/uAHL9IwpG1PalFQDsSLvbFNGZuWx0aERk7wfVPkSWPh3xP90cT8TweRE36tI++a3SVkp0eBjfSX/eX8dB+VMXRhSI+P2+2mFLXrE1GpS6UsdB9VtJgYnewntQmicbjmM/Itj8hy0OTknzYj/K239fmNS1k3sEzh6d1pL4DdM26tHgIc1k+T7WAeyWzc+R4hANI8pUH6ZiCJRGfLtuFXdkaeihMpRGRISeGWk1IjxP2yPK94mIqAv1Jj0num1Ud7Lo2dHTvVr045Fnnd4Om5M1UUmie0SHvh0RPeImeuPoSxERlr/WinBEtrmpvqLjdRtEjfaIg8OQCtFc0mo0r/brv7kyJPrb6KoRTm1JX63eM8x7/wgHEbuWRHQb+xOZ/0hEhJoIWd0BIWL65Yihx3okqpbNVDbHcSCIYH8+4ppSIu9bss0wHBFO2vN7ItpsmXbRlToOcwBhj/MNa7g/PTquIjxPNhxlPyKdf4iIWGOjkubFfpS3/74wqWsnQYYfRfXgAlFhrr84maY+AjqA3WoSRL2OjK4T4VyUxFwiomjX6lZx1y0NkcuPR9xkrlfb84HZxinCsWDeFL02ohHMHSQxZEZkYv/aMefJNkNRzGNiKGdWiQjezhHz/hgSZD7g3hE9TuaHMTTI3L96om5fiRhq7HLdBjG9az7kJsOczDJfbJ7t139z5XfGnD9+d0fXALw/2+zLdAymHXCzZQpGPRHZxv4MXeFMMXzMEHFJDCEfEvFKFLitNMqBwMmjzodF96oV6rHZ5ub5lwguDGXTnvmc1JU6Dqofc27pQGKDS0R0VpifSeT9n9E82XCU/Zj3x/xN2myZooB95sV+g+4LjJpM4trJNAzyoe2WxD3jUxH3EOalm2oEdAC71RwWyQHkxojDhPNHj3VYKr0/eoVEY+bJScK5xZnl4svFZRIXsS61SObNEFXBuV0E+y27A0h0jwUsDF1vjEr0b5BtiZqxOIsOD/PpuuwA9pe/RHaJdBKVXyQHEMedObksDFwvddV+g+4LOoAzuurrAM4I/JDTLsoQMIsfGK5mdRu98vXSTvmS3jpzNHA4ujwEPKgezNdk8j8X5UUaAiYKy7A7kdmPrWPAebLfMg8B4/wR2cQ5otNVhkeHmZZhfqZtMIeRiHeXh4AH1YH5uAwD48QuyhDw9VMXhjmZHsOCnvVSF+037L7gEPAIY07rax3AaZHd8XxZBMKwYenhETJnTg4/nq4vAqE9sViFifYbo/qjNIYRYYXsN6IrRz+LykIJhljLqmeGHXncwZ4R0YiuJKIj2GZzxDxNbjr3iIiykBg2pMfevwhkHupGnRjS3BCt9/idebLfsEUgLABhnh+JuXy0u01RfREIK2ZZSUy6ecTKxv5FIMzPOq3ah2HI8kik6qNWXgYNIRbnj4U8zE2knY5KDA/j9F0gYl5dWQQy6zqOGiKlXtiF3yXzApmGUhaBzIMN16vfSurCdJP66u1hduyS/UbdF8oikKbXTqYTMeTLnPOSmMLCPFwXgQxoKTqAoy6D7X/PvCOcCW6+OIJMaGUuFj3x+vPk2i/Z6DPyrDjC+UT/6s/+Y9EEQ6TMz+F7VlASgWAOIBPNGSJmjiOpPCqFOWfMd2Fl5TsjlvUzlDPLhKPAohWGfRmu5/lx9MaZ58VNleENLkCbIobXcIZJzKnqet3qXOl0ELl9b8R8o5Lm0X446UwvILGAiOF65mQy1w0ngbmZ1JF5ftSZBUm0y/7HwOD4sBq9PAaGFcG0ZRI3MNo7w6TchLhJ8xiYx0RMaZh2Wq+OzG1kVToLqFjNXb+GwIAhfjoozC+GC49+4T2/S+bbwmXWdVyvftSBuZh0ulhURhtlzjSrZHEESoeRunTVhqPaKPzpmGDLx0U85qSeum6/UfcF6jKJa2d5DAzP4+T3R2TxVZGPgelrMOWtDuAQMDP+mEfAlAdBszrxkRGRwa4neq+DEiuxViKiSe+KuEEydMjjbVhFyYNq6/ORGH7kgrAxYvEHDjE36Vk/CJqIEMPau0c4fEQunxYxd5FUHmZKT7b+IGhuTCV1tW61IvYiXAzHE8FkYnVJ82g/2hCOTX+iTW2KuAbiyBNlZk4nNuXh3fV6E0EgAl9/EDS/yWEPgua5kDj/OINtpPXquDkFGDYNg2jgaoRzyE2aTibtlv3pdLH6ux5xrz/sus06rlc/IpM8MYGV3NiPjiOO+DOiurPbZRuuV79NVQOifbKaldEDOtT11HX7jbovUJdJXTthSeeFDhyBBTp0K328fFsR0AG0KUhAAhKQgAQkIIElI6ADuGQGt7oSkIAEJCABCUhAB9A2IAEJSEACEpCABJaMgA7gkhnc6kpAAhKQgAQkIAEdQNuABCQgAQlIQAISWDICOoBLZnCrKwEJSEACEpCABHQAbQMSkIAEJCABCUhgyQjoAC6Zwa2uBCQgAQlIQAIS0AG0DUhAAhJoTmCcvyhrfhZzkIAEJDAhAjqAEwJpNhKQwMwIrOTM5S/L6oXg30za+g9QHcCZmd8TS0ACO0JAB3BHqHmMBCTQJQI4gPzPK385WE/8jdnxLRVUB7Al0J5GAhKYDAEdwMlwNBcJSGB2BHAA+R/Y2w8pAs4Z/+9722hjdHT0xOiDtf2vmO2DomtHf48+FD02qv/f7/3z/nHRftFfqn34324S53hAxB/P7x8dWe378er78+eV/xPmf5Z3jvif0udHb6uVwU0JSEACrRHQAWwNtSeSgASmRGAl+Y5yAI/LPk+OvhbdJ3pKhNP3i2in6NfRt6NnRXtGb6723VSV+SF5fXmVx2fyet7outErq+9xAHHqcCy/Hz0iwmHcJ8JZxPljf5zEYyOcyHNHn6iO90UCEpBAqwR0AFvF7ckkIIEpEFhJnveOTunLmwgbwjl7fYQTV9J3svGjiMggTtmLog3RydUOB1TO2YXzekxERI9o3dOHlJ9zHBg9o/oep5Lo4S2jz0ZEAnH8cApNEpCABGZOQAdw5iawABKQQEMCKzl+76ju4JElkTeEc8YikXfUzvOKbF8lulFEZO+q1XbZhQjfX6MbRodFOIE3jr4ypKyc467RB2rfn5BtIoGcF0eQYeVfRZ+PPhp9a0hefiwBCUhg6gR0AKeO2BNIQAJTJrCS/EcNATdxAH+c/E8cwwG8Q+XYleriQD46onykPSIiizeL7hQdHD1+ymzMXgISkMBAAjqANgwJSGDeCYzjAL4ulWS4tyTm++HYjTsEfHj2fXe03hDwKAewzvlBefOSaNd5h2/5JSCB+SSgAzifdrPUEpDA/wjgAA56DMzp+Zx5dwzP8vqk6BvRvSpHjkUgh0bniX4TMSS7OSJSxyKQr0ebqtMQQWQeIXmwCGSXiEUdr66+H/QYmHoE8DnZ74fRIdE5oxdGLDa5VnW8LxKQgARaJaAD2CpuTyYBCUyBwEryHPQg6F/m88tEOGcPi3hMzA0iHgODI/f+WlnGeQwMUbvHRPtGOJQ8RuaRVR6jHEAih/eMLhZti3AuyYvIokkCEpBA6wR0AFtH7gklIIGWCfiQ5paBezoJSKD7BHQAu28jSygBCTQjoAPYjJ9HS0ACC0hAB3ABjWqVJCCBMxDQAbRBSEACEugjoANok5CABCQgAQlIQAJLRkAHcMkMbnUlIAEJSEACEpCADqBtQAISkIAEJCABCSwZAR3AJTO41ZWABCQgAQlIQAI6gLYBCUhAAhKQgAQksGQEdACXzOBWVwISkIAEJCABCegA2gYkIAEJSEACEpDAkhHQAVwyg1tdCUhAAhKQgAQkoANoG5CABCQgAQlIQAJLRkAHcMkMbnUlIAEJSEACEpDAfwDW56yxP6Dx5AAAAABJRU5ErkJggg==\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAgAElEQVR4XuydB5gUxRaFL4jkpCRFUUAERAUxgIIK5pzzM6FPfeZnzgFz1mfOijlnUUARUAmCoiCCgAQFVECUJBjhnTMzDb3t7EzP1NSys3vq437sznb1VP9V3XX61q2qKqYkAiIgAiIgAiIgAiJQqQhUqVRXq4sVAREQAREQAREQAREwCUA1AhEQAREQAREQARGoZAQkACtZhetyRUAEREAEREAEREACUG1ABERABERABERABCoZAQnASlbhulwREAEREAEREAERkABUGxABERABERABERCBSkZAArCSVbguVwREQAREQAREQAQkANUGREAEREAEREAERKCSEZAArGQVrssVAREQAREQAREQAQlAtQEREAEREAEREAERqGQEJAArWYXrckVABERABERABERAAlBtQAREQAREQAREQAQqGQEJwEpW4bpcERABERABERABEZAAVBsQAREQAREQAREQgUpGQAKwklW4LlcEREAEREAEREAEJADVBkRABERABERABESgkhGQAKxkFa7LFQEREAEREAEREAEJQLUBERABERABERABEahkBCQAK1mF63JFQAREQAREQAREQAJQbUAEREAEREAEREAEKhkBCcBKVuG6XBEQAREQAREQARGQAFQbEAEREAEREAEREIFKRkACsJJVuC5XBERABERABERABCQA1QZEQAREQAREQAREoJIRkACsZBWuyxUBERABERABERABCUC1AREQAREQAREQARGoZAQkACtZhetyRUAEREAEREAEREACUG1ABERABERABERABCoZAQnASlbhulwREAEREAEREAERkABUGxABERABERABERCBSkZAArCSVbguVwREQAREQAREQAQkANUGREAEREAEREAERKCSEZAArGQVrssVAREQAREQAREQAQlAtQEREAEREAEREAERqGQEJAArWYVX8sttj+ufADsC9nyOLGri+KWwi2E35pi3mA4nl81gZFXWaW984VuwrWCfpr785VRZNslSGP79S9ghMOYpVPop1VZOL9QJdR4REAERKA8EJADLQy1U3jIsj3npO+C4wTGPzXSYBGB2iNkE4Lo4xXewx2AnlHK6NfH5jykh9q/sX7niiFUlAHuiBLSbYUsi5S0PAvAClOkm2AewnXLgqUOTBGrDKOAPhbWFVYdNh/WD3QmbJlAiUBkJSABWxlovP9d8VKQox+D3XWBHRz5/D7/PLkCx2d5rwP6ALcvjfPQC/gn7O4+8xZIlmwDkdQyC0UvYLMUyem3/wQcPwPaCvZPDhacTgKsjP+uNdZYpuXgAe+PEV8KawCj4wonthfX9Vw7XUehDx+CE9WHrwVrAvi/0F1Tg862NaxsA2xj2Bowimp78jWAcCeA9zRcWJRGodAQkACtdlZfrC74HpTsNFrdd1sKxv8HiehLL9cWXk8LFEYD0/D0MOwD2eppyD0l1sM3xfy7CKZ0AjIvFlwCM+/2+jguui2KadXMV7DZfX+Z43jrI/6vjOQqdfTBO2B22L+zdyMnpGewNo4fVNdGryJfKXNq763cqvwg4EYjb0Tp9iTKLQEwCmQTg7qkH+EH4vyuMXsK1YHyI14NdAtsV1jL1EP4I/18I+yr03emGgNmp7gzbHHYfrCeMw4CPwC5LPdR5inQxgIwF5HesD7setk/q+Jfw/5kwitMgsXO8BXY4jF4tejXPgXH4KVtcIYXupbA9YW1gVWGMkWP5Pg59R3B9Z+AziuJzYRRhn8NOgX0ROpY/ckisN6w1bBKMDOmVzRYD2BDHcIj3zdQ5wqcNhojJMoib2xA/nw/jUD7/vhjG6+dns0KZ4w4BN0aeu2A8nh3uK7BHYcNh4RjALfH7WbBtYfQEzUuVmXW2IPW9t+J/coqmwBuYbgi4HQ7mkGxPGDt+8qUH8f0018Iysr2eCCM3iuOTYBxGj5PYxugZJ7c+MApCttVoqoYP2J6OhW0AWwgbCWPbYmxkkP6NH06F0QNGT9hYWG8Yy1UXtgjGeiGXcIpyYN3eDdsaxuvZL3U+eijj1jfPz7rk9zN/Uxg9/eTIeuN98gOM9w3bfzhxKHcijPcZy5Eucbic57oDRjbZEu8ptmvWWThF41ADUU6ODWAnw3jdvP94H50Hi4r0LfAZz38crE/q5Lz2q2G8dv78LYz3zf8i398Lv5MHubK9T08d92DkOP0qAjkRkADMCZcO9kwgjgAcjzJQoD0Do6hi3BY7WAoAPqj5EGVnz4cyO5AOsDmpcpcmACms2NGwE2RnTrFJj8HxsMdTeTMJQOaZDBsM6wLrBeODnaIgSBx+4jl5PnYEFJ0UXp1g2QQgO/8RMIpVfg+FBL1w7HQoBsiEKbg+loeikUxWg9HDMR/GTjMYvqZYZZkoAJ6AUfDQ+0pBRoGZbRIIRdceMA4DUzQEieKBddINRkHG1Ct17rfxP4cvKWIpSPlzR1gwvBtHAFLo8LwUqffCpsAoZDlEynOFBSD5bw/jsB/bAFlTiA2DUYwykR+FNL2ZLBPFKRNF/O+wqPDhMCz58tlJ4UGhRVFFtvTS9U/lD66Fx/JFgHVHxuQzFBYnlo/fMR32GowCgLw5pM42zclM4fQifuG1s04Hwthee8J4TwRtmEKK4mQwjJNt6LHaBsaXJLbXfAQg2x7bDL+Xw+W3w3rB2Jay1TfbMUVqSxhfuDjUzfbEuuC1fAOjh5n1xnsl7OmnJ5QvLHzBmQtLlxjfR4HIOmY9ZEu5CkBeO+8v3mdk+TSML0VMfCaFE++J/8IocvnywfbKa18DxnAJ3gs9YXxBvA7GNsm0P4z1z3pnnfH7KED54kuxryQCeROQAMwbnTJ6IBBHAH6N72Xnz845SOzs+Hu4g2CHPA5GzwE7PqbSBOBh+BtFUnAc7wvm/QVG7xFTJgHIt3Z2eEHiw5pihMKNiWKInT69ORR7QXoOP/CBn00AUvSwTIw/DFIj/EBvA4VF8N3B9dGLQS8VxQkTBdILMMZXBl4qdl7sRNiZBKKHopAdGD0r2QTggTiGIpCd0JOhcrGjZedGL1SQKEbpbQonCmB6AXkednBMcQTgkTiOHS29L/en8lHoUxTSyxIWgOm+Nxi+DouC3shXWgxgVABy6JuCj98ViAoKGQqyn2GMNQtfy2j8QjEQDA1StLCDp6DJNvmgB44ZDKNI4wsA2wHrloIhEAj8rqDe6IWOesrYbnhfsD1SYJEdPYrheyU4Jh8ByPg6vjCFzxe3vuklo2eOnnu2hXAKyhS0s+3wx7C3m+KQz4Koty58DpaNbZ5e2vC9E/mqFb/mKgDZNuiV48tVkHg9vK5o/U5P8ae3j4nPAr6ksl7C3mC+VNCjymcHhS2FMV9Q14Ep1KW0mtPneRGQAMwLmzJ5IhBHAHL4jm/TpSV2khyWYdum6GIHzGBvpkwCkHkCwcRjObzCjpUeBqZMApAP8fAwGwUdO3l2hBSm9K5cDqP3aEao4IEwzCYAw9dK7xwFB/+ngGSnTYEQvj56YcLDmvSI0sPAyRkPwVrBpsJ6w+hJCSd2rBQr2QQgvT0UI5/AKADC338tfuH1pkvsjCkQWT9kQdEdHBtHANLzy06UAjj8EsChNc5MLm0ZGNYFPcb0MFHcUwjSc8PUGxZXANLbReER9eDxmim+yHY6LLiWsFDld1HIfJjKT89kpsS6CjzFwXEUfxRMFBhB6oMf+CJBJqXF4AXXSMHCOk6X8hGADMl4NcNFZKpvcpoJC16y0p2G+emdp4eTHlomDjtT8Gdbzomimd5D1n2clKsApFijhzGcghAI3tMMEwiXly8vz6Y+o+eaLxAUgeHEZwK9qfT88X8OxXO4nffY4DgXoWNEIC4BCcC4pHRcWRCIIwDpzeLwXDhxWISChw9TxuNRHAWJgd98g2YqTQDuhr9xKCac+IbOIZug88gkACnIgpgynoPloHeKMYqMaeIQK72MPEc4BTFPcQQgBcvZMHo2KXKDRM8ThwSZguvjcCGHv4IUlP0ifBDErnEmb7hDCo6l95LiIpsA5PH0hvWC0TvBIdZrYPRMMb6MIilIFBYUR/QWkkn4uRPuROMIQHqBOGszuObgOwIxHRaA5Nsbxs8YYxVObC8Uykw8Jo4AJHd6kli3FHbhFHgme+JDhhIE18L/+4YODOLHDsZn9KCWliiwKXzoHb0hdBDFEod0ObGBQ9lMjHfl8HKmOnsKf+d30utbmicpHwGYbng1Tn0HLPmiFRVBUSb0sPO+54sM+bPNsC1RzEc9y+G8vj2A9PYxvjCa2EbJOYjV5DF8+WJ7pLedzyteR6b+l15A3l8M8+C9So86PYW8Jnr9OcyvJAJOBCQAnfApc4EJxBGA9MoxtiicAu8LPSb0qnDoljE57Djo6Yp6qMKeAz5M6WWJCgQKQAqpQLRlEoCchBIMo7JcgQBkh0UvmasADIYtGc/FmCgOPTGW7woYO5Wg4w8EICeBkGWQomXviT8UQgAGQ5TB99GzRCHM4dFwImN6ijg0NgpGTytFCK+lD4weDqZCC0B6gCgU6TGm14/eMXoBKarCEx1643dfApBxe1xvLkiBAMy2YDXj4DJ51sJhB4USgGTDdpxuEgjvKXpfg7ri/xRiUbHP64xT37kIwMDjR88vX1Dozaaoptc3U+JEIbbNuDGAbJt8YYsOK7O90HPKumMK6pAeSXpkoylgwzz09FG40VNOAc4UXDvDLUqbwMIXu2CCFO9ftiM+x/g/RWE07CRNMfSRCGQmIAGoFlKeCOQrAOltotALPH3BNVEocVhnVQtA1yFgCgg+9IP4suD6PsMP7LRzFYCFGAJmGfj84KQbDuPRO0nBFfas8Rh6YzkJgh1leLiMHlfGzHEiRy4CMO4QMIfiOMQcLU9nfMawgLDIofjrDUu3DiDbEAVNUMbShoAD72d0CDhfAUixv1Wq/EF9B/9zcW0OJfMFg8P1fWAcAuZLTPhFJJyP18frzDQEzPpkXXFYPhxjyPAIxrmF66o0AZhLfU/HObMNAQfXwHhXDpnyZYrij0Pw2YbQGf9Hj1k0JCLKM/idx9JzFx2SZnvhUHRcAUgvN9sJX9DoDaZAjwp+3jeMteVwfi6J3sM+sKNgwQtmLvl1rAisICABqMZQngjkKwA5i5Fv2exsg8RlYjg5gbMyV7UA5HAdh4XoVcxnEgg7PAoLCsBg+I6zW9m5hCdsxPUAkhE9DBzeZqeWzySQgDOHlDmBht4Mek6iCxVTEPD8jLejNyZIjD1kB5mrACxtEgiHQ7eEBR1tEPfIWa/hJTkoIDgJIiwAeQxFTzpxFBWAwSQQCklOqmCiQOKkGoqk6CSQfAQgz0dPFIdHGYYQTRQNbNfB8HIuk0AooHlvpJsEwu9hu+DkA7avIDF0gMPQcQVg3PqOMwkkKAPjRHnvcOiTk8AY6hFnMXfGW9KDSEZkFk5s/71hjCtm4tA+hRVfHoKQDsbXsm3xGRNXAPJcFKcU5LxHe8HoqQ8PV7O98eWEnMOTW5iXsZzBKAZ/5vJF4cT7jfddSxiFpJII5EVAAjAvbMrkiUC+AjAQIZwxx2EcBn4z5o4dEb2Dq1oAEheHrblMSLAMDD0YjLVjZxbE5pWGlUNNHPLhkCA7McYDMaaIQ2HhJVtyEYAcTuPQFpeB6QNjB5XLMjBBWTdNnYO/s3PmcHo0MdaNHTDjEjlMzE6PnTI9bhTpuXgAOXzG4TROvKEg4flY1+mWgaGHlKKOHiDGKJI/4xXZPsICcAf8zg6bPMiYXjX+z+VpogIwWAaGAorDd1wCh7OCOes63TIw+QhAno9tmSzTxXrRG8VysU3RG8hExpwxy4kDnOnNY3qmrilYBoYc6KkdDKNgZxgB64Gijx5MJoqSW2H0elK80AvJFxhOhgrXVaYh4Lj1TS8wPfR8aaCwpqBmm+DwNz2a4ckqLfE7vfzssyieKILiJJabM4x5bzDkgKEPFGL8naEgFIEUWUzBWn1sX7xWthWGX5A16zsXARjshsP2Ea6noMwU+RSWbWB8OeK1sw2zbTJcgmzojaVXkvc464L3O+99vkhx0hnjXpVEIG8CEoB5o1NGDwTyFYB8iNO7FqwHx06FAdoUCPTKlAcBWBflYMdKscJhHAq53jDGpkUnbUTRsgPgkBw7I3aQ9EZwOZHjYeFFm3MRgPwOdrIsQ0tYLgtBR8tHEUkhyPIEYiN8DD0hXNyWYohLtrAz43AwxXp4eDVODCDPS7HK+C4KLgbTU3CwE40uBM3rokij4KTYYfwYOXL5lWicG2dts/ycWMDnYjAcHBWA/H5yZnujcOT1cGiSw6vBEjs8JriWfAQgxSjFCLmVtnwJJ0Ix5IHl5YsOy8Fr4uQIXjfbPYUM2wnbWJAYn8oJLJxMxJhIlp3eWA5TMlFgs53SS8jYMwpQvhjwuHBdZRKAceub38e6pPjkCwKFGGNmKdh4/4Zn5fNYthvWZXTWfXBtpf3PMAmKJj4fgklU0/Ez2wNfSsJeNIpvehs5jEuRRe8w87LOcxGAZMBJPOQZzOiNlo+Txzg5ioKPXkd6/ejRZ3tmu6WHkwKf7ZLXTNFIEUhByTpj21QSgbwJSADmjU4ZRcCZQBDczuDwTDNCnb9IJxCBCkCAwpCCkV4yJREQAUcCEoCOAJVdBGISoJcyumQF1/Gj+OPbP2O+lERABNITYLjEZBiHfsMxneIlAiKQJwEJwDzBKZsI5EiAuzRwGIlB6Ywn4vAlZylyKDNdoH+Op9fhIlAhCTCGk55yDltzyRlOhuJQqZIIiIAjAQlAR4DKLgIxCTBei7FFFIGMSWLcUR8YY8kYn6YkAiLwTwKMNeRL0nQY40YZ/6YkAiJQAAISgAWAqFOIgAiIgAiIgAiIQDERkAAsptpSWUVABERABERABESgAAQkAAsAUacQAREQAREQAREQgWIiIAFYTLWlsoqACIiACIiACIhAAQhIALpBJD+uNM/V3pVEQAREQAREQASKh0A9FJWLa4e3Riye0juWVALQDSC3CuJm5koiIAIiIAIiIALFR4DrsM4qvmK7l1gC0I0h925cMGPGDKtfnz8qiYAIiIAIiIAIlHcCCxcutBYtuA11You96LaD5b34BSmfBKAbxoQARJIAdOOo3CIgAiIgAiJQZgQoABs0oPaTACwz6BXsiyQAK1iF6nJEQAREQAQqPgEJQDN5AN3auQSgGz/lFgEREAEREIEyJyABKAHo2ugkAF0JKr8IiIAIiIAIlDEBCUAJQNcmJwHoSlD5RUAEREAERKCMCUgASgC6NjkJQFeCyi8CIiACIiACZUxAAlAC0LXJSQC6ElR+ERABERABEShjAhKAEoCuTU4C0JWg8ouACIiACIhAGROQAJQAdG1yEoCuBJVfBERABERABMqYgASgBKBrk5MAdCWo/CIgAiIgAiJQxgQkACUAXZucBKArQeUXAREQAREQgTImIAEoAeja5CQAXQkqvwiIgAiIgAiUMQEJQAlA1yYnAehKUPlFQAREQAREoIwJSABKALo2Oe8CcPHvf9l385ZYh+b8KqWKTuDvZctt3KwFifpefbWqFf1ydX1FRGDJH39Z7erViqjEmYvKe+3O9ydZl1aNbNsNG1eY69KFxCMgASgBGK+llH6UdwG4990fQRAstHv/tblt2XINa1a/pi3Dg+vv5csTAmH+kj/slyV/WqvGdVyvJZH/r7+X2eQ5i61ds3pWtWrl2Sp6OXj+/tcyq7n6alk5/vbn3/bdz0tsw6Z1rUqVJKPR3/1igyfOtdN3aGPVq+Uv3O58f7LdgU7p2G3Wt6v22yRtWVj/fy5bZjWqZS9r1ospogN6v/mVffbtL/bSydtkrac/0Y5ZM9Vwj7C++n/1o22/YRNbo071f1wx/x6u9zkLf7NHh06zr3Df9WzXxE7YrnVGSsxfA3UetIXwwW+N+d5YlgM3XzfxMdtZv3E/JgT++o1yv2eZH9Vvq5Vyb0bb8az5S+1ztM09N1nb6X4eAH4nPfWZXbXvxnZst5aJa+k79gf7Gc+fo7devyCtiBzf+fIH27ZNY2uK55zv9MpnM+3cl8Ykvmb6jXsZWa2+WhVrWi/edz/ONvL9QrvpoI6l1kf0GoK2NnXu4sQ11q2x6gR1pnabjf29g74x3ic92zW15g1rWbu16mXLEvvvv8Lp8d742bbjRk2tfs3VY+fL9UAJQAnAXNtM9HjvArDlRX1LfCeF3s+//mELlv5p+2/W3F7/4vvE3//To7Vt07pR4obMlNhB/IUepDTv0qWvfWnPfPKdXbh7ezul5wYJsTkFDyuKwfXXrJ3oUIPEcy3542+rE3qIsbOrhmPTdYZxYNPb2bhedbvija/shwVL7cp9Ni4htPidcc4dHMf/B0+aa22a1LUWKH+6RE/ANjcMtDmLfrc+x21lw6bMs+q4zsO2apHIw3Pgn42a/rOt3aCWXfjKWBs+dZ49cNTmNuGHRegEFtj7E+YkTl27+mo2rvdutggPsd/RoYU7Mor1gTiuS6s1cZ6auL7f7LXPZyU6vYeO3tJuHTDR3oRgCNJ7Z29vLVHf03/61e764BtrWGt1O3/3dnbaM6Pt6x8X2cBze5T6gFz025928P3DITJqo5xb2EiUfeCE2Qlvx854sN43eIo9i3q+47DNEuUhA14n6/eDr2dbS4gTtjWyfnL49ERZ2ebq4PrYQX6Dl4TO6zW0TyHIflr8e6Iju/uIzom2s+i3v2yH9k2s/VpJr/WEHxYmBNjJPTZIcF2G7/lw8ly75u0JdmTX9eyQLVsYO2My7QVxMfOXJYl23LReDRuOupj5y9JE/oFfJxkfuuW6dmrPNgk2TG98MStxzv06rWNfwntKpn2GTbc2EOjn7drWbuk/EW34V2tct4bdjzrbquWaKxhToJ3x3Od2zX4bW6cWDRM8r357PBgkv4vp+gM2xUvWH7YOOrrNcMwfaOO8ZnL4Ay8Ne971ke3Tqbn9Z/vWdtfAyRB76yTytWlaz3a+fUji55GX7pQ4nvV7Jr6PadB5PUu8uH0EJmxfLPd4CAte0ybrNEgcy/uQv7Md3P3BZHv3v9sl+E6avShRNz3aNkm8DPJaRqNO3junR6JjDp4fLPfZu7S19dCe2V55fL1U58p6f3zo9ASXTddtkGgL50EYbQyRSvFLsbLjbcnrCHh0b9PIetwyOPF7v7O2s7a41vGo5wHouMmBz4QZeEmaC04f4v7bfL01EvfGjxANG+LYhrVXtwZoz2xbvA62zXchjHkPMp2184YJpq3QDoMXUZaT9ybZnLBdq0Tb5HewfY2Y+rOdi7rmM4NtN/ycWlFw/PDipzMSbXXXDs3sFNxHFBpMX/be1TbtPSDx85grd02UjaL3TtTnTu2bJtjxxfh7iEReZ1V8943vfp04/iCIe+pxiqDoy8IItOmh3/xkR0Ekd71+YOL4Ww7uaOe/PDZxbw45f4fEZ3xu8pn8xYz5tv+9Q1cU+Vx872l4qeQLJvNcvEd723XjtRJi9Su09Z03aoZrn2cT0Q7oHGBad41aifNtsf6aiTbxMb5/F1wvn2Hvg/N2bZok6iVom8+c0DVxr7HdsX6qVa2Ke/jPFXX+yinbJF422e7rwANcDSJ5p1B74HdOu2FP+x7tkGXaEu3oxncnJJ6NTxzfxZ4a/q3tvslaqC/Dc31cgt3th26WEM1bXfd+oi3ed+TmiTbzOu7di14di5e2ZbbXpmvbvfjcV5IAlAB0bVtlLgBzKfAeuOn4xh4WIUc/+knirfWVU7olOh+Ki0sg+i7Zc6NEh7rJlf1XfAVv/JfRMT83ckbiMz60+XA5sPO6CS/A+S+PSdywd6Hj50Nlx9sG2zyI00bwsrzwn20SD9EmeLAwvT32exyLznbHNolOLezBmIYy8IFDL8yud3yYKBc/CxKF6Pm7trPWl7xTomxHPPRJ4qG0QZM6dkSX9RIdFx8ytfCQuvz1cbYvOhA+lCkA2Lk/CCH0yuiZCVHHB94YPGzHgQVFQCETRQwFCBM7yqHfzLM9N10LQu/HQn7NinMd372VPQZvBAVO3RqrJV4QFkKEBYmdPzuWdIkdFz1KpSV6gtm55JMohFgnb6ReUlgOdlxzU518tnPSw8pOt7TUHnVbA22G9ZhP2nL9NRICtizS9ujkjoLYpRctnPji9u1PS6wfxEa6xGv8Fi9FS/EyEU299+lgvd8an3fxW6xZCwJqqdVDx8sXlvKa+IIyctrP1gnidMzMBSuK2RG/jw39Hi0/n1WX7bWRDZn0E55h35X4cy20mzBTcuZLVZCi9wVfVPhyky1dd8AmRk81RQ5HFLKljdaunxCwPlLbZnXxglD6/VPI72yOF1oKwGii6KeTIE46rnvLxItINLGe3zx92zinyOkYCUAJwJwaTJqDvQpAirOetw52LeOK/PTM0fsXpJPwpv7Qh1MLdv50J2pWv4bNXph8q48mvvmNmTkfb6l/Zi0D32CDt/WsB+sAERABERCBCkOAXsruCA0oZJIAlAB0bU9eBWB0+DdTYeldWYo3rXy9Na4glF8EREAEREAEfBA4bQeMAu3WvqCnlgAsLgF4Gmr/fNhaMEbungEbWUqLYOToxbBjYQzImQi7ENYvcnwu50z3VWUqALduvSbi/Bon4jQ4vLsZYrBKC5LljL0D7xtWYlijoHdPBT7ZGhjq5sQaDhPVwZAq4xAZW5UuMWj8z78zjKGGMjGmaT0Mu907aErO9K7ZfxPbHbE/jJnJN9WviTg9TCY69rHSbpt8z1z4fK0xrD8VcXtBCobgGP/H2CLG+oUTO4jVMOzGGDmm/+60YSJ+q7TESRvRITrGK22FiVaMdzri4RGJYUemqOf8cMSGcjJKpuHp0r73ir07JMIWgvixdMfRa844Kk6yiKa+Z25re931cVbgDx69RSIMIoipYzgGYzjjJE586QnvvMvwcvR7rkaMJWNdGasXTR0wDMq4uvYaEH8AACAASURBVCCdipCPddeonQhNSZfORN0y1pKJbToc7hDn+sr6GIYyMN6P17RPp7XtIMTm5pJ2RAwiw29eHT3rH9ka162OeNQ/bLeNmyE+dQ2Enkz7x4jL5ugnRn+Xe5jEiYizfPijaSW+k/GQDNF55OPk54xnfPijqSuGmjmUzmFtxuGWlth3Md4zl8SY0LN2bptLlqzHSgAWjwA8DLX5JOxk2Cews2CHwNrBVkZrr6zym/DjUbATYYzU3Q12O6wbLOjJcz1nugZVZgJw2EU7JoK6c00MnE4E4D89OpGVMXlxY7CC72JM29Mjvi0xfJxrOXg8g8oZf8h01Nbr4ZzJmBp27uzQM8Xz8LiPLtghEb83Z9Fv1uW6ZEA1Hwz/w8xZJpbzVAgBBjFTmF2N+CgOHTOw/dq+ExIB8Bx2ZlwbO38GjHdGcHrU00rWnOW7NSbVMPieQej8f9q8X+0+iDd+x0TECzFom+fn36ZiuP5+TKwg3weGJAVeF3TinHzBxNigI7smZ0typjV5boXYJnZ+nOTAfIzj67RuQwRvr1HqLFd+V2ICAgK+GTfJmElOAmBQ+4kY0l8LnzOYek3EYfJYStNPps1LBOEHM11v6f81eC+0R4/dEszn28EPDE+w4ySinRBUPg/nZ4A9RQOD8zn0/j1YtUAH9m90CrcPmJQI9md6/5ztE8KCLyKsG06WuLX/pMT5GH85AxM61qxdHRMOqtlGV/RLiOUTtm1lFyPmlBMoOJuw5upVE4KHsXw3ILB+U8SIvnXGtjYZsYdDMIHgaMyIjs54ZrvmRBbGOzLWcOPmyckSnBDCcrOej+szyn6Y/xsmpDRN1MkNB26amHzD8u632ToJj/lxfUYmRMmZiE09B3Gm4UR+FFBrIU9Qb4xdDSYhhdvNlOv3TMw65uxsnr9xnRp2EzhzQgJntXJpn47w0nMiCdMwBOaf8OSnifgoCr4BZ/dIxOIxOL8JYjnZ5vgSxxUABk2ck5yYgfIFM8xveGeCPZgK3+CLIROv44DO6yDAvtOKMpITY7N4zo+/mWvdNmicaAeMe/36x4WJc/J6eC8w7pZ/DxInizyBWNZGyPsk/n+s11Z2+3uTEtdz0BbrJmYzs77Jm+egwOMxnB169otf2HHdWiXaIZdYCSadHfLAMEymWhl3+dyJW9s2GzQqwT34hbNUD31wuO2ACUGMlTz92c9RvkaJiRbBfcljX8LEDj5XKFwZL8g2cQ9eBHgf7dphrYS45ISlXo+PTFwfBSQnGnFSBGOGZ+H+a4tnQg20Q05Y4EQPxgfugrx8EeE9z/bM50iQ+P1MXI2BE5X4bGHd8OV8Ieq/1+OjEn8PJtNFL5CTIRgT/A4EfU3Eyd3c72t7YdSMFS+T1+KFjy8ajKkOJncwjnEyYvo4wYP3yKH4OxkNm/JTwjFQC+dh4j3Ll5+bIc6CiVgBL04KYSwjn4HT8TzjdbFN34Z7ej2I1EMxIYspOH42rodtl+z5Enow6p2J11y9WpXERJPf//rbBn09F99Vb8XELE4wu7bv+ER74HOUZX4e18f62wAT8vhyxbZFQcxJKpzowlhpTgr6F+K5D4exHujEIFO+FFyAiYmFTBKAxSMAKfp4R52eagCcisqZCXfDbkzTKBjVfx3s3tDfXsHPS2EUhky5njNd2/MqADfApAc++Jm+vmb3rEtfxL05ePPyjZQPbt58XB6DQ8ecocnlKfidfCiwA1q49K9EB8iOhEKFb6LsxOkl4w3cAR0vH7qbX/Ne4sHLwHROEKGAomBgR8ZOmefeA7O6bsDsMHb0fY7rUuJ6KGYGfDUbnU31xIQFPqjpjWHHwo6KQdV8SAeJS1vwgccHHMvLoO04s4PTMeKD9VN0SomZpJhZnW0mdTbOnMn8Fia9HAXB1wCcAp7Z8uX7d86EpICMs4RNvt8RzkfhNhiipCse7GxDhUzseNgp51uX+ZQl3/p5BJ4PCqknj++aqOdcU/C9+X4/vy/c9tkO+JJY2hIxuZbPx/F8pizGBCW+wLhct4+yFfKcrAu+bJQ2GzndagbkQYHG5x+fQeWpHvOpq3zyROuAqw3wJYMrUBR6aSAJwOIQgFy4awnsYNjroQbyBH5uCNsvzY07D59dAHs09Len8TOnErWE5XNOnopTWpPTWpOJimTmggULrH79wi7UzAdEq4uTs1655APd6uU58Waf9tPixNtdWXbe5ZmJyiYCIiACIlA+CUgAFocAbI7mw4ACDt+Ggyduxu89YF3TNK9n8Vkn2P4wjsftBHsDRh85BVw+5+TX9IZdGf0+HwKQLvMNL3038VVjrsC6VHl4GMrnbadSiYAIiIAIiMCqJSABWHEFYBM0rYdh+8A4hkoRyOj542EMwslXAJaZB5DxSYyZYvrqqt1KLLa8am8bfbsIiIAIiIAIFDcBCcDiEID5DteydTJ6mxHGjAlkrODesI1hLucMt3pvMYALERPXMbUy/cRrd690234V96NFpRcBERABESjPBCQAi0MAsg1xwgbXruDSL0ycBMIppPekhF22dsYI7QmwF2GXpA52PSdP400AcibmFtcml/yYihmGlWlf3myVqb+LgAiIgAiIgAsBCcDiEYBcsoWTPv6TEoJcBuZQGOeFcz0KLhHDOEGu/cfEuECu//dF6v/e+L8VjBsLBgsiZTtnnLblTQBy+j33juRMMC4xoSQCIiACIiACIlAYAhKAxSMAWeNcAiZYCJrC7kwYvXhMg2HTYb1Sv3NyyP2w1jBuhsjptBfBopu+ZjpnnFbmTQBynaptbxqEod+qNvHaPeKURceIgAiIgAiIgAjEICABWFwCMEaVlvkh3gQgF2XdAfsA18XisOMwCURJBERABERABESgMAQkACUAXVuSNwHIXRB2wS4PXEl/9OW7uJZT+UVABERABERABFIEJAAlAF1vBm8CkNswcc9PbhP1ySU7u5ZT+UVABERABERABCQAV7QBbl+plD8BbwKQ2wHtf+9QbCBeyz6+cMf8S6icIiACIiACIiACJQjIAygPoOst4U0Ajpr+sx3ywHBr1biODTqvp2s5lV8EREAEREAEREAeQHkAC3QXeBOAw775yf71yCfWtlldG3A2JzUriYAIiIAIiIAIFIKAPIDyALq2I28CcPDEOdbr8VG2cfP61vfM7VzLqfwiIAIiIAIiIALyAMoDWKC7wJsAfG/8bDvxyU9tsxYN7fXTuheouDqNCIiACIiACIiAPIDyALreBd4E4Dtf/mCnPjPaurRc0148eRvXciq/CIiACIiACIiAPIDyABboLvAmAN/4Ypb99/kvrHubRvbMCVsXqLg6jQiIgAiIgAiIgDyA8gC63gXeBODLn820814aYz3bNbE+x3VxLafyi4AIiIAIiIAIyAMoD2CB7gJvAvC5kd/Zxa9+abt0aGYPH7NlgYob4zTLl+O1QMtDxiClQ0RABERABIqUgDyA8gC6Nl1vAvDJ4dPtije+sj03XcvuO3IL13Jmz79smdkH15h9fIfZgQ+bdTzEbOH3sB/M1tk8mV/CMDtHHSECIiACIlDuCUgASgC6NlJvAvCRj6batX0n2H6bNbc7D+/sWs7M+f/8zey6tXAMvH9BOn+q2S2tQ/ngFTy+v9l6Xf2WRWcXAREQAREQAc8EJAAlAF2bmDcBeP/gKXZTv6/t4C3WtVsP6eRazsz5P/6f2ftXxvuOcyea1aNYVBIBERABERCB4iQgASgB6NpyvQnAuwZOttvfm2RHdFnPbjhwU9dyZs7/1llmnz0e7zuOfcus1fbxjtVRIiACIiACIlAOCUgASgC6NktvAvC2ARPt7g++sWO3Wd+u2m8T13Jmzv/2OWafPhrvO459GwJQO5PEg6WjREAEREAEyiMBCUAJQNd26U0A3vDuBHtwyFQ7YdtWdtneHVzLmTl/3/PMRmHiR5wkARiHko4RAREQAREoxwQkACUAXZunNwF49Vvj7bGh0+yUnhvYhbu3dy1n5vzvXmj2yQPxvkMCMB4nHSUCIiACIlBuCUgASgC6Nk5vAvCKN8bZk8O/tTN3bGPn7NrOtZyZ8/e72GzEffG+o1dfs5bbxjtWR4mACIiACIhAOSQgASgB6NosvQnAi18da8+NnGHn7tLWzthpw2Q5vxlo9uGtZvveZdY49VkuV7DkZ7OaDc2qVsWKL1jy5fOnzdbCBJMvXzIbfk+8M8kDGI+TjhIBERABESi3BCQAJQBdG6c3AXjui2PsldEz7aI92tvJPTZIlrN3g+T/zTAp5EiItjpNzf5YbDb7K/z/q1nbXVdez4xRZoOuNeuOGb4b7GA28Gqzj27DzzuZHf0qxOT7Zk8flDy+/rpY8HlmPBZHv548n5IIiIAIiIAIFCkBCUAJQNem600Anvnc5/bmmO/tckwA+TcmgpQQgKWVeqcrzDr9C4Ju7aS4o8hj2ub0kh6+s8eb3ZHnxJIjXzbbcBdXbsovAiIgAiIgAquMgASgBKBr4/MmAE95+jN7d9yPds1+G9vR27Q0GwuP36snxCvvBdPMbsPEkb9/j3d8Lkcd/pxZ043Mfhhj1mE/bQ+XCzsdKwIiIAIiUC4ISABKALo2RG8C8IQnRtn7E+bYjVgE+nAsBm3XYLg3rqDb4jjE9z1ltuwv1+vLnH+3G8waYPh4o30yC8G//jBbbXWzyQOSQ9bNEHfYpG3Jc/OYatX9lldnLz8E/v4z2SaUREAERGAVEJAAlAB0bXbeBOAxj420DyfNtduwDdxB2A7Obt84fpxe2z3MJr3rem255W/QIikGe2JGceseK/P+Mt3s7i0hRtHhB6kqOv4rflr5+wLEH96F/Y47Hmq2373Jzxf9mPQytsFwMyet/AVvJoe0W2IR6prEXo7TrNFmSzHhps3O5biQq7Bo0z4ye2Jvs10Ro9rtjFVYkDy+mm2Q3vg9b0Y7TMXk5nEaZREBEVi1BCQAJQBdW6A3AXjEQyNs+NR5dtcRnW3fTs3N/gev2fzv4pV3VQjAcMnOgABqlJq4UtouI70XrMwx4DKzYXcnf/8vRF+tNcxuhNeT6UAsUE1h+O5FWKvw/uQ2dNyOjmnZsqQ4DNKyv3HcBfCUwpu4E/c2rmL2HuIiOx9ltv42ZtOHmq3REkJ1HTOKTopTLmnD8zCFzxW+Hs6YZqqC82VLfy41uy61V/KpI5LD5cxPK+386c7JMvH7Mn1n9PrD54mTP9O1ZDp3Ngbp6iac5w605QWpthxuB3HOW6hj+EIxdQjqv7tZ9TrxzxpMxNr6VLPd4QFXKj4CvBcnvIn6H2y2B4R8oT3RvHemDjJrjpfa2muW5MOVGPi863SEdlRaxS1HAlAC0LUJehOAB98/zD799he7/8jNbY9NManjfx0hAL+NV14fAvCIF8yeOyze99eHwDoHE02YSttl5Mr5K8VNWABGv2HTQ8wOegSiCgz+XJL8K0XDZ0/gQXp5cjb0el3h8cTw8qsnmv2G8zLVbpT0wI1FuZmOx98fS82SZv6gI+/yH7ORDyaPueQHiIHaJUvAzqLPXvhuCLsTsAxPNhH3Kzybt6TE7zHoZChYn9wX3tvv4TXCEj78vepqmTn++ZvZ/d2wRA9mex/6ZPpjx2Em91v/NTukD64TM7vDieLmfgibJlg/8vBn4tVZ+Kh5U8wewTm3Oc1s+/Nzzz/wGsw4x7WS/w6Xmq2zeclzlAcB+A6ua+RDZu3hiczEaO6k5ASq7c7Fy8P6K9tNh/1RN2iDPhO94IOuN9vq32Zrd/L5TWV/br6sTf84KZLK2qP/HCbKTcR6pkx73Z7kW8g0Cs+rvmwvLZMvtOEU3Bv8bFW9/BTyWvM9F5+rcV6o8z1/jHwSgBKAMZpJxkO8CcD97vnYxsxcYI8cs6Xt3KHZqheAx/Uze3z3+LyCh1tpu4xcPg9v3tWS5+sPkVDaOoSBALwWDP6CMAoenIGAawhP4VlfruyYwyVcZwuzWZ8lP6FHcOBV/8wfPp5iauMDSl7jHxCd10N8MvFhzod6prRoNibgpOIbj3kD4hRC7tomK3OwHNth7+VMaQL2W37hyJVlTXdscP0Bj/Axk/qbPQuvabq/Zf7m5F+fPXxlCEE+nVS4bOnKcAeE7YIZ+ZcvzjVkOyYTv3DeGyH6+FLBpZdOgQc5yLfJwWYHx9w/O1tZSvv7U2iLUz5YtZzyLXu2fMMgqgfgvqcAPGlwtqML+/dw3W+PEYMdUY5CpsfxwvgtxG26th+8eOR7bxaynKvqXFyyjC+oHH3ZL+b6sx7KKgEoAejarLwJwD3v/MjG/7DQnji+i/VoCwGxqj2AJ6IjenjH+LwC4VDaLiOXwruxeq3k+eIIwGvAgEO7wYMzeIg3gAA8u1ACEB6djeHZCSc+rK7HEDxTeGi7NBL09N2OYV+mo+ClawHv5A3wiAZpzdZmZ36emSO9ey9jIk+mTiKTgImTP1MJwksIVXYBGOUc/N4R3vAD4UH0mW6GJ3lJKlY2n3rwWTbXc9+HF6M5WL80Uxt3/Y50+el5ugqL4QfJiwDcEwIQLwvpri38rKtodRrlPWcCRmIam9UNvQDzmDEYlXntpPR8WD9DbkpuUNAeQtpjkgCUAHRtXt4E4G53fGgTZy+yp//d1bbdEDfRqhaApwxLDkvGTcHDrTRxdxFiwIIg+jgC8GoM6QazmsNDuA3hoTlrbIE8gGkE4G8LEY+ICS5Mp2Fx7ejs5SiP+fBs/Q/eIiaumUgv5M2pdRz52Zro1M9EjGSmlOkBGeTLJAC5w8sbGL5N1wHFqb8nsbwP46Oi+TlsNwQxU+ujHYQn+kTPmc0DGJ7QtKo6wd4UAanYzkxlKE0AbgYP7f4xt0+Mw5zHfPVacvLT1qckcwTex3zrMe73rorj6AGaPS5+G2VYxE8TIQwQCuMydMjZ59fgeRokCUA/tf/TN2b34NmXru1+iefiK6lh9+i95zp6kcPVSABKAObQXNIe6k0A7nrHEJs0e7E9c0JX694GD6xop5qp5Gtvhhm0X7heW8n89H7dHYnlyvQNwY1dWnzf+Ygzq5N6EGcSgFwyht7H6zAEvDw1WSMsAAOPWjo+pQ0Bl3Ytu9+4svMNrm3pL2Y3tUz+dspwDAWWsoA2h4o5rFmthtmdoXit/0Kc3olOK0iN2sCTmBqWLo3faCzh8yYW744+PDm8zHjFLXolJwUFKfoQHYmJM++cl/xrONYybovog7i46ZipG/3+Mc/jzR0xk9HPo+dNJwAXz0keVRfLGaUTgAyc/xjxWOttHW+v6fGIr/wV59wq5tqY0TJehYlGQXviuplBsP4UBO9/Dw/ttmcnhUZpAnDzY5NbMhYyBd8VtLPr4TnmsknpeLOML8FLvHPvf3qtM5WJE8mq1115vfS4zP0ak7bQLkubDMHOvD684NH42HyufS5EHLeeHPviypjmOC8BXElg3mQwx2SxzY/J7Zv5Uvb0gWZd4HXaDPF/gUefZ6EA3Ajt/UXU584Iz4iGgIS/ieLxI7RR7oTUokvpZXgMqzB8hxfmdPUWftad+onZOIghzoQvDzPK/8ayYYxX5gQ+ck6XOAuecd0cus20J/ynj5u9jV2omPgMrFFvZZsbj9CYF1N1GH0+hZ9dcdpFbi2hxNESgBKADs0nkdW7AHwWArDbBvB+hYctXEudT37G2YVFR7ZzBDf2y3jT40Mums7B8EA9xNZRqD7UM/PZNsTkjcnv4ZiQxyboLANBlVUAYjYwt8PLlk7m0A2+hzFf89Dxce/kW9E5Mu3/ADoQzN5jWjwXdw9mINdB3YRFIh/mwYxmHrcbgvj7X7LyW4Py0qMx9M7kMAcne4TTKMSW9U3FCVIMMEieS+wE18gJAVwiJ0injUx2YD3QmW2Cjm44ltIJvvMKzDoMJp1QWI7ATOp/QcgxdvLnqWjBEBkUrUwUmM+jg5z16cpzBw/hnyGS7sKLRZD4+e8QJ7z2hikPKZmQ3a2Rfaovg1DjwuRcGodD/3fDM7BwVvJMFF/0OFZFPOj3Kc9ougc/Z21/jgktWx6fDB0IhtVPh5hunKqfMEMKTp6TxzK+tB2G5ZphKaUghT3K1WqaXYZrZwoYBy8DpQnALdGu94YYSJeWImaQ8ar1UrPBo8dw9nkfrJ25BTrB8CSb4LsYOsCJPdG4V9YB75nVUd5bwJgCmIltlaEL26FjzuQd+xEetwfgeWO7Zbtg+/4WQuWtM7G7z27wWEOUUYhTaFEYcr9x3nec/NUIP5+BdsGYXk7e4BAd70tOouH6nbymunhJ42Qpeoo57MfjKFS5E1FQrmvB5C8cE05XoA0Nh+BguARfAKLtMjyxivk4sWhjtHOuFjAKLzsUddH2zNm2bFf0VnP9UZ6T6UKUM3ih4+8UgGOwuH04JjXMOVzOEbj/++H6mU7nPYIXBH4vrz+Y+NER8bNjcX8F6RKEhIRnmad72e0Kj+8eePkkN5aTz4iAF18sGZLBZwRnLLPOOIrAyWj0FrOdsf0Gba0fnjWMe94Lk7AaIxaZ9xlfkpkmQ7zNx/VHX5r4HfzeTx+DpeJa+eJ9CEQchVtwbop2TrRjWh2T5RgTG5y7ZI0mnzP9sHJDkKpg4tuVqJPXMTLxBUYognQe2hpHdviCwRRmzOcAefG5tS3EZLbY6WgZsvwuASgBmGOT+cfh3gTgLrcPsclzFltCAP6MoaHAo+Na4nzzn414nTtCHWi283Bbuk3w4Ap7w8J5OKGCHqXBeSylcRHe6INh2SYQFqfhTTqbAGRnQbESN3G27rQPkx3NV+iQg8SHEsUbPZJM7Eivjiz1EP6OzbAETfiBFwjA8PI4FEHPQViyE6JnoQ46T85QDaeTBpculJvDMxuIp+j1ce9nTlyhWEnHaD0sj3M8Jvhw5vC18M5F0/GYUMJ1DT/rkxyCC3O4FR3MYginMyHiWWaKMnqXAq9VcOxB6FSCIZ+oQGYH/CE6tnBi/dLbQnH9DWZec/JOIHi5DiQ7PooUpoPRaVE4cB1Jxoiy45qNl5Ug0ZP38R3J3wJh+Qtm04e9svwbPT8Ho8MLv2idj07xllTnGeQPGJLrvzgzHh0+xRFnTLOjZCfONs/YUcamst1RGFP8UixQkD4LQTUJzJm4nEzno5Oe5Uxefi4bQqFCscdZy+nuK4pj1jUFHj3vbLvsxCnUP8Cai1xGKUg8jqItnA5Dx0yROARihCm6hSTbaTicIcEN39Eds9Ef6pH87uCcu2Am+HuYpc8UnlyVbSSDSzw9AXHMRA9ZU9zf4SHDkiX+52/rwFNI7xQnmYTvu+BIsuYi+aWl8GoBFFxcbaAnhAzFLtvYIgi6aOKOSPRqpUtkuNt1mHWMdVkH4f+6aCPf8GU2lFqBHeNJuWQVVy3YG+2VdclE0fZMas/2rdHGRqTWSY2+kPOe4YtiOr5sM3whCl4YTsLyR81DL3PZwovOg+ikoE93bj4nDwXPX9HGJ6DuOHJQD2KuEe6b6Av3ka+svJYoKzoEeM/zHJwcxLQ7YgEDwU3RzxfcAiYJQAlA1+bkXwCeCAH4FN74yiKtgVg1PnhaoZPlUE0w3MdOmx11ILriloXijMNL6RLfoO/Bw7oQqReWdOBSLdEUHgIuxPfwHBQRYQHRA51D0GHG+Y5MHss4+fM9JpNQ3ft/8JTAM3TvVvHPTiEWDBO3A/sZ6KyDCQvxz5L5yIvhvaAXJ+yRTJeDXojAw5PpjIHX8ibEjabbJWdTzJz+El6O0lI49IDH0HsaeDL5OztDeg7DsbIUh4FY5YQlek3S3UdRr26hGHItSk4KiorsfM7PuMcv0iwrFBWK0XNTuOwOTzh3+wnPiE9Xhmgd8OUi7HnOp9y55OHyUUuwQkE00csWrEKQy/n4DGIISybhyxcY3j9BopeXLzYU47/jeUPxni0FYQPZBDbPw9jk1hjG5v3Kl5Y4ec5Ff3AblpVKlxIjNPCyuiRuDsDNAkoLX4qzekKO3y8BKAGYY5P5x+HeBODO8AB+Aw/gS0dtYFu9jAdEOB2Gh3CwTEi0SFw3LoiviHt1XDeQ+aJbsf2+KOnJ4NAOhyRegDeLb2iFSIzjGV3KGneFOD/P4UsADrkFb/MxHsqlXUdYPBXqWrOdh0OgE9/JdlTF/vsOXHAccXu/Y2JPPukcvMzcjpeaYkr0vtJzyNitVZXovTwAw6fh2NLSysLlddKFjKyqsrt+LwXN0RjBiXpOXc8bzc+4Zr6QcW3QbIlDwDPxAs7wm6PgleMQc3lPHnYNkgCUAHRt9t4E4E63DbYpc3+1Vw9fxzZ/HUME4cShKcZZLcdwE4cP6AH5DEM9FBa9sIYcZ66uhrgUxt9kW7tvAyztwgdUnPTV6wg8R6xZsSQfApBxNT9hcWAlESgWAvTQBgsfr4oyUwDuhxnTV2M4PFtiLOJkhB1UlMRZy5xgFMyq93VdPRCbyOVTKmricPDWJxf06iQAJQBdG5R3Afja4WtZ59dD6+8dDRHGWWicmcf9fvk2x7iihdjFgnFYweLKwZXRi3cf4rwYX8bhIAb10t3+LnZCYNwKd/hot3s8DhMRtxR3N5B4Z/R7FOOBsg0f+i2Bzi4Cq54A4xWnIJZyVaVOmKTBGNRgi8RM5VgV3nGfXDhZ5sdQTKqv76oFkck404qauItSl9QElAJdowSgBKBrU/ImAHeEB3AqPICvH9bUNnsDW2oFKZ+p8ZzlxYcDZ5IGiVP+KQrXDK1Rl40GA/EfRJxTsSQJwGKpKZXTJwFO9PkOs8lXVWLsIPdNDvb3zlSOinbP+ortXFV1uaq+dx+smMDlrwqYJAAlAF2bk3cB+OahjazjmxgWcRGArlcZzh9ep6mQ5/VxrorWmfhgpHNWfALRmdFlfcWcCb8LZnIHe2Rn+v6mWGkg2CGkrMvp4/vKygPoo+zl6ZwMIeiMF4kCJglACUDX5uRPAN4KD+BPv9qbhzS0jm8hgJ+Jsw7PGe9aZvf84TXIbjN+aAAAIABJREFU3M/m7wwSgP7Y6szFQ4C75czH0jerKnWGAOyJ9enuKGUR9XC50i1Ps6rKXYjvrWiCthBM8jnHgVjvsWNqf/N88qfJIwEoAejalLwJwB0gAKdBAL59SAPb5K3UEidcIuEg3AirOhWLAFzVnPT9IlAeCOS6Bmahy8xhUK6xGGcnIa6TtxjrPCqJQJgAZ7NvihniBUwSgBKArs3JuwDse3Bd2/jtfZPlDG9Z5Vpyl/wSgC70lFcEREAERCAXAgdgC8xOWHS9gEkCUALQtTl5E4A9bxlk0+ctsXcOqmUd+mKXAi4iy50FykO6BVsVceV3JREQAREQARHwTYC7snRN7UNeoO+SAJQAdG1K3gXguwfWsI3ewUKdjI3h9mnlIQVbgJWHsqgMFYNAvjstVIyr11WIgAhkIqCt4Ly0D2zvoORAwJsA7AEP4LfwAPY7oJq1fxexf9wA/Eys9l4e0svYLm4cVpCvaKka1lOMblRf0a6xLK9nP+xb+ga2AYuTVq+DPZax64ySCFQGAtzZYgmW5voY6yPGSdwebhHWeq0s6QDsjcw1a7mA+QRsbnAqljGqjz2GC5jkAZQH0LU5eROA2988yL77eYn1P6CKtXsXK+lzB4rTR7mWtzD5l843436qTNxovA3WKRyK/WRzSVy02tcwcpzFZLmm1Gd9Spb4OCys/Ti2xasIadNDzHa8HGs9zkzu6fznUuwQg31Fud9mWaSaDcwu+i7ePqMsj4/10rh/6EAsP1JaqoEycq/VdIkehypVsQ/rNYWhxYVs3zmv9HN1PcXsk/vdv6sx9mvl3sPLl+NctDxTdH/aPE+zIluLrbHfLRaizzXVbIh2i+dNaanKaskdkcKprF4m+OzbAbObn8dC1+GUrczrdjE74T3MzMb98T8sFM0U3Vc6vEUbn/2MgXsYGwDkkpiPQvPZ1OxZstoCOzl9in2Go2lHbJOYac9heuh3usJsGrab4wYETNxEILwxAHlwl6Rdr0tuNMDECUgdEbsXbduso/ZY3YL36GCsEdm6p1kTtN2P0Y/0xP7q/DlIXLM2usFBLhxKOVYCUALQtRl5F4AD9jNr2x8PmCYbmZ2WxwPU9QpLy//X72Zf4+2MNy63Ohr7ktmr2JUkSBvtY3bIE9iBYJDZl/hbOwirr7Ap/W642bkoLbeg4+bqt+O6qlaDMMFNzsSHI/cNnYt9V6MP1qZYRmIPbAn0BM4dTSdgp4NHsOMBE98eXzup5BF73ZbsFINO+Dx0knMmJB/Cb56ObYZOTS5WG70OnoVC4N94YP8y3exnbMM3CA84pl7YW3cOluUJzrk9Hnp8a539FXZZeXOlN5Hb9f04Fotx/5Ke5vHY+or5WMf9L8bDEtfPRK8v33wp4u4Fl4AR/9b56OSetrOw3d8CXEM4HYs35lbYFjCaPoK3ISqI9r7D7L3eSSHEBXv5+xvgwd1mFmE2Jo/nMh7sAEY9kjzjFsclxXtjbEe4OToUCszwZvY8pkELxKxiM/sHce3cc3QbnHP4PStLxJ0LuEsNBelRaBfczvAu7JvaELGuXbHlU38IsMRLwpx/XgePbwpW3+F+aI8Z8qwX8mGiAGreGR0PhMM28D4GHWxwlu0vMPsQ8URM3OCe9TQVbTS6T/KVEB3c//qvP5LCJV2bi5aM5eZSFdwrumX35I47A3AdbPNd0R65/2rQRms3NjvyxeRe2+wMm+PabwYDih3uk70P9izm7h2j0FmHt3E7beTKaz382X/eI4yV6oLv+hSzJvueu7KEmyCMhHt+c5u1HuhgR2BdNR4TpNqN4JGal/xtZ7QH3g9fYM9xXgPvj3DiZ4c9lRQDI+DlzZS4Ry3rlPc42+t93bBrEdpzkNItUcOdQ/4Gd5aJ9zvrNrz9Ygc8FLmLERPXOKRnbMlPK8/J+6079sSlqLovtI86X0r4EsTEdtAKi9rXbYpnABbEr446oAD69uPM10NBwzZx6jCcHwvr89nA59pYiKHJA5J7qnPnFW7VSRFD4fYLluB5Fi9kQWrd0+yYVPk/xv3GNkAB9iv49z3bbH20Hca7vYPnCdddPRj11AFx4G+dYfb50yvPE2wK8NSBybbC5xFfpG7AdTNdiO/lfcDnHp/VXJPwT2wK8ACeDeEXwX/h+dx21yQb7hndBPtd3496YgqWseGOU3yGMn2KGd0z0A73vRvH47n4HAQe93BmOZdBjFeF0OT/TMuXQbyhvcyA84JOAl4r7zfuSsV7eBUmCUAJQNfm500AbnfzBzbj56U2YN+/re0AdPZ8uzplqGt5/eWfDSF0P3YcYOKDiB1gnMSHE4VgsE3UEc8nxSITH7TzsOVdcN5gFvQX2Nz+dXS2fMgPxQrxG2GWNDuk3njAM52Mh3gjTFTh3sXcIJ3el+q1k39jp1WjblIkBIk7pQR/X4YH1njsjcx9hOs2Sz48g78Fx3+EByGF4954oFEkUIDwAceOqRr2YGZiB/UiOnImigl2aOwER8DLQ1HAc2+4C8qJjmLbs0qSmjok2UHzTboxroOJ5eJD+04IhWo1zNixVkXnw/Jxh5aHQvtFXwZxFpQjfGY+fL98GXWzbbLjmvUZHtwQBhSWLC89p/VQrhJ5wIZbDU4H0yf2Tv7lcnS2fKgHKV1IQOCxZqfGToJs2FEEe6JSpHc6DB1CiH30eydh68GXITaZ/oN6I3N2aCx/9FgKPTLlPcI6STBDJ8SOjC8TTOzM2HEHbY7XFSS23ykfmL3fG+0J13lIn5LfwWGo/vD2cD09doYUwxQYp0PUXY/hOaYD8VnHUEfPz/5E214d4jlI3E6RO/Kshfs5XaJ3nUIluAYeMwod67coN1+MyJ1lZJ3Ru8My05M5CD+zbVN018NSKmwvb0DEjcG9wnTh9KQ3JpzehtigN4j3C8U4vd8UXefCixP2uAR12A4eG74IsFPnNZEjRd0wCIFJEJbdIFD4src1vJmLIdz5kkeBFU705ozFPR6EBhyJUJLEyyA81BTjTSE+wvcm87J9D74x+SJCTzbbLF84KJ740sYXufDLYof9IcTw8snE3UcobFrjheYYPA+YP909zWN5Dz+a2nWp25m4LohwJnq6+EJEDxrFDZ9X4baTrh5Z79yPnfdoUId9z0n+zPu6W0RUpzsHy8kXgnC9sb5Yb+F18aLtmeKML+jpXgL5PayDn/Dyw12dOFLAdhVOwYtyHdQd2zpFIV/oo8/BIA/vYfIIt9l018PPeG7WQWnnKi2fh88lACUAXZuVdwH4/r5/WJsBvdBhYFPxk/GAL8+Jb5mM04g+wOOUeS46HT7oudZT+EHyN0TPTS2T4ukCeN/4AGbiQ50dJTuu6hB0zMP8fNvukFo2J873+jqGDzp2hnwjDw9n8ME8Fp4fdnoNUm/quZSB+XnusKhgfopdihMufh1XfOfyvRQU9PQ1g4iKCtaF38NLhM5/K+zVOROdDwUyPRyte5b8Bu5XPRodM70+HSH+gs4xU2dBhs03XymESzuW4nY1COPoUBFFIEUKBVxb7HldF17FTCnhkcPLQrrOjAzoQeELBI+jGGJ7nDcF1w3xwHU6s11TLsxzOTZctrj5EgIO909NPsZ4T4ETPdFxOvK435HuOJb1S9wD9ADx/ihEYtnZ9obDI0kvNifNMdF7zhcqPlf44pQtUYQyL+v4LrwkMryFw7GFSHw2fYsXFLYTlyFNXmtQZy7lKqv6dimjx7wSgBKArs3LmwDc9qYPbOYvS+39fX6zNu9h0gVF1UmDXctbnPn5xsiU7a27OK+uYpWaooJD3QwLUBKBYiZAb2wNPOJXlagvZnZFUHYJQAlA12bqTQB2v/EDmzV/qQ3c+1fb4H14VujZORFxHkoiIAIiIAIiIAJOBCQAJQCdGhAyexeAg/ZaZK0GYuiNs/L+jSBjJREQAREQAREQAScCEoASgE4NqEwE4J7zrdUHCOZeD8Hsx6em37uWWvlFQAREQAREoBITkAAsLgHIFWW5uBCmuBm3xEDUuSHqt9TEqZWYjmaYBmZcIwDTHw1rbBimZyVSbxgWISqRMDXKMA0tdvLnAbxhoLVfNNSu6V7dmo/CTDcubXAsApSVREAEREAEREAEnAhIABaPAMSUQcMCS4a1Pwzz/43ijustcLXINAuFGVfm5GqXmD1hWD/BsCKm9YFh/QFLzcVPCEBMDbPUvP9EW+JidKEFpbK2L28C8JFrTrIT/sbyA0HqgmHgPVPrl2Utlg4QAREQAREQAREojYAEYPEIQIo+boMRLJ7ExZWweqdhASrDAlH/SFxxlqtMplYGTvydq1hyVdBgEbHe+BkLRhkWVss7eROAS3o3s9ornJUon4fNsPO+amUUAREQAREQgSImIAFYHAKQK+ti8a2Etw6Lna1IXOkTq8IaVpj9R6IHECvpGpY3TwwTY4l9wyJ1htWC7frU0b3xP4eUuTQ8h4Wx5UJiiDiyrULGFu5NAP7Ve02rZqEtjg5F0cvD+nZFfMOr6CIgAiIgAiJAAhKAxSEAuQP0LBj3pqFICxLHQ7n9QWivnxING0u5G7aAMG4LgFWEjcudMyYwSNxuAqt9GuP+uJQ/4wG5Mi+X6MfqqGkTVxINryaKVVNt5oIFC6x+/dRiqqVkzOljrqV2FbVtKHH7qzZhh2ZOZ9TBIiACIiACIiACKQISgBVXAPZEHTPeDxssJmIGuZ8W9gwzbKxope3uTsWFpdoTMYKhTTJL3C+98Vt04ogVXABylwtuYRROveDAjG6BpVtZBERABERABEQgZwISgMUhAPMZAuaeadhtOjHEGyRsJGnYgDTh9cNeRGkT4wyx8WFiKDhdKhsPYDoB+G8Uq8VWOTdyZRABERABERABEShJQAKwOAQga41ePMbycekXJk4CYaweJ3ukmwSCXe4TQu7CUJUfgZ/p2eOwbSi4bsURFIY8Z29YahfwrLeMnxhAbkF0E/ZLDaeTsJ9lc5f5KlmvRQeIgAiIgAiIQKUgIAFYPAKQy8Bw0gfWQkkIQS4Dgx21E2v2zYZxiRjGCQaeO4o4DuWeBAuGgO/HzxSGPBcT4wPfgnHYl3GGV8GosDrA5sa8AzwJQOylelPLkkU4FQ5Nbp6uJAIiIAIiIAIi4ERAArB4BCArmkvABAtBf4GfOcmD4o5pMGw6rFfqd076uBR2NIwTOyjoKPb4GdxricQYwe1hjVJ//zj19ympv8f5z48AXPKz2c2tSn7/GaNR0g3ilEnHiIAIiIAIiIAIZCAgAVhcArA8NmY/AvDXeWa3cOWaUDprHBa9aVEeGahMIiACIiACIlBUBCQAJQBdG6wnAYjNSG6JePvO+dqsPlerURIBERABERABEXAhIAEoAejSfpjXjwBcjN3tbt2wZNkunG5Waw3X8iq/CIiACIiACFR6AhKAEoCuN4EfAbgI81pu4/bFodSbG5YoiYAIiIAIiIAIuBKQAJQAdG1DngTgjxCA7VaWrXlnzGce7FpW5RcBERABERABEQABCUAJQNcbwY8AXPiD2e1c4SaVmm8OATjItazKLwIiIAIiIAIiIAGYaAPcJ1cpfwJ+BOACLGl4B5cjTKWtTjDb67b8S6mcIiACIiACIiACKwjIAygB6Ho7eBKAMyEAN06UbV7n063RbtjQpCa/SkkEREAEREAERMCVgASgBKBrG/IjAOfPMPvfJvb78tXt21OnWdtm3L1OSQREQAREQAREoBAEJAAlAF3bkR8B+At2p7uzo/0GATgDAnBDCUDXelJ+ERABERABEVhBQAJQAtD1dvAkAKdDAHaypcur26zTplqbpvIAulaU8ouACIiACIhAQEACUALQ9W7wIwB/nmZ212b26/Ia9sNpUyQAXWtJ+UVABERABEQgREACUALQ9YbwJACnQgB2tsXLa9qPCQFY17Wcyi8CIiACIiACIpAiIAEoAeh6M/gRgPOmmN29uS1aXstmn/aNBKBrLSm/CIiACIiACMgDWKINaB1At1vCjwD86Ruze7awhctr29zTJ9sGTeQBdKsm5RYBERABERCBlQTkAZQH0PV+8CQAJ0MAbmkLIADnQQC2lgB0rSflFwEREAEREIEVBCQAJQBdbwc/AnDuRLN7u9j85XXs59MnSQC61pLyi4AIiIAIiICGgDUEXMC7wI8AnPO12X1d7efldW3BGZOsVeM6BSyyTiUCIiACIiAClZuAPIDyALreAZ4E4AQIwK1t3vJ6tvCMiRKArrWk/CIgAiIgAiIgD6A8gAW8C/wIwNnjze7fxn5aXt8Wn/G1tZQHsIBVplOJgAiIgAhUdgLyAMoD6HoP+BGAP44ze6C7zV3ewJacOcHWb6QhYNeKUn4REAEREAERCAhIAEoAut4NngTglxCA29qc5Q1t6ZnjJQBda0n5RUAEREAEREBDwBoCLuBd4EcA/jDW7MHtbDYE4O/wAK7XqHYBi6xTiYAIiIAIiEDlJiAPoDyArneAHwH4/RdmD/WwH5evYX/AAygB6FpNyi8CIiACIiACKwlIAEoAut4PngTg5xCAPe375Wva3//9ylqsKQ+ga0UpvwiIgAiIgAgEBCQAJQBd7wY/AnDWaLOHd7BZyxvZsv+OkwB0rSXlFwEREAEREIEQAQlACUDXG8KTAPwMAnBHm7m8sS3/75cSgK61pPwiIAIiIAIiIAFYog1UUYtwIuBHAM781OyRnWzGsiZW5eyxtu4aGgJ2qiVlFgEREAEREAEJQAnAAt4FfgTgjFFmj+5s30EAVpUALGB16VQiIAIiIAIiYKYhYA0Bu94HngTgSAjAXezbZU2t2jljbZ2GtVzLqfwiIAIiIAIiIAIpAhKAEoCuN4MfAfjdCLPHdrNpy5pZjXPGWHMJQNd6Un4REAEREAERWEFAAlAC0PV28CMAvx1u9vjuNnXZWlbznC8kAF1rSflFQAREQAREIERAAlAC0PWG8CQAh0EA7mFTlq1ttc/93NZuoCFg14pSfhEQAREQAREICEgASgC63g1+BOD0oWZ99rRvljW3OueOlgB0rSXlFwEREAEREAF5AEu0AS0D43ZL+BGA0z4ye2Jvm7xsHasHAbhWg5pupVRuERABERABERCBFQTkAZQH0PV28CQAP4QA3McmQQA2OG+0NasvAehaUcovAiIgAiIgAhoCXtkG5AF0ux/8CMCpQ8ye3NcmLlvXGp73mQSgWx0ptwiIgAiIgAiUICAPoDyArreEHwE4ZZDZU/vbhGUtrNF5n1pTeQBd60n5RUAEREAEREBDwKE2IA+g2w3hSQB+AAF4AATgehCAoyQA3epIuUVABERABERAHsBIG5AAdLsp/AjAbwaaPX2gjV+2vjU+f6Q1racYQLdqUm4REAEREAERWElAQ8AaAna9H7wKwK8gAJueP8qa1KvhWk7lFwEREAEREAERSBGQAJQAdL0ZJABdCSq/CIiACIiACJQxAQlACUDXJuddADa7YJQ1risPoGtFKb8IiIAIiIAIBAQkACUAXe8GLwJw+eT3rcozBxmHgCUAXatI+UVABERABESgJAEJQAlA13vCqwAct6ylrX3BSGskD6BrPSm/CIiACIiACKwgIAEoAeh6O3gRgMsmvW9Vnz3IJABdq0f5RUAEREAEROCfBCQAJQBd7wsvAvDvSe/Zas8enBCAzS8cZWvWqe5aTuUXAREQAREQARFIEZAAlAB0vRm8CsAvIQDXhQBcQwLQtZ6UXwREQAREQAQ0BBxqA1oI2u2G8CMAJw6w1Z47xCQA3SpHuUVABERABEQgHQF5AOUBdL0zvAvAFheNsoa1NQTsWlHKLwIiIAIiIAIBAQlACUDXu8GLAPxrYn+r9tyhCQ+gBKBrFSm/CIiACIiACJQkIAEoAeh6T3gRgH9+3d9Wf/5QG7usla0PD2CD2qu7llP5RUAEREAEREAEUgQkACUAXW8G/wLwYgjAWhKArhWl/CIgAiIgAiKgIeCVbUCTQNzuB08CsB88gIclPYASgG41pNwiIAIiIAIiECEgD6A8gK43hXcB2PKSUVa/pjyArhWl/CIgAiIgAiIgD2BxegBPQ7HPh60FGwM7AzYyQ3M+C387BbYe7CfYy7CLYb+F8uR6zujXeRGAf0zoZ9VfOMzGLGttrS4ZKQGoZ5YIiIAIiIAIFJCAPIDF4wE8DPX+JOxk2CcwirtDYO1gc9K0iX/hs8dgx8OGwdrC+sCeh52TOj7Xc6Zret4FYGsIwHryABbwttepREAEREAEKjsBCcDiEYAUfaNgp6cabVX8PwN2N+zGNA35Hny2EWyn0N9uw89dYdumPsv1nGUnAMe/a9VfPDzhAdzg0lFWt0a1yn6v6vpFQAREQAREoGAEJACLQwByFeQlsINhr4dq/wn83BC2X5oWQQ/gfbBdYRwmbg3rC3sKdj0sn3Pya2qkLPjKevhh5oIFC6x+fToDC5N+hwCsAQH4BQRgGwnAwkDVWURABERABEQgRUAC0K8ApOiaWoDW1hznmAXrBhseOt/N+LkHjF69dOlMfHgrjDOd6UJ7AMaYQKZ8z9kbea+MfplPAbghBGAdeQAL0Ix0ChEQAREQARFIEpAA9CsAl4HxENijME7ACE++yKUN5iPWeuILGO93GYxDvW1gd8Iehl3jIADLxAP42/h3rOaLRyQ8gBKAuTQVHSsCIiACIiAC2QlIAPoVgJuhCo6DHQHjkOsLKTGYaeZuulrLZ7j2I5xoBIyzhoN0FH54CFYXRo9grsPK6crmZRLIb+P6Ws2X/5UQgG0vG2W1qysGMPvtrCNEQAREQAREIB4BCUC/AjCoBaqXfWG9YLvDJsE4Q5fxeHPjVVXCi0fhyKVfmDgJ5DsYJ3ukmwTyGT5/H3Zh6PwUovRGMm7vb1iu50xXVM8CcANrBwFYq/pqMTHpMBEQAREQAREQgWwEJADLRgAG9cDh01NhN8Do1fsD9mJKpP2QpbK4ZAsnffwHRiHIZWAOhbWHzYZxiRjGCXKdP6beMC73chIsGAK+Hz9TGPJcTNnOmaVIiT97EYBL4QGslfAASgDGqQQdIwIiIAIiIAK5EJAALBsBuCUqhevxHQ77FUYhR0/cujBOqKCI6hKj4rgETLAQ9Bf4mZM8KO6YBsOmw3qlfqfX8VLY0bB1YPQ0vpX6bH7ouzKdM0aR/AvA9pePspqrywMYpzJ0jAiIgAiIgAjEISAB6FcA0gPHGEAu1vwO7JHU/5wcEiSKQAq3Yg1y8+IBXPLlW1b7laMSHkAJwDi3so4RAREQAREQgfgEJAD9CsDJqArG+vWBlTbEy6FgxubRK1iMyasA/HxZG9vo8pHyABZjy1CZRUAEREAEyi0BCUC/ArDcVnwBC+ZdAHa4YqTVqKYh4ALWmU4lAiIgAiJQyQlIAPoVgBz+XQx7KdLOuIdv7SL2+oUvx4sA/HXsm1bn1aONHkAJwEr+lNLli4AIiIAIFJyABKBfAcjlXjhrd1Ck5rh7B9fjY2xgsSevAnA0BOAmV4yy6tW46o2SCIiACIiACIhAIQhIAPoVgNz5g8u0TI9UVkv8PgFWqxCVuIrP4UcAjoEH8LWjTQJwFdeuvl4EREAERKBCEpAA9CsAuVAzl1l5M9J69sPv98I4A7jYkxcBuBgCsG5KAG565ShbfTV5AIu9oaj8IiACIiAC5YeABKBfAXgTqpqLLTMW8MNUtXP4lzODuTfweeWnKeRdEk8C8A0IwGMSHsCOEIDVJADzriBlFAEREAEREIEoAQlAvwKQS7xwuzdO+vgrBZ+uLO7acTKMO4EUe/IjAL+AAHz9GPts2YbW6cqREoDF3kpUfhEQAREQgXJFQALQrwAMKrstfugEWwr7EvZtuWoFboXxLgA36z3KVqtaxa2Uyi0CIiACIiACIrCCgARg2QjAitzkvAjARfAA1kt5ACUAK3Lz0bWJgAiIgAisCgISgP4FICd67AtbD8Yh4XDiVnHFnrwIwIWfv2b13+iVGALuDA9gVXkAi72dqPwiIAIiIALliIAEoF8BuBPqmjOAp8K4HMw4WEsYxzNHw3YsR20h36J4FYCfLmtrW1w10qpU0RBwvhWkfCIgAiIgAiIQJSAB6FcAjgTwd2FXwhbBGAc4B/YMrB/s/grQJCUAK0Al6hJEQAREQAQqFwEJQL8CkKJvM9gU2C+wbWFfpYTgG/i/ZQVobt4F4JZXj6oAmHQJIiACIiACIlB+CEgA+hWAP6Kqd4Bx14/xsItgHBKmJ3AorG75aQp5l8SLAFww+lVr8OZxxiFgCcC860YZRUAEREAERCAtAQlAvwLwdVDvC3sYdiuMO4D0gR0Io0dw5wrQLr0IwPkQgA0hAEdBAG4lD2AFaCa6BBEQAREQgfJEQALQrwBsnfLyjcX/dWC3wbrBJsM4A7girAcoAVie7miVRQREQAREQARiEJAA9CcAVwP/7jCKv/kx6qJYD/EiABd89oo1eOt4eQCLtVWo3CIgAiIgAuWagASgPwHIiv8NthFsWrluBW6F8ywA22EImJOplURABERABERABApFQALQrwD8FBV1IWxgoSqsHJ7HiwCcDw9gw4QHUAKwHNa5iiQCIiACIlDkBCQA/QrA3dE+boBdDvsM9mukvSws8vbD4ksAVoBK1CWIgAiIgAhULgISgH4F4LJQc1oe+pnbWvB3xgkWe/IiAH/59GVb4+1/ywNY7K1D5RcBERABESiXBCQA/QrAHllqfUi5bBW5FcqTAHwJAvAEG7msvXW5+pPcSqSjRUAEREAEREAEMhKQAPQrACtD8/MqAEdBAG4lAVgZ2pGuUQREQAREoAwJSAD6FYDbZ6nLD8uwrn19lRcB+POol2zNvidgCFgC0FfF6bwiIAIiIAKVl4AEoF8BGI4BDFpZOBZQMYCl3Hs/j3oRAvBECcDK+2zSlYuACIiACHgkIAHoVwA2iNTd6vi9M+wa2KWwirA8jBcP4DwIwEYQgCOXbYQYwBFox52jAAAgAElEQVQebwGdWgREQAREQAQqHwEJQL8CsLQWxckht8O2qABNzo8AHAkB+A4E4HIIwKskACtAO9EliIAIiIAIlCMCEoCrRgC2RxvgItF1y1FbyLcongTgCxCAJ0kA5lsryicCIiACIiACGQhIAPoVgB0j7Ln+39qwi2DVYNtWgNbpRQD+9MkL1vjdk+wTeAC7ygNYAZqJLkEEREAERKA8EZAA9CsAOQmEkz4o/MKJY5rHw74uT40hz7J4FYAaAs6zVpRNBERABERABOQBzNgGouKskA1m/cjJKAjnwn4r5Jes4nNJAK7iCtDXi4AIiIAIiECuBOQB9OsBzLU+ivF4PwJwxPPWuN9/EAPYAZNAhhcjF5VZBERABERABMotAQlAvwLwLtT8NzD+H06n45c2sLPKbcuIXzCvAvATCMCuEoDxa0NHioAIiIAIiEAMAhKAfgXgLNTBvrDPInWxOX5/E7ZujDoq74d4EYBzRzxnTfqdjEkgEoDlvQGofCIgAiIgAsVHQALQrwBkrN8mMHoBw4nev3GwmsXXZP5RYq8CUEPAFaCF6BJEQAREQATKHQEJQL8CkCLvAdg9kZo/A7+fAutQ7lpE7gXyIgDnDH/WmvY/RTGAudeHcoiACIiACIhAVgISgH4FIJd6ofi7BfZBqjZ2wv/nwhj/93DWGir/B3gVgJ8s3xgxgMPKPwWVUAREQAREQASKiIAEoF8ByKZATx/3/W2eahfT8X9v2JNF1E4yFVUCsIJUpC5DBERABESg8hCQAPQvAIPW1AQ/LIUtrmDNy4sAnD3sGWs24FRMApEHsIK1F12OCIiACIhAOSAgAehXALZCHXPLt8mRut4Qv/8Jozew2JNfAWgQgL01BFzsjUTlFwEREAERKF8EJAD9CsAhqO7HYE9Eqv0o/H4CrGf5ag55lcarAByBSdRb9x6aV8GUSQREQAREQAREID0BCUC/AnAhsHPNv3TLwHyKzxtWgIbpRQD+OPQZW+s9DAFDAHaVAKwAzUSXIAIiIAIiUJ4ISAD6FYALUl6+zyOVvgV+HwyrV54aQ55l8SQAn4YAPE0CMM9KUTYREAEREAERyERAAtCvAHwL8Dnx4wjY36mKWA3/vwCrA9ujAjRPTwLwKQjA022EbYoh4I8rACZdggiIgAiIgAiUHwISgH4FIBd6/hA2H/ZRqtq3w/8NYDvAuFB0sScJwGKvQZVfBERABESg0hGQAPQrANmguP7f6bBOMHoDx8Luhq0jAVj6/fbDx0/Z2u/LA1jpnki6YBEQAREQgTIhIAHoXwCGK5LessNh/4ZtCeNwcLEnLx7AHz560tYeeAZiADfFJBANARd7I1H5RUAEREAEyhcBCcCyEYDbp0TfQfj/e9irsFdgo8pXc8irNF4F4AjriBjAYPQ8r/IpkwiIgAiIgAiIQISABKA/AbgWWPdKCT+KpBdhJ8M4FDy+ArVELwLwe3gAm8MDKAFYgVqKLkUEREAERKDcEJAA9CMAOfuXXr++sGdg/WCcBczdPyQAYzR/CcAYkHSICIiACIiACORJQALQjwD8C/VxF+x+WHgbOAnAmA31+w+fsOYfnCkPYExeOkwEREAEREAEciEgAehHAG6NSuBEj8NgE2BPwZ6H/SAPYLzmOQsCcB0KwCqIAbxSMYDxqOkoERABERABEYhHQALQjwAM6HOxZ4rA42FdYJz1ew6M+wMvildF5f4oLzGAKwVgJwhALqWoJAIiIAIiIAIiUCgCEoB+BWC4ntrhF3oFj4ZxD+D3YPvmUZGnIc/5ME4yGQM7AzaylPMMxuc90vztHXy2V+rzPvj/2Mgx/fH77jHL5kcADulj6wz6LzyAEoAx60GHiYAIiIAIiEBsAhKAZScAg0qhF3AfGL2CuQpAehOfhHE28Sews2CHwCgu56Sp9TXxWfXQ543wM0XjCTAKPyb+3wx2XOi43/HzLzFbkVcBOBwCcBt5AGNWhQ4TAREQAREQgXgEJADLXgDGq5n0R1H0ce1A7izCVBU2A8adRW6McWIKxqtha8N+TR1PAUiP5P4x8qc7xIsAnDnkcVt30FkmAZhnrSibCIiACIiACGQgIAFYPAKQnrwlsINhr4fq9ImUgNsvRkv/EscMh50UOpYCkOLvDxi9fh/ALoPNK+V8NfA5LUj18MPMBQsWWP361IKFSTMGP24tBp+lIeDC4NRZREAEREAERKAEAQnA4hGA3FN4FqxbSsQFFXkzfmCcX9csbZuTUOhB5HHhmEFuTUdhOQ22Aex62GLYNjCuXRhNvfHBldEPCy0AZw5+zNYdfLYEoB5YIiACIiACIuCBgARg5RGAD6ZEXccs7ag1/j4FtjNsYJpjy8QDGAjA4VU2QwzgEA9NX6cUAREQAREQgcpLQAKweASgyxAwl6PhHsRXwO6M0dzn4hgOA1M0Zkt+YgBTHkAJwGz49XcREAEREAERyJ2ABGDxCEDWLodwOXzLpV+YOAnkO9g9sEyTQHrh7w/A1oGVFtsXtJ51U+dkXOCbMZqUFwE4Y9Bj1mLI2ZgEIg9gjDrQISIgAiIgAiKQEwEJwOISgFwGhpM+/pMSgpzVeyisPWw2jEvEME7w4kgr4FYa/JzxfuFUF78wnu8V2I8wxgAyppATOzaFcTmYbMmTAHwUAvAcxABuhoWgNQScrRL0dxEQAREQARHIhYAEYHEJQNYtl4AJFoL+Aj+fCaNnkGkwbDqsV6gRcI3Ar2G7wrj4dDjVwi+cUdwZxqVgOEw8AHY5jIIyTvIiAL8b9KitBwE4vEpnxADyspREQAREQAREQAQKRUACsPgEYKHqvlDn8SMAP4AA/FACsFCVpPOIgAiIgAiIQJiABKAEoOsd4UkAPgIBeK4NrwoP4BXyALpWkvKLgAiIgAiIgARgyTZQRU3CiYAXAfjtB4/Y+gkBuDkE4CCnAiqzCIiACIiACIhASQLyAMoD6HpPSAC6ElR+ERABERABEShjAhKAEoCuTc6PABz4sK3/0XnyALrWjvKLgAiIgAiIQBoCEoASgK43hhcBOH3gQ9byo/MlAF1rR/lFQAREQAREQAIwbRtQDKDbreFZAG6BGMAP3Eqo3CIgAiIgAiIgAiUIyAMoD6DrLeFHAL4PD+DH9ABKALpWkPKLgAiIgAiIQJSABKAEoOtdIQHoSlD5RUAEREAERKCMCUgASgC6NjlPAvBBeAAvkAfQtXaUXwREQAREQATSEJAAlAB0vTG8CMBp7z1orYZeYMNW29K6XT7QtYzKLwIiIAIiIAIiECIgASgB6HpDeBWAwyEAt5EAdK0j5RcBERABERCBEgQkACUAXW8JCUBXgsovAiIgAiIgAmVMQAJQAtC1yXkSgA9gCPhCkwfQtXqUXwREQAREQAT+SUACUALQ9b7wIgCnDnjAWg+7EDGAWyEG8H3XMiq/CIiACIiACIhAiIAEoASg6w3hRwD2v99aD78IHsCtEAMoAehaScovAiIgAiIgAmECEoASgK53hCcBeB8E4MUSgK61o/wiIAIiIAIikIaABKAEoOuN4UUATul/n20AAaghYNfqUX4REAEREAER+CcBCUAJQNf7QgLQlaDyi4AIiIAIiEAZE5AAlAB0bXJ+BGA/eABHyAPoWjnKLwIiIAIiIALpCEgASgC63hleBOA3/e61NiMusWHVuli3y95zLaPyi4AIiIAIiIAIhAhIAEoAut4QEoCuBJVfBERABERABMqYgASgBKBrk/MjAN+FB/ATeQBdK0f5RUAEREAEREBDwOnbQBU1DScCEoBO+JRZBERABERABMqegDyA8gC6tjpPAvAeeAAvVQyga+0ovwiIgAiIgAikISABKAHoemN4EYCT373HNkwIwK6YBDLAtYzKLwIiIAIiIAIiECIgASgB6HpDSAC6ElR+ERABERABEShjAhKAEoCuTc6PAHznbttw5GXyALrWjvKLgAiIgAiIgIaA07YBTQJxuzW8CsChq29t3S/t71ZC5RYBERABERABEShBQB5AeQBdbwkvAnASPIBt4QGUAHStHuUXAREQAREQgX8SkACUAHS9L7wKwGHwAHaTB9C1jpRfBERABERABOQBjLQBDQG73RR+BGDfu6ztqMtNAtCtcpRbBERABERABNIRkAdQHkDXO8OLAJzY905rN+oKDAFvgxjAfq5lVH4REAEREAEREIEQAQlACUDXG8KrABwGAdhNAtC1jpRfBERABERABDQErCHggt4FEoAFxamTiYAIiIAIiIB/AvIAygPo2sr8CMC3/2ftPr3ShlWHB/ASDQG7VpLyi4AIiIAIiECYgASgBKDrHeFVAA6t3s26X/KuaxmVXwREQAREQAREIERAAlAC0PWG8CIAv4YHsH3CA9gNHkAJQNdKUn4REAEREAERkAewZBvQMjBu94QEoBs/5RYBERABERCBMicgD6A8gK6Nzo8AfOsOa/9Zb3kAXWtH+UVABERABEQgDQEJQAlA1xvDswDsjiHgd1zLqPwiIAIiIAIiIAIhAhKAEoCuN4QXATjhzTtso9H0AEoAulaQ8ouACIiACIhAlIAEoASg613hSQDeDgF4lQSga+0ovwiIgAiIgAhoCDhtG9AkELdbw6sAHFp9WywD09ethMotAiIgAiIgAiJQgoA8gPIAut4SfgTgG7fZRp9fbRKArtWj/CIgAiIgAiLwTwISgBKArveFVwE4rMa21u1ieQBdK0n5RUAEREAERCBMQAJQAtD1jvAiAMfDA9gBHkAJQNfqUX4REAEREAERkAcwXRtQDKDbneFHAL4OAfgFhoDhAewuD6BbDSm3CIiACIiACEQIyAMoD6DrTeFVAA6rsR2GgN92LaPyi4AIiIAIiIAIhAhIAEoAut4QngTgrfAAXoMhYAlA1wpSfhEQAREQARGIEpAAlAB0vSs8CcBbIACvlQB0rR3lFwEREAEREIE0BCQAJQBdbwwvAvCr126xjcdcixjA7RED+JZrGZVfBERABERABERAQ8Al2oAmgbjdEl4F4LCa21u3iyQA3apIuUVABERABESgJAF5AOUBdL0nPAnAm+EBvM4kAF2rR/lFQAREQARE4J8EJACLTwCehmo8H7YWbAzsDNjIUhr3YHzeI83f3sFne6U+pwf0KtiJsIawobBTYJNj3jBeBeDQmj2s+0VvxiyKDhMBERABERABEYhDQAKwuATgYajUJ2Enwz6BnQU7BNYONidNha+Jz6qHPm+EnykaT4D1SX1+If6/GHYsbBrsGtimsA6w32I0IgnAGJB0iAiIgAiIgAiUJwISgMUlACn6RsFOTzWiqvh/Buxu2I0xGhYF49WwtWG/wuj9+x52G+zWVP4G+H82rBfs+Rjn9CIAx712s22CIWB5AGPUgA4RAREQAREQgRwJSAAWjwCkJ28J7GDY66F6fgI/c+h2vxh1/yWOGf7/9s4F3qox7+PPIOkiEb2FVMi4RWGmm5fMDKpBhpl48X6cFxNya0xSmDqSppRL7kY47pdiDK8J4xKlKJKoSbmcXN7QRWEKld7/b9mrWee0b+esvfZee+/v8/n827uz1/Os5/n+n7XXb/2fyzbrnzh2V3t936yz2ZxA/pcS/78gizKjEYCPjXH7zh1lcwAPtUUgDAFn4QcOgQAEIAABCGRNAAFYPAJwR/Pqp2bdEyLOd/JV9kbz/Lpk8PrP7XNFEHWcP2dQZWnOn8peEsj/iL3fYKYh59qpof1B5qet7c0nq1atcs2aSQvmJr2TEICvNLI5gBcjAHNDlVIgAAEIQAACPxJAAJaPALzN/N3NbL9A56+PAKy0/MNrX0C5FoBvmwDsaBFABCBfVRCAAAQgAIHcE0AAFo8ADDME3MS6jub6DTMbH+hG9RkCzksE0BeA0xv1dN0v/lvuez4lQgACEIAABMqYAAKweASguqmGcDV8q61flLQI5COzG83SLQKpsM9vNdvJbHmgv/uLQLQARAtBlDSOqxXFylOwRSBvPzradXz7zw4BWMbfTjQdAhCAAAQiI4AALC4BqDl5WvRxppmEoFb19jPb00wrd7VFjOYJaluXYJqa+PuJSXqStoEZYhbcBkbDxAXdBsYXgK9YBLAHEcDIvgAoGAIQgAAEypMAArC4BKB6qbaA8TeC1srd880UGVSaYlZtVhHoztojcIHZEWb/SNLN/Y2gtTJYq4mnmQ0wW5jlJRHJKmAigFnS5zAIQAACEIBAPQggAItPANbDzZFmiUQAzp002u33DkPAkXqOwiEAAQhAoGwJIAARgGE7fyQC8O1Jf3Yd3xltcwAPs0UgwW0Pw1aX/BCAAAQgAAEIIAARgGGvgkgE4NxJoywCOMa2gTnM5gAiAMM6ifwQgAAEIACBIAEEIAIw7BURiQB8a+Iot/+8MW56Y4sADkYAhnUS+SEAAQhAAAIIwJp9QIsgSPUnEIkAnDvxSrffvKsQgPX3CzkhAAEIQAACKQkQASQCGPbyiEQAvvXIlW7/+Ve5Vxr/wvUY/NewdSQ/BCAAAQhAAAIBAghABGDYCyJiAfhLE4CPha0j+SEAAQhAAAIQQADW6AMMAYe7JBCA4fiRGwIQgAAEIJB3AkQAiQCG7XSRCMA5j4x0neaPtTmAv7RFIEQAwzqJ/BCAAAQgAIEgAQQgAjDsFRGtAGxiAvAiBGBYJ5EfAhCAAAQggACs2QcYAg53TSAAw/EjNwQgAAEIQCDvBIgAEgEM2+kQgGEJkh8CEIAABCCQZwIIQARg2C4XjQB8+ArX6Z/j3HSGgMP6h/wQgAAEIACBTQggABGAYS+LiAXgr2wO4KNh60h+CEAAAhCAAAQCBBCACMCwFwQCMCxB8kMAAhCAAATyTAABiAAM2+UiEYBvPjTCdV5wtQ0BEwEM6yDyQwACEIAABGoTQAAiAMNeFdEKwKaHu+6DJoWtI/khAAEIQAACEGAIuEYfYBuYcJcEAjAcP3JDAAIQgAAE8k6ACCARwLCdDgEYliD5IQABCEAAAnkmgABEAIbtctEIwAcvd53fvcZNZwg4rH/IDwEIQAACENiEAAIQARj2sohEAM5+sNId8O61JgCPsDmAE8PWkfwQgAAEIAABCAQIIAARgGEvCARgWILkhwAEIAABCOSZAAIQARi2yyEAwxIkPwQgAAEIQCDPBBCACMCwXS4aAfjAcHfAwuvc9K1tCPiPDAGHdRL5IQABCEAAAkECCEAEYNgrIhIB+IYJwAM9AXikCcBHwtaR/BCAAAQgAAEIBAggABGAYS8IBGBYguSHAAQgAAEI5JkAAhABGLbLRSIAZ98/zB2waDwRwLDeIT8EIACBLAmsX7/erV27NsujOSzuBBo0aOA233zzlNVEACIAw/bhSATgGyYAD/QEYC8bAn44bB3JDwEIQAACKQhs2LDBffbZZ27lypUwKjECzZs3d61atXI/+cmmP3qGAEQAhu3u0QrAZiYAL0QAhnUS+SEAAQikIrBkyRJP/LVs2dI1btw4qViAXnERkKhfvXq1++KLL5xEYOvWrTdpAAIQARi2VyMAwxIkPwQgAIECEdCw78KFCz3x16JFiwLVgtNGRWD58uWeCNxjjz02GQ5GACIAw/a7aATgfX9yB753vZthEcBuRADD+oj8EIAABJIS+Pbbb92HH37o2rVr5xo1agSlEiOwZs0aV11d7dq3b++22mqrGq1DACIAw3b3SAXg9Ga9bQj4obB1JD8EIAABCCQh4AvAZAIBYMVPIJ1/EYAIwLA9PBIB+LpFAA+yCCACMKx7yA8BCEAgNQEEYGn3DgRgev9uujSmtPtDrluHAMw1UcqDAAQgkCcCCMDkoLVytrKy0p111ll58kQ0p0EAIgCj6Vk/lhqNALz3MnfQ+zcQAYzSc5QNAQiUPYFiFYDJtjUJOnP48OGegKtvWrp0qWvatGnRz4tEACIA63sNZJMvEgE4ywTgzyQAt+njuv/hwWzqwTEQgAAEIFBHAsUqALVvoZ8efvhhN2zYMPfuu+9u/JvEmyyYtDWKVj1vscUWdaRUvIcjABGAUfbeSAXgDBOA3RCAUfqPsiEAgTImUKwCMOiyqqoqN3DgwE02sn766add79693TPPPOMGDx7s5s2b56ZOnertizdo0CA3c+ZMp1Wy++yzjxs9erTr2bPnxmKDQ8BipBXSOs/EiRPdCy+84Nq0aeOuu+46r/w4JwQgAjDK/hmRALzUIoA3OgRglK6jbAhAoNwJJBMIipStWbs+72gaNdi8XptQZxKABxxwgBs3bpwn2rbffnv33nvvuTlz5rhu3bo5/VzahAkT3M033+wWLVq0ccPkZAKwbdu2buzYsa5z585eeYo8Ll682DVrpttgPBMCEAEYZc9EAEZJl7IhAAEIREggmUBY/f06t/ewZyI8a/Ki54840jXesu7Ds5kEoCKBRx55ZNr27L777m7IkCHujDPO8I5LJgBHjhzpLr30Uu/zFStWeBtnv/jiizUih3mHluGECEAEYJR9MlIBOH2bX9scwAeirD9lQwACEChbAuUgAJctW1bjV05WrVrltEhEwlBzCdetW+cNBUvcjRgxIqUAfOKJJ9zRRx+9sa80bNjQ3Xvvva5fv36x7T8IQARglJ0zGgF4jw0Bf6Ah4F/bHEAEYJQOpGwIQKB8CZTDELDEXfBXMCoqKtyMGTPcmDFj3G677ebN75Ow69u3rzcXMFUEcPLkya5Xr14bO4vKVPTxxBNPjG0HQgAiAKPsnBEJwEtMAN7kZjQ3ATgQARilAykbAhAoXwLlsAiktgDs0KGD69+/v7vooos8x69cudLtvPPO7txzz0UAltmlwEbQ4RwekQAcagLwZhOAR5kAvD9cDckNAQhAAAJJCZSjAOzTp4/TsLAWf2hbGA39Tps2zQ0YMAABWGbXCQIwnMMRgOH4kRsCEIBAwQiUowDUKuDTTz/dzZo1y7Vs2dITgHfccYe3mIMh4IJ1xYKcGAEYDnskAnDm3UPdzz8kAhjONeSGAAQgkJ5AKQhAfJyaAHMA0/cOBGC4qwcBGI4fuSEAAQgUjAACsGDo83JiBCACMMqOFrEAPNrmAN4XZf0pGwIQgEDZEkAAlrbrEYAIwCh7eCQC8LWqoa5LtYaAEYBROo+yIQCB8iaAACxt/yMAEYBR9vBoBeC2JgAvIAIYpQMpGwIQKF8CCMDS9j0CEAEYZQ+PSABebBHAW90MBGCUvqNsCECgzAkgAEu7AyAAEYBR9vCIBeAxFgG8N8r6UzYEIACBsiWAACxt1yMAEYBR9nAEYJR0KRsCEIBAhAQQgBHCjUHRCEAEYJTdMBoBeNdg12Xxbe7VbY9xXYkARuk/yoYABMqYAAKwtJ2PAEQARtnDIxWAM7br67qdf0+U9adsCEAAAmVLAAFY2q5HACIAo+zhCMAo6VI2BCAAgQgJlLsAPOWUU5wYTJo0yaN88MEHu65du7px48alpL7zzju7IUOGuHPPPTeUZ3JVTrpKIABLRwCeY025yKyV2Vtm55nNTNO85vbZlWbHmW1ntthsoNnfE3kq7XV4rfzv2v/3rEOvjlQAvmoRwK5EAOvgDg6FAAQgkD2BYhWARx99tFu7dq17+umnN2ns1KlT3SGHHOLeeustt99++6WFUVsArlixwjVo0MBtvfXWOROAEyZM8ATjsmXLapS5dOlS16RJE9e4cePsHVbHIxGApSEAT7BmaCz0LLPXEkLud/b6U7MvkjRxS/vbK4nPRtnrp2ZtzVaaSTwqVZr91uxXgfzr7H3NXpqeXzQC8M6LXJeP/uIQgHW82jkcAhCAQB0IFKsAfPzxx93xxx/vFi9e7BRJC6bTTjvNvf32227WrFkZSdQWgBkz2AF1jdylEoDZnCvsMQjA9ASL5beAJfrUm/2Y82b2/mOzG8xGJ2mihKKihYrmrU2BQALwWLNOITpZJALwVROAXSUAWxzrup53d4jqkRUCEIAABFIRKFYBuG7dOk+IaRj2sssu29i8b775xrVu3dqNHTvWnX766e7MM890L7zwgvv888/dLrvs4h1/3nkaPPsxZRoC/uyzz9wZZ5zhnn/+ea/cUaNGuUGDBtUYAta57r77bvfBBx+4Fi1auL59+7oxY8Z40b3nnnvOHX744TXwX3HFFV6dawvJ6upqd/7553vn2mKLLVzv3r3dDTfc4HbYYQcvv/Io4qn6Dxs2zK1cudIdddRR7rbbbnNNmzZN6mIEYPprvxgEoKJ5q80UrXs80BwpIw3z9k3SRA3zrkjk0+dLzR4wG2O2PnF8pb1KJK4y+9ZshtlQs4/SI6vxKQKwDrA4FAIQgECcCCQVCBs2WNhAt5w8pwY2FPqT7G/JgwcPdo899phbtGiRZfsx31133eXOOecct2TJEtewYUM3evRoTyRJmE2bNs0ThPfdd5877jjNjMosAI844ghv6PbWW2/1ziGBNmfOHE9g+nMAr732Wte5c2fXrl079/7777uzzz7b9erVy11//fXu+++/dzfeeKO78sor3bx587xzanhZ4jAoAH/44QfXqVMnt91227lrrrnGy6dyVG+JSCUJwPHjx3vCUAJw+fLlrl+/fu6ss85yl19+eVJnIQDT9+Hse1uer4XA6Xa09xrC7W4mkeanq+zNoWZdklRtgf2tndn9Zjeb7Z54vd5e/Z7S297rsUHz/lqbaT7gTmb7mn2dorkN7e8yP2mixCerVq1yzZpJC+YmEQHMDUdKgQAEIJCOQFKB8P2/nBul206e0yX/59yWTbI+6YIFC9xee+3lXnzxRdezZ08vn+b+tW3b1t17b/IfEJBYUuTsoYce8o5PFwGcP3++22effdzs2bM9gaf0zjvvuI4dO3qRuVSLQFT2wIEDnaKHSqmGgIMCcPLkye6YY47xhrR33PFH9nPnznX777//xvP7AlDlSkAqXXjhhW7mzJmeuE2WEIDpu1OpCsCF1uytzNqb+RG/C+29In4Se5gPxUgAABVuSURBVMmSoolaKKLj7khxTKX9vfbCEZdrAXjf3ya7ma9NdT/dp5M75+R+6T3IpxCAAAQgUC8CxSwA1eAePXq43Xbbzd1zzz3uvffecx06dKghCCXUqqqqPGGltiqydtBBB7np06d7vNIJwEcffdSdfPLJbs2aNRsjjMqjYIeGgn0B+Oyzz3qRRgnSr776yq1fv947l0xRyGwEoKJ+t9xyixfNDCZFCzXEe9JJJ3kRwCeffNJb3OInRSJvv/12t3ChbvmbJgRg+suiGARgfYaAX7Jma+5fcIGHIn4aGlYE7/sUWDTPUPFmDQUnS3mJAF733EJ33XOL3ElddnGjftOxXl9sZIIABCAAgfQEinkIWC278847vTlxiopJhD388MMbh4Q11Nu/f39vSLVLly7e0KuO0RDu66+/7oEJKwA15Lv33nt7YlDDsdtuu6176aWXvPN+/fXX3ty8XApAzQH06676a7saDU9L/CIA6361F4MAVKu0CERbvvizV7UIRHP1bjRLtghEK39PMtvV7IcElgvs9WKzVLF9DQerzEozDRVnkyKZA3jtPxa68c8vciebALwSAZiNHzgGAhCAQJ0JFOsiEL+h/qIPCaGRI0d68+YuueQS72O918KMZ555ZiMXDRUrTzYCMNkQsObx7bvvvhuHgCU4Tz31VC/a56fKykpvTp4vABWdvOCCC9yXX35Zwz/ZDgG/+eab3vxAfxEIArDO3TxlhmIRgNoGRos+zjSTENR+fhob1Srfz820RYzmCfqRuzb2XjNOlUcrhTuY3WkmYae9AZW00+WTZhr2lSjU3ECtCN7bTItGskmRCsBTuu7iRh5LBDAbR3AMBCAAgboSKHYBqPZqla4Wg2j49aOPPto4h06RvxEjRriJEyd68wI1FHzTTTd5w8TZCECVrRW8Em4antUiEAk5zQn0F4G88cYb3pCyhpr79OnjtAfh0KFDvUUovgB8+eWXvTmKWo0s8aj5e40aNUq6CESLPlTv7777zg0YMMBbFBJcBEIEsK49PP3xxSIA1QptAeNvBD3H3p9vpsig0hSzarOKQHO72ftrzSTqJA41ry+4ClizYA8xa2EmwadZpJeavV8HxJEIwNkffelmL/7S7dW6meux+/Z1qA6HQgACEIBAtgRKQQDOmDHDde/e3RNgTz311Mamq20ain3iiSfcZptt5s2j06bLEmLZCkAJOW0nozytWrXy5v5p9XHwl0AUfbz66qu9ufASeieccIKrqKjYKAA32KpqrT6WSNXK3XTbwGg4W+dKtw0MEcBse3fm44pJAGZuTf6PiEQA5r8ZnBECEIBA+REoBQFYfl7LvsUsAknPCgGYfV9KdiQCMBw/ckMAAhAoGAEEYMHQ5+XECEAEYJQdDQEYJV3KhgAEIBAhAQRghHBjUDQCEAEYZTdEAEZJl7IhAAEIREgAARgh3BgUjQBEAEbZDRGAUdKlbAhAAAIREkAARgg3BkUjABGAUXZDBGCUdCkbAhCAQIQEfIGg37HV1iSk0iKgXzGprq527du3d1ttpR8H+3fStjnbbLON/qB/viqtlmfXGhaBZMcp1VEIwHD8yA0BCECgYAT0s2X6GbGWLVs67UFHKi0C2nbmiy++cHvssYfbfPPNEYC13IsADNffEYDh+JEbAhCAQEEJaK+7lStXeiJQ++Rpw2NScRPQ3oOrV6/2xF/z5s1d69atN2kQEUDn6Onh+jkCMBw/ckMAAhAoKAGJBf2WrkQgqbQISPxpA+tkoh4BiAAM29sRgGEJkh8CEIBADAhoOHjt2rUxqAlVyAWBBg0abDLsGywXAYgADNvPEIBhCZIfAhCAAAQgkGcCCEAEYNguhwAMS5D8EIAABCAAgTwTQAAiAMN2OQRgWILkhwAEIAABCOSZAAIQARi2yyEAwxIkPwQgAAEIQCDPBBCACMCwXc4TgB9//LFr1kxvSRCAAAQgAAEIxJ2ABGCbNm1UTTaCjruzYlq/naxen8S0blQLAhCAAAQgAIH0BHa2jz8tR0jsAxjO6+K3o9nX4YpJmnvrhLhU54yi/AiqXKciaV+dcMXyYHwYS7fUqVL4sE64YndwqftPwKNso8r+P7MNsfNsHiqEAMwD5HqewhteNivV8DTtq2fHiFE2fBgjZ9SzKviwnuBikq3U/SfM5dDGgnQnBGBBsGd10lLv9LQvq24Q64PwYazdk1Xl8GFWmGJ7UKn7DwEYYddDAEYIN2TRpX5h076QHSQG2fFhDJwQsgr4MCTAAmcvdf8hACPsYAjACOGGLLqh5R9q9mez70KWFcfstC+OXqlbnfBh3XjF8Wh8GEevZF+nUvefSJRDG7P3eA6PRADmECZFQQACEIAABCAAgWIggAAsBi9RRwhAAAIQgAAEIJBDAgjAHMKkKAhAAAIQgAAEIFAMBBCAxeAl6ggBCEAAAhCAAARySAABmEOYFAUBCEAAAhCAAASKgQACMJ5eOseqdZFZK7O3zM4zmxnPqtaolVYtH2e2p9kas+lmF5u9Gzhqir0/tFZbbrP/nxX42y72/hazw8y+MbvbTGWvKzCDSjv/8Fp1UNvUXqWtzK42O9FMK9eeMRtg9nkRtM2vYrW9aZuE8832N/XLKWbF5L9DrL66lg40a232G7PHA+3Td+DlZr83a272itnZZosCx2xn728wO9rsB7NHzS4wU9/003725iazn5ktTRx/VRKOUfwpXRsb2AlHmvUx29VMm8s/ZzbETL+A4Kdqe1Pb77rmRsegjZl8WGV1PLUWWF17vQJ/i7MPM7Uv1a9UDLb2jU20Mc7+y+a+kKvvzp7G4xqzfcw+TvR99Q9SEgIIwPh1ixOsSveYSRC9ZjbQ7HdmPzX7In7VrVGjp+1/D5nNMtvCbJTZvmZ7m/0rceQUe11oNiyQc7W9/yrx/83tdY7ZZ2a6ceumLR63m11S4PZX2vl/a/arQD0kSpcl/i/R+muzCjPdaG80k2DoUQRt85u0g72RD/wk//3DTGJ8SsKKyX+9E/zfsNfHzGoLQD2g6AYlAfGh2RVmHc3UZ79NQJhsr+qHZ5pJUN1lpj5+UuJz7cUmJhJW2rZJ+e8007X7l40ko3uTro36JaFJZrp+9DC5rdl4M/n4oECVqu39HYnj/D/rJyj967aQbczkwyqr53+Y/U+gPdo668vA/+Psw0ztUyAgmHS8fLW72QeJD+Lsv2zuC7n47mxvLN4xu9Vsgtkvza4z03eyHghItQggAOPXJST6dHM5N1G1zexVTzKKQASfxuNX801rJDEh0aqI0cuJj6fYqwSebo7Jkr7c/tdMv7HsR84khseYqbzvC9jwSjv3sWadktRBN1pFfiQKdMNVUmTwn2bdzF41i3PbUmHVF+hRZh3MFImYYlas/lP9gwJQ33+KgilqOy4BQH5Uv6sw08PMXmbzzRTZez1xjCJLfzfT73QrvyKGV5rpRu33T12r6it+dDgV31z/vXYbk5WvtmhEQRG/jxIHVNurfC1LluLSxmTtq7IKK3or3slSMfkwG/8pgq3fsJXA8VOx+E/1rX1fyNV3p+4REnt6aPWTrmH1jWA0OEU3Kb8/IwDj5fMtrTqKhinKFBym0hCoOnHfeFU3Y230hKqhNEVE9GSmNMVM4Xn1PUX5njRT1EXtVhphdoxZUGTpyU5PugeYvZnxrNEdUGlFKyqp6J6iQzPMFD3STfQXZs+bKcKyMlCFxfZeN9VrY962ZNTUHyVwNKSiaK7SFLNi9V/tm6uGRN8362wmUeunlxL/1zDvaWYSiPKrnxTdlv8Vmf+rmSLUipAFBYgipi+YaegxGIkKFBPJ22wEhCLYz5rpO8WPvFfbew3DKcKp/vyAmfqsP+0iLm1MJQDFXuJbrMX9MrPlCcLF5MNM/lOk8xMzRazlIz8Vi/9U39r3hVx9dyrIMNssGFxQVFjfvxKZpFoEEIDx6hKKen1q1t1M4sJPmkukKFqXeFU3bW0UuXzCTDeZgwNH9rf3EkUSFpo3pac2RSM0d1BJQ2aKTBwZyNPY3msoSvOYNJRTqKQIXlMzzfvTkKDmA+5kpidOzQ/T0KDm/gWT2vaimYYa49y2ZEz72R91k9GcTH++WDH7r/bNVdeZ5vzpulsSAPCIvdexmo6haQe62WoKRjApsi3/a+hKYkrDxxoi9pOGkOeZ6VVR4HylTAJCIk9tXmB2cqBSF9p73TxXmImLhrLVn/V3pbi0MVn7NOdWD5DywW5meljR/ExF3tebFZMPM/lP8/40f1N91p+iIP8Ui/+S3Rc0apKL705Nw1A56rt+0j3jKTPdQzQvnRQggACMV3coJQGoG6MEk8SfnlhTJf/pT0+FisYUk0iSuJWY1Zevvlxy8SUWpx6peTOKqkjcloL/yl0AKrqnBSwauu5p5kf/kvlWUTMtztIDj+bTxVkA1q6/H9lVpFNR+VISgBLumpOrhYHpUlz9l+y+gAAs0Lc+ArBA4FOctlSGgLX4QcPVWt2mp/J0qYl9qKd1zdGQ4IjzEHCydmi+pib/60u5lIaAFYXVsLsis39L48Bi8l85DwFL/CmyKXGkhy5/eDSVazXMr2kbmsOoiHech4CTtUHzcTUMLBFbKkPA/2lt0TCnpsdoQU+6FEf/pbovMAScwZlRfYwAjIps/cvVIhANG/pPeAqZa06OLp64LwJRf9JiFU2072kW3EojFRGtkJ1mtr/ZXDN/oYSGWP1Vzxp21HYHLc0UjYhLUnREvqk00zxN3XT+y0xRFiUNG+qJvfYikGJom9qkIc02Zum23ykm/6VaBKIFIJrnp6S5fOp3FWbBRSBaMauVxEpHmGllY+1FIJqftTZxjIYh/S2REn/Ky0uyIURf/Gkhj+Ymqp9mShoelujb3kzz6vxFIIVuY6YhUrVLftF1qXmBmobiLwIpBh+ma1+VtUXTTYKrt1P5MU7+y3Rf8BeBhP3u1HQiDflqzrmfNIVF83BZBJKkpyAAM30N5v9zzTuSmNDNV0JQE1o1F0tP4sH95PJfs8xn1F5xCucr+hfc+0+LJjREqvk5+lwrKBWB0BxATTTXELHmOCr528Bozpnmu2hl5b1mWtavoZxCJgkFLVrRsK+G67V/nJ7GNc9LN1UNb+gLqMJMw2sSw0qaUxX3tgW56qFDkdsHzTTfyE/F6D+JdE0vUNICIg3Xa06m5rpJJGhuptqoeX5qsxYkqV/W3gZGwker0f1tYLQiWH1ZSTcw9XcNk+ompJu0toH5g5mmNESd0rVRcxu1Kl0LqLSaO/gdIgYa4tcDiuYXi4u2ftH/dV1qvq24FLqN6dqnNmguph66tKhMfVRzprVKVkLAf2BUW+Lqw0x9VPz1YCJf/tFM25wEU9z9l+m+oLbk4rvT3wZG+3Hq+lNk8XoztoGp1WH8/yIAU4Ap8J+1BYy/EbRWJ55vpshg3JOeXpMlrcSqMlM06T4z3SA1dKjtbbSKUhvVBucjafhRXwg9zbT4Q4JYN+lCbwStiJCGtVuYSfApcnmpmeYuKvmbmepJNrgRtG5Mfopr2wJV9CJcGo5XBFMTq/1UjP5TH5KwqZ3UpyrM9B0oIa8os+Z0yqfavDvYbkUQFIEPbgStazLVRtDaF1LiX2IwHyldGyutAqmmYSgaOMVM4lA3aT1kqt/qeD10afV3MOIe3Ow6n21M1z5FJrVjglZyy396cJQQ/5NZUOzG2Yfp2leR6EDqn1rNqtEDPVAHU9z9l+m+oLbk6rtTLPXwogc4BRb0QFdVixf/TRBAANIVIAABCEAAAhCAQJkRQACWmcNpLgQgAAEIQAACEEAA0gcgAAEIQAACEIBAmRFAAJaZw2kuBCAAAQhAAAIQQADSByAAAQhAAAIQgECZEUAAlpnDaS4EIAABCEAAAhBAANIHIAABCEAAAhCAQJkRQACWmcNpLgQgAAEIQAACEEAA0gcgAAEIhCeQzU+UhT8LJUAAAhDIEQEEYI5AUgwEIFAwAlV2Zv8ny4KV0K+Z5Os3QBGABXM/J4YABOpDAAFYH2rkgQAE4kRAAlC/86qfHAwm/YzZl3mqKAIwT6A5DQQgkBsCCMDccKQUCECgcAQkAPU7sMemqILEmX7f9xiznmZLzAabTQoc39HejzfrZrba7FGzC82Cv/d7mv3/j2a7m61IHKPf7VbSOX5vph+eP9Ls08SxTyQ+39Ze9XvC+p3lpmb6ndJRZncF6sBbCEAAAnkjgADMG2pOBAEIRESgysrNJACX2zFDzF42+2+zoWYSff80a2K2yGyG2XCzlmYTEsdWJOp8tr1ekyhjsr1uY9bD7LrE5xKAEnUSlrPMzjOTYGxrJrEo8afjJRKXmUlENjJ7MpGfFwhAAAJ5JYAAzCtuTgYBCERAoMrKPMXs21plK8Imkzi71Uwizk+v2pvZZooMSpSNMWtj9q/EAX0S4mxHe/3cTBE9ResuS1F/nWOk2Z8Sn0tUKnrY2+xpM0UCJfwkCkkQgAAECk4AAVhwF1ABCEAgJIEqy7+TWVDgqUhF3mQSZ1okck/gPNfa+05mh5kpstc58d4/RBG+lWaHmi0wkwj8hdmLKeqqc/Qzmxj4fJW9VyRQ55UQ1LDyQrNnzR43m56iLP4MAQhAIHICCMDIEXMCCEAgYgJVVn6mIeAwAvBNK/+rLATgbxLCzm+uBORAM9VPaQczRRYPNzve7CazQRGzoXgIQAACSQkgAOkYEIBAsRPIRgDeYo3UcK+fNN9Pwi7bIeAP7dj7zdINAWcSgEHOZ9p/xpo1K3b41B8CEChOAgjA4vQbtYYABP5NQAIw2TYw6+zvmnen4Vm9Xmw2zezkhJDTIpD5Zo3N3jPTkGylmSJ1WgQy1awicRpFEDWPUGVoEcjWZlrUcUPi82TbwAQjgCPsuDfM5pk1NBttpsUmXRL5eYEABCCQVwIIwLzi5mQQgEAEBKqszGQbQb9rf9/TTOLsHDNtE3OImbaBkZB7JFCXbLaBUdTuD2a7mklQahuZ8xNlZBKAihyeZNbObI2ZxKXKUmSRBAEIQCDvBBCAeUfOCSEAgTwTYJPmPAPndBCAQPwJIADj7yNqCAEIhCOAAAzHj9wQgEAJEkAAlqBTaRIEIFCDAAKQDgEBCECgFgEEIF0CAhCAAAQgAAEIlBkBBGCZOZzmQgACEIAABCAAAQQgfQACEIAABCAAAQiUGQEEYJk5nOZCAAIQgAAEIAABBCB9AAIQgAAEIAABCJQZAQRgmTmc5kIAAhCAAAQgAAEEIH0AAhCAAAQgAAEIlBkBBGCZOZzmQgACEIAABCAAAQQgfQACEIAABCAAAQiUGQEEYJk5nOZCAAIQgAAEIACB/we2DLcLYgoQCQAAAABJRU5ErkJggg==\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_error_curves(history)\n",
    "plot_training_acc_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA 2 (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7592 samples, validate on 3796 samples\n",
      "Epoch 1/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.1778 - acc: 0.7983 - val_loss: 0.1947 - val_acc: 0.8164\n",
      "Epoch 2/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.1279 - acc: 0.8538 - val_loss: 0.1848 - val_acc: 0.8385\n",
      "Epoch 3/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.1103 - acc: 0.8720 - val_loss: 0.1582 - val_acc: 0.8722\n",
      "Epoch 4/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.1005 - acc: 0.8875 - val_loss: 0.1398 - val_acc: 0.8712\n",
      "Epoch 5/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0954 - acc: 0.8882 - val_loss: 0.1288 - val_acc: 0.8659\n",
      "Epoch 6/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0925 - acc: 0.8853 - val_loss: 0.1214 - val_acc: 0.8722\n",
      "Epoch 7/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0902 - acc: 0.8878 - val_loss: 0.1178 - val_acc: 0.8683\n",
      "Epoch 8/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0878 - acc: 0.8879 - val_loss: 0.1162 - val_acc: 0.8717\n",
      "Epoch 9/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0848 - acc: 0.8928 - val_loss: 0.1120 - val_acc: 0.8778\n",
      "Epoch 10/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0818 - acc: 0.8984 - val_loss: 0.1097 - val_acc: 0.8783\n",
      "Epoch 11/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0801 - acc: 0.9017 - val_loss: 0.1050 - val_acc: 0.8786\n",
      "Epoch 12/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0788 - acc: 0.9052 - val_loss: 0.1041 - val_acc: 0.8817\n",
      "Epoch 13/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0777 - acc: 0.9111 - val_loss: 0.1012 - val_acc: 0.8788\n",
      "Epoch 14/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0770 - acc: 0.9131 - val_loss: 0.1010 - val_acc: 0.8688\n",
      "Epoch 15/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0765 - acc: 0.9116 - val_loss: 0.0988 - val_acc: 0.8751\n",
      "Epoch 16/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0759 - acc: 0.9131 - val_loss: 0.0983 - val_acc: 0.8736\n",
      "Epoch 17/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0751 - acc: 0.9119 - val_loss: 0.0973 - val_acc: 0.8812\n",
      "Epoch 18/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0745 - acc: 0.9112 - val_loss: 0.0975 - val_acc: 0.8828\n",
      "Epoch 19/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0739 - acc: 0.9123 - val_loss: 0.0966 - val_acc: 0.8764\n",
      "Epoch 20/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0733 - acc: 0.9115 - val_loss: 0.0976 - val_acc: 0.8728\n",
      "Epoch 21/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0728 - acc: 0.9098 - val_loss: 0.0965 - val_acc: 0.8757\n",
      "Epoch 22/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0724 - acc: 0.9099 - val_loss: 0.0959 - val_acc: 0.8854\n",
      "Epoch 23/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0720 - acc: 0.9102 - val_loss: 0.0971 - val_acc: 0.8749\n",
      "Epoch 24/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0715 - acc: 0.9106 - val_loss: 0.0957 - val_acc: 0.8754\n",
      "Epoch 25/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0712 - acc: 0.9103 - val_loss: 0.0965 - val_acc: 0.8741\n",
      "Epoch 26/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0708 - acc: 0.9096 - val_loss: 0.0967 - val_acc: 0.8754\n",
      "Epoch 27/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0706 - acc: 0.9111 - val_loss: 0.0985 - val_acc: 0.8757\n",
      "Epoch 28/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0703 - acc: 0.9120 - val_loss: 0.0990 - val_acc: 0.8759\n",
      "Epoch 29/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0701 - acc: 0.9125 - val_loss: 0.0997 - val_acc: 0.8757\n",
      "Epoch 30/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0697 - acc: 0.9125 - val_loss: 0.1000 - val_acc: 0.8746\n",
      "Epoch 31/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0695 - acc: 0.9129 - val_loss: 0.1014 - val_acc: 0.8757\n",
      "Epoch 32/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0691 - acc: 0.9148 - val_loss: 0.1024 - val_acc: 0.8775\n",
      "Epoch 33/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0689 - acc: 0.9157 - val_loss: 0.1020 - val_acc: 0.8751\n",
      "Epoch 34/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0685 - acc: 0.9158 - val_loss: 0.1030 - val_acc: 0.8767\n",
      "Epoch 35/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0683 - acc: 0.9177 - val_loss: 0.1023 - val_acc: 0.8812\n",
      "Epoch 36/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0680 - acc: 0.9168 - val_loss: 0.1024 - val_acc: 0.8822\n",
      "Epoch 37/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0679 - acc: 0.9179 - val_loss: 0.1030 - val_acc: 0.8820\n",
      "Epoch 38/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0678 - acc: 0.9214 - val_loss: 0.1043 - val_acc: 0.8743\n",
      "Epoch 39/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0675 - acc: 0.9194 - val_loss: 0.1037 - val_acc: 0.8859\n",
      "Epoch 40/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0675 - acc: 0.9215 - val_loss: 0.1048 - val_acc: 0.8836\n",
      "Epoch 41/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0674 - acc: 0.9206 - val_loss: 0.1044 - val_acc: 0.8857\n",
      "Epoch 42/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0673 - acc: 0.9222 - val_loss: 0.1054 - val_acc: 0.8775\n",
      "Epoch 43/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0672 - acc: 0.9223 - val_loss: 0.1045 - val_acc: 0.8838\n",
      "Epoch 44/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0671 - acc: 0.9218 - val_loss: 0.1030 - val_acc: 0.8815\n",
      "Epoch 45/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0671 - acc: 0.9233 - val_loss: 0.1047 - val_acc: 0.8757\n",
      "Epoch 46/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0669 - acc: 0.9229 - val_loss: 0.1050 - val_acc: 0.8736\n",
      "Epoch 47/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0669 - acc: 0.9231 - val_loss: 0.1057 - val_acc: 0.8830\n",
      "Epoch 48/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0668 - acc: 0.9212 - val_loss: 0.1067 - val_acc: 0.8764\n",
      "Epoch 49/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0667 - acc: 0.9247 - val_loss: 0.1064 - val_acc: 0.8759\n",
      "Epoch 50/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0666 - acc: 0.9220 - val_loss: 0.1070 - val_acc: 0.8791\n",
      "Epoch 51/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0666 - acc: 0.9232 - val_loss: 0.1066 - val_acc: 0.8762\n",
      "Epoch 52/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0666 - acc: 0.9232 - val_loss: 0.1069 - val_acc: 0.8749\n",
      "Epoch 53/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0666 - acc: 0.9231 - val_loss: 0.1074 - val_acc: 0.8775\n",
      "Epoch 54/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0665 - acc: 0.9247 - val_loss: 0.1068 - val_acc: 0.8767\n",
      "Epoch 55/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0664 - acc: 0.9248 - val_loss: 0.1075 - val_acc: 0.8793\n",
      "Epoch 56/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0664 - acc: 0.9247 - val_loss: 0.1069 - val_acc: 0.8775\n",
      "Epoch 57/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0662 - acc: 0.9257 - val_loss: 0.1061 - val_acc: 0.8759\n",
      "Epoch 58/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0662 - acc: 0.9247 - val_loss: 0.1071 - val_acc: 0.87990.\n",
      "Epoch 59/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0661 - acc: 0.9241 - val_loss: 0.1064 - val_acc: 0.8780\n",
      "Epoch 60/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0661 - acc: 0.9245 - val_loss: 0.1077 - val_acc: 0.8791\n",
      "Epoch 61/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0660 - acc: 0.9245 - val_loss: 0.1070 - val_acc: 0.8793\n",
      "Epoch 62/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0660 - acc: 0.9249 - val_loss: 0.1061 - val_acc: 0.8767\n",
      "Epoch 63/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0658 - acc: 0.9241 - val_loss: 0.1069 - val_acc: 0.8767\n",
      "Epoch 64/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0658 - acc: 0.9253 - val_loss: 0.1063 - val_acc: 0.8786\n",
      "Epoch 65/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0657 - acc: 0.9241 - val_loss: 0.1068 - val_acc: 0.8759\n",
      "Epoch 66/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0658 - acc: 0.9247 - val_loss: 0.1077 - val_acc: 0.8793\n",
      "Epoch 67/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0657 - acc: 0.9247 - val_loss: 0.1071 - val_acc: 0.8780\n",
      "Epoch 68/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0657 - acc: 0.9247 - val_loss: 0.1075 - val_acc: 0.8683\n",
      "Epoch 69/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0657 - acc: 0.9239 - val_loss: 0.1073 - val_acc: 0.8678\n",
      "Epoch 70/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0656 - acc: 0.9251 - val_loss: 0.1077 - val_acc: 0.8791\n",
      "Epoch 71/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0656 - acc: 0.9252 - val_loss: 0.1080 - val_acc: 0.8796\n",
      "Epoch 72/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0656 - acc: 0.9253 - val_loss: 0.1072 - val_acc: 0.8775\n",
      "Epoch 73/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0655 - acc: 0.9249 - val_loss: 0.1077 - val_acc: 0.8778\n",
      "Epoch 74/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0656 - acc: 0.9241 - val_loss: 0.1070 - val_acc: 0.8764\n",
      "Epoch 75/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0655 - acc: 0.9253 - val_loss: 0.1078 - val_acc: 0.8778\n",
      "Epoch 76/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0655 - acc: 0.9243 - val_loss: 0.1096 - val_acc: 0.8725\n",
      "Epoch 77/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0654 - acc: 0.9256 - val_loss: 0.1088 - val_acc: 0.8786\n",
      "Epoch 78/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0656 - acc: 0.9251 - val_loss: 0.1072 - val_acc: 0.8759\n",
      "Epoch 79/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0654 - acc: 0.9245 - val_loss: 0.1075 - val_acc: 0.8783\n",
      "Epoch 80/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0654 - acc: 0.9243 - val_loss: 0.1075 - val_acc: 0.8764\n",
      "Epoch 81/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0654 - acc: 0.9247 - val_loss: 0.1081 - val_acc: 0.8778\n",
      "Epoch 82/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9257 - val_loss: 0.1069 - val_acc: 0.8757\n",
      "Epoch 83/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9251 - val_loss: 0.1079 - val_acc: 0.8764\n",
      "Epoch 84/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0654 - acc: 0.9243 - val_loss: 0.1081 - val_acc: 0.8780\n",
      "Epoch 85/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0654 - acc: 0.9245 - val_loss: 0.1076 - val_acc: 0.8764\n",
      "Epoch 86/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9258 - val_loss: 0.1081 - val_acc: 0.8678\n",
      "Epoch 87/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9257 - val_loss: 0.1089 - val_acc: 0.8701\n",
      "Epoch 88/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9262 - val_loss: 0.1081 - val_acc: 0.8691\n",
      "Epoch 89/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9256 - val_loss: 0.1077 - val_acc: 0.8772\n",
      "Epoch 90/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9261 - val_loss: 0.1092 - val_acc: 0.8693\n",
      "Epoch 91/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9257 - val_loss: 0.1081 - val_acc: 0.8685\n",
      "Epoch 92/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9258 - val_loss: 0.1081 - val_acc: 0.8696\n",
      "Epoch 93/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0652 - acc: 0.9253 - val_loss: 0.1081 - val_acc: 0.8675\n",
      "Epoch 94/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0652 - acc: 0.9258 - val_loss: 0.1083 - val_acc: 0.8680\n",
      "Epoch 95/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0652 - acc: 0.9257 - val_loss: 0.1090 - val_acc: 0.8696\n",
      "Epoch 96/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0652 - acc: 0.9249 - val_loss: 0.1085 - val_acc: 0.8696\n",
      "Epoch 97/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0652 - acc: 0.9245 - val_loss: 0.1077 - val_acc: 0.8691\n",
      "Epoch 98/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9260 - val_loss: 0.1084 - val_acc: 0.8688\n",
      "Epoch 99/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9249 - val_loss: 0.1073 - val_acc: 0.8680\n",
      "Epoch 100/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9257 - val_loss: 0.1083 - val_acc: 0.8688\n",
      "Epoch 101/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0652 - acc: 0.9253 - val_loss: 0.1097 - val_acc: 0.8688\n",
      "Epoch 102/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9257 - val_loss: 0.1086 - val_acc: 0.8699\n",
      "Epoch 103/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9262 - val_loss: 0.1066 - val_acc: 0.8764\n",
      "Epoch 104/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9254 - val_loss: 0.1090 - val_acc: 0.8691\n",
      "Epoch 105/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9257 - val_loss: 0.1080 - val_acc: 0.8738\n",
      "Epoch 106/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9252 - val_loss: 0.1085 - val_acc: 0.8701\n",
      "Epoch 107/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0652 - acc: 0.9244 - val_loss: 0.1085 - val_acc: 0.8685\n",
      "Epoch 108/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9257 - val_loss: 0.1072 - val_acc: 0.8743\n",
      "Epoch 109/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0653 - acc: 0.9240 - val_loss: 0.1094 - val_acc: 0.8685\n",
      "Epoch 110/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9257 - val_loss: 0.1089 - val_acc: 0.8685\n",
      "Epoch 111/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9251 - val_loss: 0.1103 - val_acc: 0.8691\n",
      "Epoch 112/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9258 - val_loss: 0.1093 - val_acc: 0.8691\n",
      "Epoch 113/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9257 - val_loss: 0.1094 - val_acc: 0.8691\n",
      "Epoch 114/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9256 - val_loss: 0.1090 - val_acc: 0.8709\n",
      "Epoch 115/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9256 - val_loss: 0.1087 - val_acc: 0.8691\n",
      "Epoch 116/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9258 - val_loss: 0.1086 - val_acc: 0.8685\n",
      "Epoch 117/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9254 - val_loss: 0.1083 - val_acc: 0.8767\n",
      "Epoch 118/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9254 - val_loss: 0.1089 - val_acc: 0.8683\n",
      "Epoch 119/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9249 - val_loss: 0.1084 - val_acc: 0.8685\n",
      "Epoch 120/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0652 - acc: 0.9254 - val_loss: 0.1087 - val_acc: 0.8685\n",
      "Epoch 121/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9253 - val_loss: 0.1095 - val_acc: 0.8767\n",
      "Epoch 122/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9257 - val_loss: 0.1080 - val_acc: 0.8759\n",
      "Epoch 123/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9257 - val_loss: 0.1100 - val_acc: 0.8693\n",
      "Epoch 124/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9257 - val_loss: 0.1092 - val_acc: 0.8691\n",
      "Epoch 125/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9260 - val_loss: 0.1088 - val_acc: 0.8683\n",
      "Epoch 126/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0651 - acc: 0.9252 - val_loss: 0.1091 - val_acc: 0.8680\n",
      "Epoch 127/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9258 - val_loss: 0.1093 - val_acc: 0.8688\n",
      "Epoch 128/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9254 - val_loss: 0.1081 - val_acc: 0.8683\n",
      "Epoch 129/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9261 - val_loss: 0.1105 - val_acc: 0.8714\n",
      "Epoch 130/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9261 - val_loss: 0.1085 - val_acc: 0.8683\n",
      "Epoch 131/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9256 - val_loss: 0.1099 - val_acc: 0.8699\n",
      "Epoch 132/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9260 - val_loss: 0.1102 - val_acc: 0.8691\n",
      "Epoch 133/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9261 - val_loss: 0.1103 - val_acc: 0.8685\n",
      "Epoch 134/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9261 - val_loss: 0.1104 - val_acc: 0.8691\n",
      "Epoch 135/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9261 - val_loss: 0.1088 - val_acc: 0.8678\n",
      "Epoch 136/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9257 - val_loss: 0.1091 - val_acc: 0.8691\n",
      "Epoch 137/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9256 - val_loss: 0.1095 - val_acc: 0.8714\n",
      "Epoch 138/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9249 - val_loss: 0.1097 - val_acc: 0.8672\n",
      "Epoch 139/2000\n",
      "7592/7592 [==============================] - ETA: 0s - loss: 0.0650 - acc: 0.926 - 0s - loss: 0.0649 - acc: 0.9264 - val_loss: 0.1100 - val_acc: 0.8688\n",
      "Epoch 140/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9261 - val_loss: 0.1098 - val_acc: 0.8693\n",
      "Epoch 141/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9257 - val_loss: 0.1107 - val_acc: 0.8701\n",
      "Epoch 142/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0650 - acc: 0.9261 - val_loss: 0.1086 - val_acc: 0.8691\n",
      "Epoch 143/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9258 - val_loss: 0.1105 - val_acc: 0.8712\n",
      "Epoch 144/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9256 - val_loss: 0.1112 - val_acc: 0.8717\n",
      "Epoch 145/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9254 - val_loss: 0.1106 - val_acc: 0.8693\n",
      "Epoch 146/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9253 - val_loss: 0.1098 - val_acc: 0.8664\n",
      "Epoch 147/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9258 - val_loss: 0.1116 - val_acc: 0.8693\n",
      "Epoch 148/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9262 - val_loss: 0.1126 - val_acc: 0.8699\n",
      "Epoch 149/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9253 - val_loss: 0.1105 - val_acc: 0.8696\n",
      "Epoch 150/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9262 - val_loss: 0.1106 - val_acc: 0.8688\n",
      "Epoch 151/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9262 - val_loss: 0.1115 - val_acc: 0.8693\n",
      "Epoch 152/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9265 - val_loss: 0.1098 - val_acc: 0.8741\n",
      "Epoch 153/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9261 - val_loss: 0.1098 - val_acc: 0.8683\n",
      "Epoch 154/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9253 - val_loss: 0.1145 - val_acc: 0.8746\n",
      "Epoch 155/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9265 - val_loss: 0.1114 - val_acc: 0.8691\n",
      "Epoch 156/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9264 - val_loss: 0.1111 - val_acc: 0.8691\n",
      "Epoch 157/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9260 - val_loss: 0.1107 - val_acc: 0.8693\n",
      "Epoch 158/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9261 - val_loss: 0.1090 - val_acc: 0.8693\n",
      "Epoch 159/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9261 - val_loss: 0.1121 - val_acc: 0.8691\n",
      "Epoch 160/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9256 - val_loss: 0.1107 - val_acc: 0.8691\n",
      "Epoch 161/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9265 - val_loss: 0.1102 - val_acc: 0.8680\n",
      "Epoch 162/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0649 - acc: 0.9252 - val_loss: 0.1118 - val_acc: 0.8696\n",
      "Epoch 163/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9261 - val_loss: 0.1132 - val_acc: 0.8699\n",
      "Epoch 164/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9268 - val_loss: 0.1111 - val_acc: 0.8672\n",
      "Epoch 165/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9262 - val_loss: 0.1107 - val_acc: 0.8675\n",
      "Epoch 166/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9260 - val_loss: 0.1126 - val_acc: 0.8693\n",
      "Epoch 167/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9261 - val_loss: 0.1124 - val_acc: 0.8712\n",
      "Epoch 168/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9260 - val_loss: 0.1125 - val_acc: 0.8683\n",
      "Epoch 169/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9262 - val_loss: 0.1128 - val_acc: 0.8693\n",
      "Epoch 170/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9261 - val_loss: 0.1116 - val_acc: 0.8699\n",
      "Epoch 171/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9266 - val_loss: 0.1140 - val_acc: 0.8699\n",
      "Epoch 172/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9252 - val_loss: 0.1134 - val_acc: 0.8707\n",
      "Epoch 173/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9262 - val_loss: 0.1107 - val_acc: 0.8696\n",
      "Epoch 174/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9265 - val_loss: 0.1117 - val_acc: 0.8693\n",
      "Epoch 175/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9261 - val_loss: 0.1143 - val_acc: 0.8701\n",
      "Epoch 176/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9262 - val_loss: 0.1096 - val_acc: 0.8685\n",
      "Epoch 177/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9260 - val_loss: 0.1101 - val_acc: 0.8670\n",
      "Epoch 178/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9261 - val_loss: 0.1135 - val_acc: 0.8699\n",
      "Epoch 179/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9258 - val_loss: 0.1134 - val_acc: 0.8704\n",
      "Epoch 180/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9261 - val_loss: 0.1117 - val_acc: 0.8683\n",
      "Epoch 181/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9254 - val_loss: 0.1117 - val_acc: 0.8696\n",
      "Epoch 182/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9265 - val_loss: 0.1130 - val_acc: 0.8667\n",
      "Epoch 183/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9257 - val_loss: 0.1127 - val_acc: 0.8696\n",
      "Epoch 184/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9265 - val_loss: 0.1122 - val_acc: 0.8693\n",
      "Epoch 185/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9260 - val_loss: 0.1127 - val_acc: 0.8696\n",
      "Epoch 186/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9262 - val_loss: 0.1135 - val_acc: 0.8680\n",
      "Epoch 187/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9261 - val_loss: 0.1140 - val_acc: 0.8722\n",
      "Epoch 188/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9269 - val_loss: 0.1135 - val_acc: 0.8696\n",
      "Epoch 189/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9261 - val_loss: 0.1143 - val_acc: 0.8714\n",
      "Epoch 190/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9264 - val_loss: 0.1137 - val_acc: 0.8704\n",
      "Epoch 191/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9264 - val_loss: 0.1124 - val_acc: 0.8691\n",
      "Epoch 192/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9264 - val_loss: 0.1127 - val_acc: 0.8696\n",
      "Epoch 193/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9260 - val_loss: 0.1127 - val_acc: 0.8707\n",
      "Epoch 194/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9268 - val_loss: 0.1128 - val_acc: 0.8693\n",
      "Epoch 195/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9257 - val_loss: 0.1138 - val_acc: 0.8709\n",
      "Epoch 196/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9256 - val_loss: 0.1140 - val_acc: 0.8696\n",
      "Epoch 197/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9264 - val_loss: 0.1135 - val_acc: 0.8701\n",
      "Epoch 198/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9266 - val_loss: 0.1138 - val_acc: 0.8678\n",
      "Epoch 199/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9264 - val_loss: 0.1128 - val_acc: 0.8683\n",
      "Epoch 200/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9264 - val_loss: 0.1130 - val_acc: 0.8701\n",
      "Epoch 201/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9266 - val_loss: 0.1133 - val_acc: 0.8678\n",
      "Epoch 202/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9254 - val_loss: 0.1107 - val_acc: 0.8685\n",
      "Epoch 203/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9262 - val_loss: 0.1119 - val_acc: 0.8688\n",
      "Epoch 204/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9265 - val_loss: 0.1137 - val_acc: 0.8675\n",
      "Epoch 205/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9261 - val_loss: 0.1131 - val_acc: 0.8688\n",
      "Epoch 206/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9261 - val_loss: 0.1134 - val_acc: 0.8701\n",
      "Epoch 207/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9264 - val_loss: 0.1129 - val_acc: 0.8701\n",
      "Epoch 208/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9266 - val_loss: 0.1141 - val_acc: 0.8701\n",
      "Epoch 209/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9254 - val_loss: 0.1134 - val_acc: 0.8693\n",
      "Epoch 210/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9270 - val_loss: 0.1129 - val_acc: 0.8680\n",
      "Epoch 211/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9265 - val_loss: 0.1134 - val_acc: 0.8709\n",
      "Epoch 212/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9264 - val_loss: 0.1130 - val_acc: 0.8685\n",
      "Epoch 213/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9264 - val_loss: 0.1134 - val_acc: 0.8699\n",
      "Epoch 214/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0648 - acc: 0.9262 - val_loss: 0.1135 - val_acc: 0.8691\n",
      "Epoch 215/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9268 - val_loss: 0.1135 - val_acc: 0.8693\n",
      "Epoch 216/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9261 - val_loss: 0.1132 - val_acc: 0.8688\n",
      "Epoch 217/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9262 - val_loss: 0.1129 - val_acc: 0.8683\n",
      "Epoch 218/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9265 - val_loss: 0.1137 - val_acc: 0.8683\n",
      "Epoch 219/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9257 - val_loss: 0.1137 - val_acc: 0.8699\n",
      "Epoch 220/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9265 - val_loss: 0.1134 - val_acc: 0.8704\n",
      "Epoch 221/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9269 - val_loss: 0.1140 - val_acc: 0.8691\n",
      "Epoch 222/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9264 - val_loss: 0.1136 - val_acc: 0.8664\n",
      "Epoch 223/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9262 - val_loss: 0.1124 - val_acc: 0.8685\n",
      "Epoch 224/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9269 - val_loss: 0.1136 - val_acc: 0.8701\n",
      "Epoch 225/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9264 - val_loss: 0.1138 - val_acc: 0.8688\n",
      "Epoch 226/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9261 - val_loss: 0.1134 - val_acc: 0.8704\n",
      "Epoch 227/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9269 - val_loss: 0.1130 - val_acc: 0.8688\n",
      "Epoch 228/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9254 - val_loss: 0.1137 - val_acc: 0.8707\n",
      "Epoch 229/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9266 - val_loss: 0.1128 - val_acc: 0.8659\n",
      "Epoch 230/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9266 - val_loss: 0.1129 - val_acc: 0.8678\n",
      "Epoch 231/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9264 - val_loss: 0.1144 - val_acc: 0.8717\n",
      "Epoch 232/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9265 - val_loss: 0.1139 - val_acc: 0.8701\n",
      "Epoch 233/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9260 - val_loss: 0.1136 - val_acc: 0.8701\n",
      "Epoch 234/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9269 - val_loss: 0.1134 - val_acc: 0.8693\n",
      "Epoch 235/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9261 - val_loss: 0.1137 - val_acc: 0.8701\n",
      "Epoch 236/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9262 - val_loss: 0.1135 - val_acc: 0.8699\n",
      "Epoch 237/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9262 - val_loss: 0.1137 - val_acc: 0.8696\n",
      "Epoch 238/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9260 - val_loss: 0.1135 - val_acc: 0.8685\n",
      "Epoch 239/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9269 - val_loss: 0.1135 - val_acc: 0.8701\n",
      "Epoch 240/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9256 - val_loss: 0.1138 - val_acc: 0.8685\n",
      "Epoch 241/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9261 - val_loss: 0.1105 - val_acc: 0.8672\n",
      "Epoch 242/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9261 - val_loss: 0.1131 - val_acc: 0.8691\n",
      "Epoch 243/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9256 - val_loss: 0.1133 - val_acc: 0.8688\n",
      "Epoch 244/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9262 - val_loss: 0.1139 - val_acc: 0.8712\n",
      "Epoch 245/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9266 - val_loss: 0.1139 - val_acc: 0.8725\n",
      "Epoch 246/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9262 - val_loss: 0.1134 - val_acc: 0.8699\n",
      "Epoch 247/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9265 - val_loss: 0.1132 - val_acc: 0.8670\n",
      "Epoch 248/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9260 - val_loss: 0.1141 - val_acc: 0.8691\n",
      "Epoch 249/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9256 - val_loss: 0.1146 - val_acc: 0.8699\n",
      "Epoch 250/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9269 - val_loss: 0.1133 - val_acc: 0.8688\n",
      "Epoch 251/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9264 - val_loss: 0.1138 - val_acc: 0.8701\n",
      "Epoch 252/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9262 - val_loss: 0.1131 - val_acc: 0.8667\n",
      "Epoch 253/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9261 - val_loss: 0.1139 - val_acc: 0.8688\n",
      "Epoch 254/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9264 - val_loss: 0.1139 - val_acc: 0.8704\n",
      "Epoch 255/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9266 - val_loss: 0.1132 - val_acc: 0.8670\n",
      "Epoch 256/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9260 - val_loss: 0.1140 - val_acc: 0.8685\n",
      "Epoch 257/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9264 - val_loss: 0.1132 - val_acc: 0.8704\n",
      "Epoch 258/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9264 - val_loss: 0.1129 - val_acc: 0.8683\n",
      "Epoch 259/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9262 - val_loss: 0.1137 - val_acc: 0.8701\n",
      "Epoch 260/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9269 - val_loss: 0.1136 - val_acc: 0.8685\n",
      "Epoch 261/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9264 - val_loss: 0.1137 - val_acc: 0.8691\n",
      "Epoch 262/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9262 - val_loss: 0.1145 - val_acc: 0.8709\n",
      "Epoch 263/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0646 - acc: 0.9260 - val_loss: 0.1136 - val_acc: 0.8691\n",
      "Epoch 264/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9265 - val_loss: 0.1133 - val_acc: 0.8701\n",
      "Epoch 265/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9266 - val_loss: 0.1137 - val_acc: 0.8688\n",
      "Epoch 266/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9262 - val_loss: 0.1132 - val_acc: 0.8704\n",
      "Epoch 267/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9266 - val_loss: 0.1129 - val_acc: 0.8693\n",
      "Epoch 268/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9264 - val_loss: 0.1139 - val_acc: 0.8707\n",
      "Epoch 269/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9266 - val_loss: 0.1132 - val_acc: 0.8701\n",
      "Epoch 270/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9261 - val_loss: 0.1142 - val_acc: 0.8691\n",
      "Epoch 271/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9256 - val_loss: 0.1148 - val_acc: 0.8717\n",
      "Epoch 272/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9256 - val_loss: 0.1143 - val_acc: 0.8704\n",
      "Epoch 273/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0643 - acc: 0.9269 - val_loss: 0.1138 - val_acc: 0.8685\n",
      "Epoch 274/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9258 - val_loss: 0.1137 - val_acc: 0.8664\n",
      "Epoch 275/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9262 - val_loss: 0.1135 - val_acc: 0.8704\n",
      "Epoch 276/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9266 - val_loss: 0.1134 - val_acc: 0.8688\n",
      "Epoch 277/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9264 - val_loss: 0.1139 - val_acc: 0.8699\n",
      "Epoch 278/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9272 - val_loss: 0.1139 - val_acc: 0.8685\n",
      "Epoch 279/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9265 - val_loss: 0.1137 - val_acc: 0.8688\n",
      "Epoch 280/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9265 - val_loss: 0.1138 - val_acc: 0.8712\n",
      "Epoch 281/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9268 - val_loss: 0.1145 - val_acc: 0.8696\n",
      "Epoch 282/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9262 - val_loss: 0.1134 - val_acc: 0.8672\n",
      "Epoch 283/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9258 - val_loss: 0.1134 - val_acc: 0.8696\n",
      "Epoch 284/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0643 - acc: 0.9256 - val_loss: 0.1157 - val_acc: 0.8725\n",
      "Epoch 285/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9270 - val_loss: 0.1142 - val_acc: 0.8693\n",
      "Epoch 286/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9261 - val_loss: 0.1141 - val_acc: 0.8707\n",
      "Epoch 287/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9266 - val_loss: 0.1140 - val_acc: 0.8691\n",
      "Epoch 288/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9266 - val_loss: 0.1137 - val_acc: 0.8691\n",
      "Epoch 289/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0644 - acc: 0.9262 - val_loss: 0.1137 - val_acc: 0.8688\n",
      "Epoch 290/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0645 - acc: 0.9268 - val_loss: 0.1132 - val_acc: 0.8685\n",
      "Epoch 291/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0643 - acc: 0.9260 - val_loss: 0.1137 - val_acc: 0.8685\n",
      "Epoch 292/2000\n",
      "7592/7592 [==============================] - 0s - loss: 0.0647 - acc: 0.9257 - val_loss: 0.1139 - val_acc: 0.8688\n",
      "Epoch 293/2000\n",
      "4864/7592 [==================>...........] - ETA: 0s - loss: 0.0620 - acc: 0.9280"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e2e6926c5dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                          \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# utilizado para misturar as amostras a cada epoca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                          validation_data=(X_validation, y_validation))\n\u001b[0m",
      "\u001b[0;32m~/Documentos/env/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Documentos/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/Documentos/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(5, activation='relu', input_dim=6)) # camada escondida\n",
    "classifier.add(Dense(1, activation='relu')) # \n",
    "classifier.compile(optimizer='adam', \n",
    "                   loss='mean_squared_error', # metrica de erro\n",
    "                   metrics=['accuracy']) # metrica de sucesso\n",
    "\n",
    "history = classifier.fit(X_train, y_train,\n",
    "                         epochs=2000, # quantidade de epocas que a rede neural vai executar\n",
    "                         verbose=1,\n",
    "                         shuffle=True, # utilizado para misturar as amostras a cada epoca\n",
    "                         validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = classifier.evaluate(X_test, y_test)\n",
    "print (test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_training_error_curves(history)\n",
    "plot_training_acc_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA 3 (3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(3, activation='relu', input_dim=6)) # camada escondida\n",
    "classifier.add(Dense(5, activation='relu')) # camada escondida\n",
    "classifier.add(Dense(1, activation='relu')) # \n",
    "classifier.compile(optimizer='adam', \n",
    "                   loss='mean_squared_error', # metrica de erro\n",
    "                   metrics=['accuracy']) # metrica de sucesso\n",
    "\n",
    "history = classifier.fit(X_train, y_train,\n",
    "                         epochs=2000, # quantidade de epocas que a rede neural vai executar\n",
    "                         verbose=1,\n",
    "                         shuffle=True, # utilizado para misturar as amostras a cada epoca\n",
    "                         validation_data=(X_validation, y_validation))\n",
    "#                          callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = classifier.evaluate(X_test, y_test)\n",
    "print (test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_error_curves(history)\n",
    "plot_training_acc_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA 4 (5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(5, activation='relu', input_dim=6)) # camada escondida\n",
    "classifier.add(Dense(3, activation='relu')) # camada escondida\n",
    "classifier.add(Dense(1, activation='relu')) # \n",
    "classifier.compile(optimizer='adam', \n",
    "                   loss='mean_squared_error', # metrica de erro\n",
    "                   metrics=['accuracy']) # metrica de sucesso\n",
    "\n",
    "history = classifier.fit(X_train, y_train,\n",
    "                         epochs=2000, # quantidade de epocas que a rede neural vai executar\n",
    "                         verbose=1,\n",
    "                         shuffle=True, # utilizado para misturar as amostras a cada epoca\n",
    "                         validation_data=(X_validation, y_validation))\n",
    "#                          callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = classifier.evaluate(X_test, y_test)\n",
    "print (test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_error_curves(history)\n",
    "plot_training_acc_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA 5 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aqui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(2, activation='relu', input_dim=6)) # camada escondida\n",
    "classifier.add(Dense(1, activation='relu')) # \n",
    "classifier.compile(optimizer='adam', \n",
    "                   loss='mean_squared_error', # metrica de erro\n",
    "                   metrics=['accuracy']) # metrica de sucesso\n",
    "\n",
    "history = classifier.fit(X_train, y_train,\n",
    "                         epochs=2000, # quantidade de epocas que a rede neural vai executar\n",
    "                         verbose=1,\n",
    "                         shuffle=True, # utilizado para misturar as amostras a cada epoca\n",
    "                         validation_data=(X_validation, y_validation))\n",
    "#                          callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = classifier.evaluate(X_test, y_test)\n",
    "print (test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_error_curves(history)\n",
    "plot_training_acc_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA 6 (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aq## RNA 5 (2)ui criamos o esboço da rede.\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(4, activation='relu', input_dim=6)) # camada escondida\n",
    "classifier.add(Dense(1, activation='relu')) # \n",
    "classifier.compile(optimizer='adam', \n",
    "                   loss='mean_squared_error', # metrica de erro\n",
    "                   metrics=['accuracy']) # metrica de sucesso\n",
    "\n",
    "history = classifier.fit(X_train, y_train,\n",
    "                         epochs=2000, # quantidade de epocas que a rede neural vai executar\n",
    "                         verbose=1,\n",
    "                         shuffle=True, # utilizado para misturar as amostras a cada epoca\n",
    "                         validation_data=(X_validation, y_validation))\n",
    "#                          callbacks=[early_stopping], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = classifier.evaluate(X_test, y_test)\n",
    "print (test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_error_curves(history)\n",
    "plot_training_acc_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predições no Conjunto de Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora utilizamos a nossa rede para fazer predições no conjunto de teste e computar métricas de desempenho.\n",
    "\n",
    "Além das métricas utilizadas aqui, mais métricas de desempenho podem ser encontradas em: http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão\n",
      "[[1774  124]\n",
      " [   9   55]]\n",
      "\n",
      "Train Loss:       0.0725\n",
      "Validation Loss:  0.0816\n",
      "Accuracy:         0.9322\n",
      "Recall:           0.8594\n",
      "Precision:        0.3073\n",
      "F1:               0.4527\n",
      "AUROC:            0.9239\n"
     ]
    }
   ],
   "source": [
    "## Fazer predições no conjunto de teste\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred_class = classifier.predict_classes(X_test, verbose=0)\n",
    "\n",
    "## Matriz de confusão\n",
    "print('Matriz de confusão')\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "## Computar métricas de desempenho\n",
    "losses = extract_final_losses(history)\n",
    "print()\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Train Loss:\", value=losses['train_loss']))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Validation Loss:\", value=losses['val_loss']))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy_score(y_test, y_pred_class)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Recall:\", value=recall_score(y_test, y_pred_class)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"Precision:\", value=precision_score(y_test, y_pred_class)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"F1:\", value=f1_score(y_test, y_pred_class)))\n",
    "print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=roc_auc_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
